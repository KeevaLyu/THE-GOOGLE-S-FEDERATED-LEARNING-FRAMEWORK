{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"a5e36ac6a21e329c2cec267b08e4f28884519c7e5682f29504bd17199cc3d203"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library","metadata":{"id":"NsvvFSId2xB6"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nimport numpy as np\nimport random\nfrom collections import OrderedDict, ChainMap, Counter\nfrom tqdm.asyncio import tqdm\nimport math\nimport matplotlib.pyplot as plt\n\n# for reproducible results\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\ndevice = torch.device('cpu')\n# gpu\nif torch.backends.mps.is_available():\n    device = torch.device('mps')\nelif torch.cuda.is_available():\n    device = torch.device('cuda:0')\nprint(device)","metadata":{"id":"vDaWQfJ022KB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51b40344-98b9-44f0-ce98-b67d8e6c23bc","execution":{"iopub.status.busy":"2023-05-24T05:04:29.650288Z","iopub.execute_input":"2023-05-24T05:04:29.650642Z","iopub.status.idle":"2023-05-24T05:04:29.659592Z","shell.execute_reply.started":"2023-05-24T05:04:29.650611Z","shell.execute_reply":"2023-05-24T05:04:29.658319Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data processing","metadata":{"id":"t_RCPBAVzB9L"}},{"cell_type":"code","source":"transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))]) # scale from [0,255] to [0,1] and make mean and std to 0.0 and 1.0 respectively\ntraining_dataset = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)","metadata":{"id":"GrvHYZ_swCAM","execution":{"iopub.status.busy":"2023-05-24T05:04:29.661620Z","iopub.execute_input":"2023-05-24T05:04:29.662305Z","iopub.status.idle":"2023-05-24T05:04:29.757089Z","shell.execute_reply.started":"2023-05-24T05:04:29.662273Z","shell.execute_reply":"2023-05-24T05:04:29.755952Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# sort by labels\nsorted_indices = torch.argsort(torch.Tensor(training_dataset.targets))\nsorted_training_dataset = torch.utils.data.Subset(training_dataset, sorted_indices)\n\n# partition data into shards\ndef prepare_datashards(num_clients, num_shards, strict=False):\n    training_datashards = []\n\n    shards = []\n    # partition by class\n    if strict:\n        number_of_classes = len(sorted_training_dataset.dataset.classes)\n        shards_per_class = num_shards // number_of_classes\n\n        ptr = 0\n        # for each class\n        for label, size in sorted(Counter(sorted_training_dataset.dataset.targets.tolist()).items()):\n            shard_size = math.ceil(size / shards_per_class)\n\n            # for each shard\n            for i in range(shards_per_class):\n                shard = []\n                # fill shard of shard_size\n                for j in range(shard_size):\n                    shard.append(sorted_training_dataset[ptr])\n                    ptr += 1\n                    # break for next class\n                    if ptr >= len(sorted_training_dataset) or sorted_training_dataset[ptr][1] != label:\n                        break\n                shards.append(shard)\n\n    # partition by size\n    else:\n        shard_size = len(sorted_training_dataset) // num_shards\n\n        # for each shard\n        for i in range(num_shards):\n            shard = []\n            # fill shard of shard_size\n            for j in range(shard_size):\n                shard.append(sorted_training_dataset[i * shard_size + j])\n            shards.append(shard)\n    \n    # shuffled shard ids\n    random.seed(seed)\n    shard_ids = random.sample(list(range(num_shards)), num_shards)\n    print(\"Shards order - {}\".format(shard_ids))\n\n    # for each client\n    for k in range(num_clients):\n        client_shards = []\n        # number of shards per client\n        shards_per_client = num_shards // num_clients\n        for s in range(shards_per_client):\n            id = shard_ids[k * shards_per_client + s]\n            client_shards.append(shards[id])\n        training_datashards.append(client_shards)\n\n    return training_datashards","metadata":{"id":"ZohHDK7o65fH","execution":{"iopub.status.busy":"2023-05-24T05:04:29.758453Z","iopub.execute_input":"2023-05-24T05:04:29.759045Z","iopub.status.idle":"2023-05-24T05:04:29.782351Z","shell.execute_reply.started":"2023-05-24T05:04:29.759010Z","shell.execute_reply":"2023-05-24T05:04:29.778899Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Global","metadata":{"id":"mamL4quE65fI"}},{"cell_type":"code","source":"# clients training mode\nPARALLEL_TRAINING = True\n\n# clients and shards\nnum_clients = 100\nnum_shards = 200\n\n# prepare training data\ntraining_datashards = prepare_datashards(num_clients, num_shards)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPNbLHz865fI","outputId":"80b1bb83-032c-416d-c78d-c1fc8b9442f2","execution":{"iopub.status.busy":"2023-05-24T05:04:29.795298Z","iopub.execute_input":"2023-05-24T05:04:29.795683Z","iopub.status.idle":"2023-05-24T05:04:41.459913Z","shell.execute_reply.started":"2023-05-24T05:04:29.795647Z","shell.execute_reply":"2023-05-24T05:04:41.458837Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Shards order - [163, 28, 6, 189, 70, 62, 57, 35, 188, 26, 173, 139, 22, 151, 108, 8, 7, 23, 55, 59, 129, 154, 197, 143, 50, 166, 191, 107, 56, 114, 150, 71, 1, 40, 185, 87, 168, 39, 181, 86, 190, 182, 97, 24, 91, 88, 67, 11, 117, 137, 31, 96, 20, 141, 75, 92, 49, 17, 152, 58, 74, 147, 180, 25, 157, 199, 116, 93, 41, 94, 90, 53, 68, 89, 119, 164, 82, 9, 77, 81, 21, 127, 132, 149, 138, 169, 48, 34, 120, 178, 134, 198, 124, 131, 98, 99, 183, 29, 4, 174, 51, 112, 184, 27, 72, 155, 100, 148, 83, 63, 175, 123, 140, 18, 33, 142, 133, 109, 118, 85, 196, 54, 79, 104, 46, 165, 84, 65, 179, 146, 177, 14, 19, 115, 78, 135, 176, 156, 38, 102, 80, 16, 192, 161, 0, 43, 145, 103, 95, 105, 113, 73, 106, 125, 52, 160, 144, 10, 60, 171, 172, 32, 195, 61, 69, 153, 36, 12, 122, 37, 194, 5, 110, 47, 162, 186, 126, 42, 15, 159, 3, 30, 130, 45, 167, 158, 76, 128, 170, 136, 44, 64, 2, 13, 121, 111, 193, 101, 187, 66]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"e6vzuzLL1cP8"}},{"cell_type":"code","source":"class CNN(nn.Module):\n    # https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html#specify-how-data-will-pass-through-your-model\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 5x5 convolution layer with 32 channels\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same')\n        # 5x5 convolution layer with 64 channels\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same')\n        # fully connected layer with 512 units, in_features = channels * height * width from conv2\n        self.fc1 = nn.Linear(in_features=64*7*7, out_features=512)\n        self.fc2 = nn.Linear(in_features=512, out_features=10)\n\n    # x represents our data\n    def forward(self, x):\n        # Pass data through conv1\n        x = self.conv1(x)\n        # Use the rectified-linear activation function over x\n        x = F.relu(x)\n        # Run max pooling over x\n        x = F.max_pool2d(x, kernel_size=2)\n        \n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n\n        # Flatten x with start_dim=1\n        x = torch.flatten(x, start_dim=1)\n        # Pass data through fc1\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n\n        # Apply softmax to x\n        output = F.log_softmax(x, dim=1)\n        return output","metadata":{"id":"4KIxpXNR1dWg","execution":{"iopub.status.busy":"2023-05-24T05:04:41.463355Z","iopub.execute_input":"2023-05-24T05:04:41.463720Z","iopub.status.idle":"2023-05-24T05:04:41.474795Z","shell.execute_reply.started":"2023-05-24T05:04:41.463694Z","shell.execute_reply":"2023-05-24T05:04:41.473916Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_params = sum(p.numel() for p in CNN().parameters())\nprint(\"Total number of parameters:\", num_params)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLzdTLYt65fJ","outputId":"3f1223fb-5b0b-43c0-e35b-eab69d11a45c","execution":{"iopub.status.busy":"2023-05-24T05:04:41.476443Z","iopub.execute_input":"2023-05-24T05:04:41.477103Z","iopub.status.idle":"2023-05-24T05:04:41.506009Z","shell.execute_reply.started":"2023-05-24T05:04:41.477072Z","shell.execute_reply":"2023-05-24T05:04:41.505142Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Total number of parameters: 1663370\n","output_type":"stream"}]},{"cell_type":"code","source":"for p in CNN().parameters():\n    print(p.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY3Pl12PP4rP","outputId":"5c6d2ae1-1831-4068-d3a8-3ed4ae5e1cd8","execution":{"iopub.status.busy":"2023-05-24T05:04:41.507481Z","iopub.execute_input":"2023-05-24T05:04:41.507799Z","iopub.status.idle":"2023-05-24T05:04:41.527240Z","shell.execute_reply.started":"2023-05-24T05:04:41.507769Z","shell.execute_reply":"2023-05-24T05:04:41.526388Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([32, 1, 5, 5])\ntorch.Size([32])\ntorch.Size([64, 32, 5, 5])\ntorch.Size([64])\ntorch.Size([512, 3136])\ntorch.Size([512])\ntorch.Size([10, 512])\ntorch.Size([10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Client\n","metadata":{"id":"RtdxFdsz1h0m"}},{"cell_type":"code","source":"class Client():\n    def __init__(self, k, model, args):\n        # inititalize client\n        self.id = k\n        self.model = model\n        self.args = args\n\n        # load dataset\n        self.dataset = []\n        self._load_dataset(k)\n        self.training_loader = torch.utils.data.DataLoader(self.dataset, batch_size=self.args['B'], shuffle=True)\n\n        # state_dict\n        self.state_dict = self.model.state_dict()\n\n    def _load_dataset(self, k):\n        # load dataset\n        for shard in training_datashards[k]:\n            self.dataset += shard\n        return\n\n    def labels(self):\n        return dict(Counter(data[1] for data in self.dataset))\n\n    def size(self):\n        return len(self.dataset)\n\n    async def update(self):\n        # load state_dict\n        self.model.load_state_dict(self.state_dict)\n\n        # Sets the module in training mode\n        self.model.train(True)\n\n        optimizer = optim.SGD(self.model.parameters(), lr=self.args['lr'])\n        loss_fn = nn.CrossEntropyLoss()\n\n        # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n        for epoch in range(self.args['E']):\n            for inputs, labels in self.training_loader:\n                # Every data instance is an input + label pair\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                # Zero your gradients for every batch!\n                optimizer.zero_grad()\n\n                # Make predictions for this batch\n                outputs = self.model(inputs)\n\n                # Compute the loss and its gradients\n                loss = loss_fn(outputs, labels)\n                loss.backward()\n\n                # Adjust learning weights\n                optimizer.step()\n        \n        # save state_dict\n        self.state_dict = self.model.state_dict()\n\n        return { self.id: self.state_dict }\n\n    def model_sync(self, state_dict):\n        self.state_dict = state_dict","metadata":{"id":"bzCVn4hfAOhX","execution":{"iopub.status.busy":"2023-05-24T05:04:41.528684Z","iopub.execute_input":"2023-05-24T05:04:41.529010Z","iopub.status.idle":"2023-05-24T05:04:41.540597Z","shell.execute_reply.started":"2023-05-24T05:04:41.528981Z","shell.execute_reply":"2023-05-24T05:04:41.539660Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Server","metadata":{"id":"unKQT-qEPnKL"}},{"cell_type":"code","source":"class Server():\n    def __init__(self, args):\n        self.model = CNN().to(device)\n        # number of rounds of communication\n        self.rounds = 0\n        # client fraction C\n        self.c = args['C']\n        # client list\n        self.clients = []\n        # inititalize clients according to num_clients\n        if PARALLEL_TRAINING:\n            for k in range(num_clients):\n                torch.manual_seed(seed)\n                client_model = CNN().to(device)\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n        else:\n            torch.manual_seed(seed)\n            client_model = CNN().to(device)\n            for k in range(num_clients):\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n\n    def _fed_avg(self, state_dicts):\n        # total number of data\n        len_total = 0\n        for k in ChainMap(*state_dicts).keys():\n            len_total += self.clients[k].size()\n\n        dict = OrderedDict()\n        # for each client's state_dict\n        for k, state_dict in ChainMap(*state_dicts).items():\n            # for each tensor param\n            for param_tensor in self.model.state_dict().keys():\n                # param = w0 * wf0 + w1 * wf1 + ... wk * wfk\n                if param_tensor in dict:\n                    dict[param_tensor] += state_dict[param_tensor] * (self.clients[k].size() / len_total)\n                else:\n                    dict[param_tensor] = state_dict[param_tensor] * (self.clients[k].size() / len_total)\n\n        return dict\n\n    def clients_info(self):\n        for i, client in enumerate(self.clients):\n            print(\"Client {} - {}\".format(i, client.labels()))\n\n    async def model_sync(self):\n        selected_clients = self.clients\n\n        # clients random selection\n        if self.c < 1.0:\n            # clients per round\n            k = max(int(self.c * num_clients), 1)\n            # client selection\n            random.seed(self.rounds)\n            selected_clients = random.sample(self.clients, k=k)\n            client_ids = []\n            for client in selected_clients:\n                client_ids.append(client.id)\n            print(\"Selected clients - {}\".format(client_ids))\n\n        state_dicts = []\n        # for each selected client do client update\n        if PARALLEL_TRAINING:\n            state_dicts = await tqdm.gather(*[client.update() for client in selected_clients])\n        else:\n            for client in tqdm(selected_clients):\n                state_dict = await client.update()\n                state_dicts.append(state_dict)\n        \n        # update server weights\n        avg_state_dict = self._fed_avg(state_dicts)\n        self.model.load_state_dict(avg_state_dict)\n\n        # sync with all clients\n        for client in self.clients:\n            client.model_sync(avg_state_dict)\n\n        # increase rounds count\n        self.rounds += 1","metadata":{"id":"rjIkYahr1jVG","execution":{"iopub.status.busy":"2023-05-24T05:04:41.542229Z","iopub.execute_input":"2023-05-24T05:04:41.542914Z","iopub.status.idle":"2023-05-24T05:04:41.559544Z","shell.execute_reply.started":"2023-05-24T05:04:41.542860Z","shell.execute_reply":"2023-05-24T05:04:41.558846Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def test_model(model):\n    # https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-analysis-train-model#test-the-model-on-the-test-data\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Sets the module in evaluate mode\n    model.eval()\n    model.to(device)\n    \n    correct = 0\n    loss = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            # Every data instance is an input + label pair\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Make predictions for this batch\n            outputs = model(inputs)\n            _, pred = torch.max(outputs, dim=1)\n            total += labels.size(0)\n\n            # Compute the loss and accuracy\n            loss += loss_fn(outputs, labels).item()\n            correct += (pred == labels).sum().item()\n\n    loss /= total\n    accuracy = correct / total\n\n    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n        loss, correct, total, accuracy * 100))\n    return accuracy, loss","metadata":{"id":"v-JVTN0sCHlk","execution":{"iopub.status.busy":"2023-05-24T05:04:41.560828Z","iopub.execute_input":"2023-05-24T05:04:41.561422Z","iopub.status.idle":"2023-05-24T05:04:41.572476Z","shell.execute_reply.started":"2023-05-24T05:04:41.561391Z","shell.execute_reply":"2023-05-24T05:04:41.571792Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"async def execute(server, T, target_accuracy, es=None, min_delta=0.0, patience=0):\n    _patience = patience\n\n    # initial values\n    record_round = 0\n    best_round = 0\n    best_accuracy = 0.0\n    last_loss = None\n    state_dict, accuracies, losses = [], [], []\n\n    # loop until rounds\n    while server.rounds < T:\n        print(\"Round {}/{}\".format(server.rounds + 1, T))\n\n        # model sync\n        await server.model_sync()\n        \n        # test accuracy\n        accuracy, loss = test_model(server.model)\n\n        if accuracy >= best_accuracy:\n            # save best record\n            best_accuracy = accuracy\n            best_round = server.rounds\n\n            if best_accuracy >= target_accuracy or server.rounds > T - 10:\n                # save state_dict\n                state_dict = server.model.state_dict()\n\n        # statistics\n        accuracies.append(accuracy)\n        losses.append(loss)\n\n        # early stopping\n        if es == 'loss':\n            if last_loss is None:\n                last_loss = loss\n                continue\n\n            if last_loss - loss < min_delta:\n                # break if patience equal to 0\n                if patience == 0:\n                    break\n                else:\n                    patience -= 1\n            else:\n                # reset patience and update last loss\n                patience = _patience\n                last_loss = loss\n\n        # target accuracy reached\n        if accuracy >= target_accuracy and record_round == 0:\n            record_round = server.rounds\n\n    if record_round > 0:\n        print(\"Target accuracy reached at round: {}\".format(record_round))\n    print(\"Best round: {}, accuracy: {}\".format(best_round, best_accuracy))\n\n    return state_dict, accuracies, losses","metadata":{"id":"BQ7wc8Q_FAkU","execution":{"iopub.status.busy":"2023-05-24T05:04:41.573689Z","iopub.execute_input":"2023-05-24T05:04:41.574280Z","iopub.status.idle":"2023-05-24T05:04:41.584858Z","shell.execute_reply.started":"2023-05-24T05:04:41.574249Z","shell.execute_reply":"2023-05-24T05:04:41.584181Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Execute","metadata":{"id":"OE0VQHt_65fS"}},{"cell_type":"code","source":"# model params\nargs = { 'C': 0.1, 'E': 5, 'B': 10 , 'lr': 0.1 }\n\n# server\nserver = Server(args)\n\n# data distribution\nprint(\"Training dataset - {}\".format(dict(sorted(Counter(training_dataset.targets.tolist()).items()))))\nserver.clients_info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gas3rs865fT","outputId":"f06e8ff8-8899-47c4-c709-f4aeb088613b","execution":{"iopub.status.busy":"2023-05-24T05:04:41.586106Z","iopub.execute_input":"2023-05-24T05:04:41.586680Z","iopub.status.idle":"2023-05-24T05:04:43.896203Z","shell.execute_reply.started":"2023-05-24T05:04:41.586633Z","shell.execute_reply":"2023-05-24T05:04:43.895251Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training dataset - {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\nClient 0 - {8: 300, 1: 300}\nClient 1 - {0: 300, 9: 300}\nClient 2 - {3: 577, 2: 23}\nClient 3 - {2: 300, 1: 300}\nClient 4 - {9: 300, 1: 300}\nClient 5 - {8: 300, 6: 235, 7: 65}\nClient 6 - {1: 300, 7: 300}\nClient 7 - {5: 300, 0: 300}\nClient 8 - {0: 300, 1: 300}\nClient 9 - {2: 600}\nClient 10 - {6: 300, 7: 300}\nClient 11 - {9: 300, 7: 300}\nClient 12 - {2: 300, 8: 300}\nClient 13 - {9: 300, 5: 300}\nClient 14 - {2: 300, 5: 300}\nClient 15 - {7: 300, 3: 300}\nClient 16 - {0: 300, 1: 300}\nClient 17 - {9: 300, 4: 300}\nClient 18 - {8: 300, 1: 300}\nClient 19 - {9: 300, 4: 300}\nClient 20 - {9: 600}\nClient 21 - {4: 300, 1: 300}\nClient 22 - {4: 600}\nClient 23 - {3: 300, 0: 300}\nClient 24 - {5: 300, 6: 300}\nClient 25 - {1: 300, 4: 300}\nClient 26 - {1: 300, 7: 300}\nClient 27 - {3: 300, 4: 300}\nClient 28 - {2: 300, 0: 300}\nClient 29 - {7: 300, 2: 300}\nClient 30 - {3: 300, 7: 300}\nClient 31 - {8: 51, 9: 249, 1: 300}\nClient 32 - {7: 300, 9: 300}\nClient 33 - {5: 300, 4: 300}\nClient 34 - {1: 300, 4: 300}\nClient 35 - {4: 300, 2: 300}\nClient 36 - {3: 300, 4: 300}\nClient 37 - {5: 300, 8: 300}\nClient 38 - {3: 154, 4: 146, 0: 300}\nClient 39 - {3: 600}\nClient 40 - {1: 300, 6: 300}\nClient 41 - {6: 300, 7: 300}\nClient 42 - {6: 300, 8: 300}\nClient 43 - {2: 300, 1: 300}\nClient 44 - {5: 17, 6: 283, 8: 300}\nClient 45 - {6: 300, 9: 300}\nClient 46 - {6: 600}\nClient 47 - {4: 600}\nClient 48 - {9: 300, 1: 300}\nClient 49 - {0: 300, 8: 300}\nClient 50 - {2: 300, 5: 300}\nClient 51 - {9: 300, 1: 300}\nClient 52 - {3: 300, 7: 300}\nClient 53 - {4: 300, 7: 300}\nClient 54 - {4: 300, 3: 300}\nClient 55 - {8: 300, 6: 300}\nClient 56 - {7: 300, 0: 300}\nClient 57 - {1: 300, 7: 300}\nClient 58 - {6: 300, 5: 300}\nClient 59 - {5: 300, 4: 300}\nClient 60 - {9: 300, 2: 300}\nClient 61 - {3: 300, 5: 300}\nClient 62 - {2: 300, 8: 300}\nClient 63 - {4: 300, 3: 300}\nClient 64 - {8: 300, 7: 300}\nClient 65 - {8: 300, 0: 300}\nClient 66 - {0: 223, 1: 77, 5: 300}\nClient 67 - {3: 300, 6: 300}\nClient 68 - {8: 300, 7: 300}\nClient 69 - {1: 300, 5: 300}\nClient 70 - {3: 300, 0: 300}\nClient 71 - {9: 300, 8: 300}\nClient 72 - {0: 300, 2: 300}\nClient 73 - {7: 300, 5: 300}\nClient 74 - {4: 300, 5: 300}\nClient 75 - {5: 300, 3: 300}\nClient 76 - {5: 300, 6: 300}\nClient 77 - {2: 300, 7: 200, 8: 100}\nClient 78 - {7: 300, 0: 300}\nClient 79 - {2: 300, 8: 300}\nClient 80 - {8: 300, 1: 300}\nClient 81 - {9: 300, 2: 300}\nClient 82 - {3: 300, 7: 300}\nClient 83 - {1: 300, 0: 300}\nClient 84 - {6: 300, 1: 300}\nClient 85 - {9: 300, 0: 300}\nClient 86 - {5: 300, 2: 300}\nClient 87 - {8: 300, 9: 300}\nClient 88 - {6: 300, 1: 65, 2: 235}\nClient 89 - {0: 300, 7: 300}\nClient 90 - {0: 300, 1: 300}\nClient 91 - {6: 300, 2: 300}\nClient 92 - {8: 300, 7: 300}\nClient 93 - {3: 300, 6: 300}\nClient 94 - {8: 300, 6: 300}\nClient 95 - {2: 300, 3: 300}\nClient 96 - {0: 600}\nClient 97 - {6: 300, 5: 300}\nClient 98 - {9: 300, 4: 296, 5: 4}\nClient 99 - {9: 300, 3: 300}\n","output_type":"stream"}]},{"cell_type":"code","source":"# rounds and target accuracy\nT = 200\ntarget_accuracy = 0.99\n\nstate_dict, accuracies, losses = await execute(server, T, target_accuracy)\n\n# save model to file\ntorch.save(state_dict, \"cnn_state_dict.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjbFmiTb65fT","outputId":"1467fbfb-3b0e-4bb3-bd3d-df056b1cbfaa","execution":{"iopub.status.busy":"2023-05-24T05:04:43.897467Z","iopub.execute_input":"2023-05-24T05:04:43.898423Z","iopub.status.idle":"2023-05-24T05:29:18.677038Z","shell.execute_reply.started":"2023-05-24T05:04:43.898389Z","shell.execute_reply":"2023-05-24T05:29:18.675950Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Round 1/200\nSelected clients - [49, 97, 53, 5, 33, 65, 62, 51, 38, 61]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.2311, Accuracy: 974/10000 (9.74%)\nRound 2/200\nSelected clients - [17, 72, 97, 8, 32, 15, 63, 57, 60, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1873, Accuracy: 5726/10000 (57.26%)\nRound 3/200\nSelected clients - [7, 11, 10, 46, 21, 94, 85, 39, 32, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1405, Accuracy: 5454/10000 (54.54%)\nRound 4/200\nSelected clients - [30, 75, 69, 16, 47, 77, 60, 80, 74, 8]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1015, Accuracy: 7391/10000 (73.91%)\nRound 5/200\nSelected clients - [30, 38, 13, 92, 50, 61, 19, 11, 8, 2]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1141, Accuracy: 6704/10000 (67.04%)\nRound 6/200\nSelected clients - [79, 32, 94, 45, 88, 83, 67, 3, 59, 99]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0645, Accuracy: 8001/10000 (80.01%)\nRound 7/200\nSelected clients - [73, 10, 62, 97, 33, 4, 0, 18, 84, 75]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0692, Accuracy: 7594/10000 (75.94%)\nRound 8/200\nSelected clients - [41, 19, 50, 83, 6, 9, 68, 12, 46, 74]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0421, Accuracy: 8699/10000 (86.99%)\nRound 9/200\nSelected clients - [29, 47, 48, 16, 24, 90, 5, 10, 17, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0416, Accuracy: 8599/10000 (85.99%)\nRound 10/200\nSelected clients - [59, 78, 47, 34, 17, 23, 86, 0, 43, 64]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0316, Accuracy: 9023/10000 (90.23%)\nRound 11/200\nSelected clients - [73, 4, 54, 61, 1, 26, 59, 62, 35, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0351, Accuracy: 8837/10000 (88.37%)\nRound 12/200\nSelected clients - [57, 71, 99, 59, 65, 75, 24, 23, 60, 80]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0343, Accuracy: 9079/10000 (90.79%)\nRound 13/200\nSelected clients - [60, 34, 84, 67, 85, 44, 18, 48, 1, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0275, Accuracy: 9086/10000 (90.86%)\nRound 14/200\nSelected clients - [33, 37, 87, 23, 83, 29, 85, 18, 28, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0235, Accuracy: 9323/10000 (93.23%)\nRound 15/200\nSelected clients - [13, 78, 89, 96, 83, 67, 31, 34, 94, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0227, Accuracy: 9215/10000 (92.15%)\nRound 16/200\nSelected clients - [26, 1, 66, 94, 4, 20, 30, 2, 7, 87]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0403, Accuracy: 8696/10000 (86.96%)\nRound 17/200\nSelected clients - [46, 60, 61, 36, 53, 29, 57, 0, 52, 84]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0171, Accuracy: 9507/10000 (95.07%)\nRound 18/200\nSelected clients - [66, 53, 38, 46, 37, 22, 98, 90, 69, 84]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0259, Accuracy: 9212/10000 (92.12%)\nRound 19/200\nSelected clients - [23, 15, 84, 57, 42, 30, 25, 62, 80, 63]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0195, Accuracy: 9357/10000 (93.57%)\nRound 20/200\nSelected clients - [86, 5, 66, 15, 65, 25, 50, 44, 67, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0197, Accuracy: 9370/10000 (93.70%)\nRound 21/200\nSelected clients - [92, 87, 98, 19, 33, 86, 81, 12, 41, 73]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0169, Accuracy: 9424/10000 (94.24%)\nRound 22/200\nSelected clients - [21, 53, 88, 81, 36, 61, 27, 60, 65, 23]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0123, Accuracy: 9612/10000 (96.12%)\nRound 23/200\nSelected clients - [17, 31, 3, 78, 57, 23, 89, 15, 94, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0115, Accuracy: 9665/10000 (96.65%)\nRound 24/200\nSelected clients - [99, 37, 10, 2, 75, 39, 54, 48, 67, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0188, Accuracy: 9314/10000 (93.14%)\nRound 25/200\nSelected clients - [91, 49, 74, 23, 27, 21, 24, 85, 87, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0131, Accuracy: 9610/10000 (96.10%)\nRound 26/200\nSelected clients - [48, 98, 1, 27, 39, 81, 60, 5, 96, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0164, Accuracy: 9458/10000 (94.58%)\nRound 27/200\nSelected clients - [95, 25, 84, 26, 55, 76, 69, 7, 16, 99]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0106, Accuracy: 9639/10000 (96.39%)\nRound 28/200\nSelected clients - [83, 61, 89, 35, 36, 25, 9, 8, 32, 69]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0116, Accuracy: 9668/10000 (96.68%)\nRound 29/200\nSelected clients - [14, 95, 16, 69, 76, 91, 22, 28, 81, 59]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0148, Accuracy: 9516/10000 (95.16%)\nRound 30/200\nSelected clients - [70, 9, 44, 76, 77, 36, 11, 65, 50, 53]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0091, Accuracy: 9719/10000 (97.19%)\nRound 31/200\nSelected clients - [69, 37, 78, 3, 79, 83, 26, 32, 6, 50]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0102, Accuracy: 9674/10000 (96.74%)\nRound 32/200\nSelected clients - [1, 60, 14, 97, 50, 18, 87, 5, 17, 68]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0144, Accuracy: 9491/10000 (94.91%)\nRound 33/200\nSelected clients - [9, 27, 18, 38, 89, 30, 63, 3, 92, 4]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0089, Accuracy: 9714/10000 (97.14%)\nRound 34/200\nSelected clients - [73, 21, 80, 29, 35, 61, 83, 68, 67, 23]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0093, Accuracy: 9714/10000 (97.14%)\nRound 35/200\nSelected clients - [67, 45, 74, 3, 29, 49, 46, 8, 54, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0081, Accuracy: 9749/10000 (97.49%)\nRound 36/200\nSelected clients - [70, 42, 96, 16, 95, 43, 19, 36, 55, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0081, Accuracy: 9745/10000 (97.45%)\nRound 37/200\nSelected clients - [42, 7, 2, 36, 10, 0, 64, 80, 22, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0092, Accuracy: 9672/10000 (96.72%)\nRound 38/200\nSelected clients - [87, 77, 11, 79, 85, 95, 81, 65, 4, 80]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0151, Accuracy: 9453/10000 (94.53%)\nRound 39/200\nSelected clients - [81, 53, 54, 96, 92, 13, 8, 46, 89, 59]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0063, Accuracy: 9791/10000 (97.91%)\nRound 40/200\nSelected clients - [26, 33, 49, 3, 24, 28, 50, 93, 72, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0076, Accuracy: 9762/10000 (97.62%)\nRound 41/200\nSelected clients - [58, 74, 67, 4, 31, 36, 85, 81, 26, 16]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0085, Accuracy: 9744/10000 (97.44%)\nRound 42/200\nSelected clients - [48, 42, 29, 21, 49, 73, 88, 36, 70, 35]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0064, Accuracy: 9792/10000 (97.92%)\nRound 43/200\nSelected clients - [81, 14, 3, 94, 35, 31, 28, 17, 13, 86]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0092, Accuracy: 9692/10000 (96.92%)\nRound 44/200\nSelected clients - [4, 36, 89, 97, 18, 59, 47, 85, 12, 58]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0066, Accuracy: 9789/10000 (97.89%)\nRound 45/200\nSelected clients - [52, 66, 69, 89, 14, 22, 48, 28, 37, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0079, Accuracy: 9749/10000 (97.49%)\nRound 46/200\nSelected clients - [34, 53, 62, 32, 10, 38, 43, 2, 9, 61]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0075, Accuracy: 9769/10000 (97.69%)\nRound 47/200\nSelected clients - [9, 51, 5, 75, 29, 81, 66, 19, 74, 68]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0065, Accuracy: 9786/10000 (97.86%)\nRound 48/200\nSelected clients - [45, 8, 55, 70, 58, 73, 43, 32, 65, 49]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0063, Accuracy: 9787/10000 (97.87%)\nRound 49/200\nSelected clients - [70, 40, 16, 71, 91, 68, 38, 64, 24, 97]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0077, Accuracy: 9739/10000 (97.39%)\nRound 50/200\nSelected clients - [8, 44, 52, 14, 41, 96, 70, 65, 6, 87]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0074, Accuracy: 9745/10000 (97.45%)\nRound 51/200\nSelected clients - [63, 34, 46, 81, 31, 88, 60, 98, 42, 10]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0063, Accuracy: 9789/10000 (97.89%)\nRound 52/200\nSelected clients - [31, 64, 70, 20, 29, 32, 50, 59, 93, 89]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0053, Accuracy: 9819/10000 (98.19%)\nRound 53/200\nSelected clients - [34, 6, 92, 65, 61, 47, 52, 4, 17, 20]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0071, Accuracy: 9784/10000 (97.84%)\nRound 54/200\nSelected clients - [78, 27, 58, 64, 91, 61, 66, 46, 93, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0060, Accuracy: 9805/10000 (98.05%)\nRound 55/200\nSelected clients - [17, 56, 71, 38, 61, 62, 48, 28, 57, 42]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0056, Accuracy: 9820/10000 (98.20%)\nRound 56/200\nSelected clients - [11, 25, 19, 94, 38, 10, 95, 23, 45, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0058, Accuracy: 9813/10000 (98.13%)\nRound 57/200\nSelected clients - [71, 1, 60, 83, 66, 38, 98, 69, 53, 90]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0089, Accuracy: 9701/10000 (97.01%)\nRound 58/200\nSelected clients - [5, 47, 75, 77, 2, 28, 65, 41, 61, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0059, Accuracy: 9811/10000 (98.11%)\nRound 59/200\nSelected clients - [74, 25, 26, 94, 82, 5, 24, 57, 51, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0066, Accuracy: 9785/10000 (97.85%)\nRound 60/200\nSelected clients - [28, 10, 83, 58, 2, 17, 38, 91, 87, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9846/10000 (98.46%)\nRound 61/200\nSelected clients - [39, 36, 73, 19, 33, 29, 61, 59, 42, 5]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9816/10000 (98.16%)\nRound 62/200\nSelected clients - [63, 23, 71, 27, 41, 37, 88, 3, 62, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0081, Accuracy: 9762/10000 (97.62%)\nRound 63/200\nSelected clients - [73, 22, 8, 30, 59, 39, 85, 45, 21, 65]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0057, Accuracy: 9816/10000 (98.16%)\nRound 64/200\nSelected clients - [56, 37, 32, 61, 84, 11, 49, 95, 10, 9]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9844/10000 (98.44%)\nRound 65/200\nSelected clients - [60, 15, 80, 78, 51, 68, 87, 2, 26, 34]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0053, Accuracy: 9825/10000 (98.25%)\nRound 66/200\nSelected clients - [53, 36, 65, 28, 56, 58, 67, 70, 43, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9836/10000 (98.36%)\nRound 67/200\nSelected clients - [9, 39, 55, 31, 57, 37, 32, 71, 12, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0056, Accuracy: 9804/10000 (98.04%)\nRound 68/200\nSelected clients - [9, 14, 98, 52, 59, 53, 34, 76, 54, 62]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0046, Accuracy: 9844/10000 (98.44%)\nRound 69/200\nSelected clients - [94, 59, 88, 95, 64, 14, 77, 74, 31, 55]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0060, Accuracy: 9789/10000 (97.89%)\nRound 70/200\nSelected clients - [87, 4, 12, 21, 8, 77, 44, 41, 70, 53]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0053, Accuracy: 9815/10000 (98.15%)\nRound 71/200\nSelected clients - [15, 37, 89, 58, 57, 17, 41, 13, 19, 86]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0058, Accuracy: 9795/10000 (97.95%)\nRound 72/200\nSelected clients - [41, 65, 79, 1, 33, 19, 96, 25, 11, 7]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0058, Accuracy: 9803/10000 (98.03%)\nRound 73/200\nSelected clients - [9, 76, 94, 23, 44, 89, 69, 79, 47, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9839/10000 (98.39%)\nRound 74/200\nSelected clients - [35, 15, 64, 61, 72, 23, 59, 38, 75, 9]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0065, Accuracy: 9786/10000 (97.86%)\nRound 75/200\nSelected clients - [78, 65, 14, 40, 15, 39, 23, 27, 44, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0069, Accuracy: 9767/10000 (97.67%)\nRound 76/200\nSelected clients - [57, 74, 55, 58, 5, 93, 98, 65, 86, 85]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0052, Accuracy: 9819/10000 (98.19%)\nRound 77/200\nSelected clients - [47, 59, 49, 25, 38, 6, 53, 30, 36, 96]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0080, Accuracy: 9732/10000 (97.32%)\nRound 78/200\nSelected clients - [32, 41, 25, 30, 24, 14, 37, 60, 71, 78]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9865/10000 (98.65%)\nRound 79/200\nSelected clients - [24, 12, 38, 85, 93, 32, 95, 54, 4, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9818/10000 (98.18%)\nRound 80/200\nSelected clients - [18, 56, 44, 76, 20, 30, 31, 92, 88, 63]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9836/10000 (98.36%)\nRound 81/200\nSelected clients - [34, 50, 69, 90, 53, 47, 46, 68, 51, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9844/10000 (98.44%)\nRound 82/200\nSelected clients - [64, 58, 43, 71, 68, 49, 61, 2, 20, 19]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0053, Accuracy: 9828/10000 (98.28%)\nRound 83/200\nSelected clients - [18, 98, 62, 64, 37, 22, 21, 87, 33, 20]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0063, Accuracy: 9786/10000 (97.86%)\nRound 84/200\nSelected clients - [63, 58, 11, 16, 48, 4, 6, 83, 27, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9823/10000 (98.23%)\nRound 85/200\nSelected clients - [93, 36, 99, 4, 62, 0, 66, 84, 40, 25]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0057, Accuracy: 9814/10000 (98.14%)\nRound 86/200\nSelected clients - [25, 89, 78, 13, 41, 24, 28, 59, 99, 98]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9822/10000 (98.22%)\nRound 87/200\nSelected clients - [99, 3, 71, 40, 95, 1, 98, 8, 90, 64]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9823/10000 (98.23%)\nRound 88/200\nSelected clients - [18, 94, 24, 69, 13, 35, 96, 42, 82, 90]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9853/10000 (98.53%)\nRound 89/200\nSelected clients - [50, 24, 42, 23, 80, 1, 67, 98, 89, 43]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0050, Accuracy: 9839/10000 (98.39%)\nRound 90/200\nSelected clients - [10, 98, 77, 90, 33, 17, 44, 8, 19, 53]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9856/10000 (98.56%)\nRound 91/200\nSelected clients - [26, 91, 11, 61, 84, 73, 75, 39, 81, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0058, Accuracy: 9803/10000 (98.03%)\nRound 92/200\nSelected clients - [10, 75, 22, 87, 86, 20, 51, 58, 95, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9854/10000 (98.54%)\nRound 93/200\nSelected clients - [53, 66, 72, 70, 71, 75, 34, 86, 97, 12]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9845/10000 (98.45%)\nRound 94/200\nSelected clients - [63, 72, 92, 45, 14, 11, 18, 22, 50, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9862/10000 (98.62%)\nRound 95/200\nSelected clients - [69, 23, 15, 35, 38, 55, 2, 87, 63, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0049, Accuracy: 9845/10000 (98.45%)\nRound 96/200\nSelected clients - [97, 68, 65, 94, 69, 16, 63, 3, 17, 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9872/10000 (98.72%)\nRound 97/200\nSelected clients - [47, 40, 86, 50, 26, 12, 43, 97, 5, 89]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0051, Accuracy: 9829/10000 (98.29%)\nRound 98/200\nSelected clients - [24, 54, 47, 6, 73, 2, 71, 99, 5, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9872/10000 (98.72%)\nRound 99/200\nSelected clients - [45, 73, 5, 53, 7, 60, 36, 93, 86, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9877/10000 (98.77%)\nRound 100/200\nSelected clients - [51, 48, 25, 76, 22, 29, 31, 17, 97, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0056, Accuracy: 9825/10000 (98.25%)\nRound 101/200\nSelected clients - [18, 58, 98, 22, 90, 50, 93, 44, 55, 64]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9857/10000 (98.57%)\nRound 102/200\nSelected clients - [74, 24, 69, 45, 59, 6, 84, 64, 27, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0049, Accuracy: 9837/10000 (98.37%)\nRound 103/200\nSelected clients - [18, 86, 78, 45, 21, 70, 91, 84, 77, 23]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9867/10000 (98.67%)\nRound 104/200\nSelected clients - [91, 58, 92, 89, 94, 27, 88, 9, 77, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9861/10000 (98.61%)\nRound 105/200\nSelected clients - [2, 25, 93, 98, 29, 50, 42, 0, 91, 16]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9864/10000 (98.64%)\nRound 106/200\nSelected clients - [75, 44, 74, 13, 0, 39, 67, 98, 73, 42]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0062, Accuracy: 9803/10000 (98.03%)\nRound 107/200\nSelected clients - [90, 61, 2, 71, 67, 60, 7, 33, 8, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0051, Accuracy: 9832/10000 (98.32%)\nRound 108/200\nSelected clients - [31, 79, 74, 98, 93, 84, 54, 61, 97, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0050, Accuracy: 9836/10000 (98.36%)\nRound 109/200\nSelected clients - [16, 91, 10, 84, 49, 93, 35, 48, 25, 38]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9852/10000 (98.52%)\nRound 110/200\nSelected clients - [35, 29, 58, 57, 70, 7, 12, 64, 63, 38]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0046, Accuracy: 9857/10000 (98.57%)\nRound 111/200\nSelected clients - [49, 76, 31, 52, 61, 91, 35, 81, 69, 88]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9870/10000 (98.70%)\nRound 112/200\nSelected clients - [27, 40, 63, 24, 50, 53, 78, 21, 80, 89]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9853/10000 (98.53%)\nRound 113/200\nSelected clients - [61, 85, 74, 79, 38, 89, 59, 53, 96, 84]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9847/10000 (98.47%)\nRound 114/200\nSelected clients - [3, 83, 92, 35, 2, 61, 70, 44, 30, 55]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9849/10000 (98.49%)\nRound 115/200\nSelected clients - [30, 72, 12, 43, 85, 31, 80, 79, 6, 19]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9862/10000 (98.62%)\nRound 116/200\nSelected clients - [36, 25, 99, 14, 68, 42, 96, 70, 37, 86]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9860/10000 (98.60%)\nRound 117/200\nSelected clients - [95, 76, 69, 92, 38, 1, 96, 82, 15, 94]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9859/10000 (98.59%)\nRound 118/200\nSelected clients - [30, 23, 21, 26, 51, 20, 71, 52, 89, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9823/10000 (98.23%)\nRound 119/200\nSelected clients - [91, 80, 23, 39, 12, 89, 46, 37, 98, 2]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9875/10000 (98.75%)\nRound 120/200\nSelected clients - [36, 23, 94, 68, 85, 96, 70, 55, 13, 10]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9854/10000 (98.54%)\nRound 121/200\nSelected clients - [65, 31, 24, 81, 93, 75, 85, 59, 11, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9856/10000 (98.56%)\nRound 122/200\nSelected clients - [11, 27, 74, 50, 80, 22, 78, 66, 42, 36]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9849/10000 (98.49%)\nRound 123/200\nSelected clients - [65, 27, 76, 38, 9, 93, 46, 97, 28, 58]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9865/10000 (98.65%)\nRound 124/200\nSelected clients - [6, 34, 11, 98, 52, 13, 4, 48, 68, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0055, Accuracy: 9815/10000 (98.15%)\nRound 125/200\nSelected clients - [35, 70, 0, 22, 7, 53, 46, 4, 40, 21]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0049, Accuracy: 9841/10000 (98.41%)\nRound 126/200\nSelected clients - [31, 28, 76, 38, 72, 94, 23, 44, 19, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9875/10000 (98.75%)\nRound 127/200\nSelected clients - [73, 7, 76, 58, 31, 82, 22, 60, 29, 20]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9861/10000 (98.61%)\nRound 128/200\nSelected clients - [5, 79, 74, 72, 12, 3, 34, 25, 52, 29]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9889/10000 (98.89%)\nRound 129/200\nSelected clients - [30, 51, 65, 46, 17, 61, 3, 19, 40, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9877/10000 (98.77%)\nRound 130/200\nSelected clients - [75, 66, 34, 5, 88, 51, 80, 28, 42, 29]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9873/10000 (98.73%)\nRound 131/200\nSelected clients - [66, 54, 34, 94, 84, 56, 82, 58, 2, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9875/10000 (98.75%)\nRound 132/200\nSelected clients - [40, 47, 98, 65, 11, 50, 36, 2, 49, 99]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9876/10000 (98.76%)\nRound 133/200\nSelected clients - [52, 19, 7, 21, 5, 39, 15, 99, 69, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9817/10000 (98.17%)\nRound 134/200\nSelected clients - [63, 45, 61, 41, 98, 78, 43, 69, 88, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9884/10000 (98.84%)\nRound 135/200\nSelected clients - [61, 66, 25, 92, 71, 95, 81, 16, 3, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9874/10000 (98.74%)\nRound 136/200\nSelected clients - [85, 47, 80, 82, 74, 35, 62, 37, 90, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9881/10000 (98.81%)\nRound 137/200\nSelected clients - [73, 54, 67, 7, 55, 63, 97, 25, 89, 17]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9875/10000 (98.75%)\nRound 138/200\nSelected clients - [9, 23, 52, 41, 24, 29, 62, 44, 1, 51]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9889/10000 (98.89%)\nRound 139/200\nSelected clients - [24, 48, 57, 89, 38, 26, 66, 34, 31, 23]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9865/10000 (98.65%)\nRound 140/200\nSelected clients - [0, 88, 78, 68, 77, 84, 38, 95, 70, 67]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9865/10000 (98.65%)\nRound 141/200\nSelected clients - [98, 12, 3, 34, 2, 68, 93, 6, 86, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9872/10000 (98.72%)\nRound 142/200\nSelected clients - [66, 99, 3, 74, 60, 22, 73, 89, 59, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9887/10000 (98.87%)\nRound 143/200\nSelected clients - [74, 88, 87, 81, 62, 21, 36, 44, 45, 33]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9888/10000 (98.88%)\nRound 144/200\nSelected clients - [23, 5, 2, 28, 18, 31, 10, 93, 52, 63]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9855/10000 (98.55%)\nRound 145/200\nSelected clients - [57, 4, 58, 10, 92, 21, 50, 11, 84, 52]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9883/10000 (98.83%)\nRound 146/200\nSelected clients - [96, 54, 66, 0, 56, 3, 84, 41, 93, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9869/10000 (98.69%)\nRound 147/200\nSelected clients - [17, 79, 42, 98, 8, 20, 72, 36, 10, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9873/10000 (98.73%)\nRound 148/200\nSelected clients - [77, 82, 19, 50, 56, 78, 57, 23, 80, 94]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9889/10000 (98.89%)\nRound 149/200\nSelected clients - [51, 89, 81, 4, 86, 44, 36, 34, 13, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9880/10000 (98.80%)\nRound 150/200\nSelected clients - [9, 12, 32, 48, 17, 7, 2, 22, 73, 5]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9882/10000 (98.82%)\nRound 151/200\nSelected clients - [41, 51, 24, 29, 38, 61, 18, 20, 53, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9890/10000 (98.90%)\nRound 152/200\nSelected clients - [90, 52, 91, 80, 92, 26, 45, 36, 47, 73]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9883/10000 (98.83%)\nRound 153/200\nSelected clients - [96, 50, 80, 18, 48, 25, 11, 79, 2, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9887/10000 (98.87%)\nRound 154/200\nSelected clients - [62, 9, 4, 33, 90, 53, 74, 72, 76, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9877/10000 (98.77%)\nRound 155/200\nSelected clients - [26, 48, 62, 56, 65, 0, 57, 33, 50, 54]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9856/10000 (98.56%)\nRound 156/200\nSelected clients - [74, 64, 69, 36, 87, 99, 53, 68, 35, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9878/10000 (98.78%)\nRound 157/200\nSelected clients - [62, 53, 94, 31, 98, 45, 19, 28, 20, 17]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9878/10000 (98.78%)\nRound 158/200\nSelected clients - [78, 62, 28, 20, 2, 3, 44, 29, 40, 17]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9885/10000 (98.85%)\nRound 159/200\nSelected clients - [87, 28, 13, 7, 53, 72, 98, 42, 97, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9869/10000 (98.69%)\nRound 160/200\nSelected clients - [50, 21, 86, 57, 31, 66, 25, 79, 24, 2]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9835/10000 (98.35%)\nRound 161/200\nSelected clients - [15, 64, 43, 51, 22, 75, 44, 91, 66, 63]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9885/10000 (98.85%)\nRound 162/200\nSelected clients - [66, 26, 70, 21, 29, 81, 75, 61, 4, 96]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9862/10000 (98.62%)\nRound 163/200\nSelected clients - [6, 88, 80, 26, 64, 25, 52, 63, 98, 78]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9863/10000 (98.63%)\nRound 164/200\nSelected clients - [69, 79, 58, 74, 22, 63, 36, 27, 45, 26]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9877/10000 (98.77%)\nRound 165/200\nSelected clients - [12, 94, 38, 32, 59, 62, 77, 49, 15, 10]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9879/10000 (98.79%)\nRound 166/200\nSelected clients - [2, 7, 91, 55, 9, 63, 29, 22, 54, 86]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9866/10000 (98.66%)\nRound 167/200\nSelected clients - [22, 80, 77, 52, 54, 1, 41, 4, 62, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9870/10000 (98.70%)\nRound 168/200\nSelected clients - [29, 11, 42, 54, 41, 98, 94, 92, 10, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9882/10000 (98.82%)\nRound 169/200\nSelected clients - [95, 14, 66, 47, 48, 23, 28, 68, 24, 25]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9879/10000 (98.79%)\nRound 170/200\nSelected clients - [32, 66, 79, 22, 71, 65, 15, 67, 44, 96]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9884/10000 (98.84%)\nRound 171/200\nSelected clients - [44, 75, 40, 11, 31, 41, 33, 74, 15, 27]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9895/10000 (98.95%)\nRound 172/200\nSelected clients - [71, 49, 52, 15, 75, 59, 86, 22, 48, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9856/10000 (98.56%)\nRound 173/200\nSelected clients - [45, 24, 27, 38, 94, 6, 50, 59, 71, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9894/10000 (98.94%)\nRound 174/200\nSelected clients - [41, 62, 85, 99, 92, 65, 76, 46, 31, 52]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9888/10000 (98.88%)\nRound 175/200\nSelected clients - [0, 56, 3, 63, 46, 8, 28, 30, 13, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9874/10000 (98.74%)\nRound 176/200\nSelected clients - [56, 30, 6, 92, 73, 88, 64, 24, 32, 76]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9884/10000 (98.84%)\nRound 177/200\nSelected clients - [3, 7, 98, 28, 99, 14, 49, 81, 40, 80]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9890/10000 (98.90%)\nRound 178/200\nSelected clients - [27, 63, 53, 74, 24, 90, 51, 5, 54, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9853/10000 (98.53%)\nRound 179/200\nSelected clients - [14, 71, 59, 82, 30, 96, 43, 93, 61, 36]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9846/10000 (98.46%)\nRound 180/200\nSelected clients - [25, 15, 8, 7, 66, 38, 56, 6, 74, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9859/10000 (98.59%)\nRound 181/200\nSelected clients - [18, 10, 86, 1, 79, 33, 15, 75, 64, 57]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9879/10000 (98.79%)\nRound 182/200\nSelected clients - [74, 89, 13, 7, 42, 43, 24, 96, 39, 29]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9873/10000 (98.73%)\nRound 183/200\nSelected clients - [57, 45, 29, 40, 44, 36, 9, 91, 34, 4]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9885/10000 (98.85%)\nRound 184/200\nSelected clients - [13, 11, 95, 0, 45, 38, 28, 66, 1, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9878/10000 (98.78%)\nRound 185/200\nSelected clients - [35, 0, 30, 88, 89, 41, 42, 43, 92, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9894/10000 (98.94%)\nRound 186/200\nSelected clients - [14, 19, 38, 75, 62, 60, 95, 51, 22, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9896/10000 (98.96%)\nRound 187/200\nSelected clients - [43, 84, 53, 70, 98, 57, 13, 60, 87, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9876/10000 (98.76%)\nRound 188/200\nSelected clients - [44, 60, 75, 19, 74, 3, 70, 31, 63, 94]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9898/10000 (98.98%)\nRound 189/200\nSelected clients - [90, 28, 33, 0, 30, 9, 88, 34, 50, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9877/10000 (98.77%)\nRound 190/200\nSelected clients - [61, 95, 35, 18, 73, 70, 14, 51, 94, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9882/10000 (98.82%)\nRound 191/200\nSelected clients - [9, 21, 96, 42, 47, 26, 28, 60, 50, 19]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9877/10000 (98.77%)\nRound 192/200\nSelected clients - [97, 67, 70, 65, 64, 18, 98, 51, 81, 89]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9893/10000 (98.93%)\nRound 193/200\nSelected clients - [47, 38, 11, 59, 39, 54, 42, 35, 87, 29]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9871/10000 (98.71%)\nRound 194/200\nSelected clients - [71, 59, 97, 22, 38, 34, 67, 28, 3, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9872/10000 (98.72%)\nRound 195/200\nSelected clients - [77, 8, 74, 19, 45, 49, 32, 94, 55, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9889/10000 (98.89%)\nRound 196/200\nSelected clients - [76, 50, 5, 82, 25, 86, 26, 10, 38, 91]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9883/10000 (98.83%)\nRound 197/200\nSelected clients - [83, 64, 91, 3, 26, 98, 54, 84, 82, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9882/10000 (98.82%)\nRound 198/200\nSelected clients - [69, 1, 16, 20, 2, 88, 24, 74, 15, 5]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9900/10000 (99.00%)\nRound 199/200\nSelected clients - [6, 73, 91, 61, 12, 85, 95, 58, 67, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9885/10000 (98.85%)\nRound 200/200\nSelected clients - [44, 95, 50, 35, 85, 91, 39, 1, 61, 88]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:04<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9891/10000 (98.91%)\nTarget accuracy reached at round: 198\nBest round: 198, accuracy: 0.99\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Statistics","metadata":{"id":"VIENpKmy65fT"}},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(accuracies)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Um5mHx2E65fT","outputId":"3be8cfe8-3876-4205-bdbd-aebf5b2bed9f","execution":{"iopub.status.busy":"2023-05-24T05:29:18.678717Z","iopub.execute_input":"2023-05-24T05:29:18.679092Z","iopub.status.idle":"2023-05-24T05:29:18.685955Z","shell.execute_reply.started":"2023-05-24T05:29:18.679058Z","shell.execute_reply":"2023-05-24T05:29:18.683436Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[0.0974, 0.5726, 0.5454, 0.7391, 0.6704, 0.8001, 0.7594, 0.8699, 0.8599, 0.9023, 0.8837, 0.9079, 0.9086, 0.9323, 0.9215, 0.8696, 0.9507, 0.9212, 0.9357, 0.937, 0.9424, 0.9612, 0.9665, 0.9314, 0.961, 0.9458, 0.9639, 0.9668, 0.9516, 0.9719, 0.9674, 0.9491, 0.9714, 0.9714, 0.9749, 0.9745, 0.9672, 0.9453, 0.9791, 0.9762, 0.9744, 0.9792, 0.9692, 0.9789, 0.9749, 0.9769, 0.9786, 0.9787, 0.9739, 0.9745, 0.9789, 0.9819, 0.9784, 0.9805, 0.982, 0.9813, 0.9701, 0.9811, 0.9785, 0.9846, 0.9816, 0.9762, 0.9816, 0.9844, 0.9825, 0.9836, 0.9804, 0.9844, 0.9789, 0.9815, 0.9795, 0.9803, 0.9839, 0.9786, 0.9767, 0.9819, 0.9732, 0.9865, 0.9818, 0.9836, 0.9844, 0.9828, 0.9786, 0.9823, 0.9814, 0.9822, 0.9823, 0.9853, 0.9839, 0.9856, 0.9803, 0.9854, 0.9845, 0.9862, 0.9845, 0.9872, 0.9829, 0.9872, 0.9877, 0.9825, 0.9857, 0.9837, 0.9867, 0.9861, 0.9864, 0.9803, 0.9832, 0.9836, 0.9852, 0.9857, 0.987, 0.9853, 0.9847, 0.9849, 0.9862, 0.986, 0.9859, 0.9823, 0.9875, 0.9854, 0.9856, 0.9849, 0.9865, 0.9815, 0.9841, 0.9875, 0.9861, 0.9889, 0.9877, 0.9873, 0.9875, 0.9876, 0.9817, 0.9884, 0.9874, 0.9881, 0.9875, 0.9889, 0.9865, 0.9865, 0.9872, 0.9887, 0.9888, 0.9855, 0.9883, 0.9869, 0.9873, 0.9889, 0.988, 0.9882, 0.989, 0.9883, 0.9887, 0.9877, 0.9856, 0.9878, 0.9878, 0.9885, 0.9869, 0.9835, 0.9885, 0.9862, 0.9863, 0.9877, 0.9879, 0.9866, 0.987, 0.9882, 0.9879, 0.9884, 0.9895, 0.9856, 0.9894, 0.9888, 0.9874, 0.9884, 0.989, 0.9853, 0.9846, 0.9859, 0.9879, 0.9873, 0.9885, 0.9878, 0.9894, 0.9896, 0.9876, 0.9898, 0.9877, 0.9882, 0.9877, 0.9893, 0.9871, 0.9872, 0.9889, 0.9883, 0.9882, 0.99, 0.9885, 0.9891]\n","output_type":"stream"}]},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(losses)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfI_uBW-65fU","outputId":"938c6c2f-03c1-4a42-9ee7-e32cd9ad093b","execution":{"iopub.status.busy":"2023-05-24T05:29:18.687209Z","iopub.execute_input":"2023-05-24T05:29:18.690224Z","iopub.status.idle":"2023-05-24T05:29:18.698487Z","shell.execute_reply.started":"2023-05-24T05:29:18.690129Z","shell.execute_reply":"2023-05-24T05:29:18.697608Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[0.2311424460887909, 0.18730347414016724, 0.1405250855088234, 0.10150677332282067, 0.11408863059878349, 0.06446228877678513, 0.06918851526752114, 0.04211759332306683, 0.04160133952284232, 0.03156893116300925, 0.03514001762578264, 0.03428461813349277, 0.027528324537561277, 0.023457078901911153, 0.022657951881038026, 0.040346624949015676, 0.01709173075980507, 0.025884592844499274, 0.01947968334313773, 0.019697727041551844, 0.016872550536884228, 0.012298417548829457, 0.011507565460324986, 0.018751244226057315, 0.013086406278086361, 0.01641024889734108, 0.0106304901698677, 0.011592283427296207, 0.01477238867302658, 0.009064183244056766, 0.01022743644916918, 0.014399763997033006, 0.008866245485744731, 0.009252524172376434, 0.008085121285343484, 0.008126549231195532, 0.009227270716085331, 0.015066107492853916, 0.006345789253623298, 0.007583398381988082, 0.008494149857597222, 0.006353955176887393, 0.00923383476887684, 0.0065719788627975504, 0.007897144236559506, 0.0074735393110870975, 0.006526162329212093, 0.006339539940648683, 0.0076512592322469574, 0.0074086687020495446, 0.006281296636823754, 0.005321917044538168, 0.007125980020052521, 0.005996595177915879, 0.005613674959441414, 0.0058070935033665595, 0.008920088933772422, 0.005939564455448272, 0.006618530980443461, 0.0046881418051454606, 0.005438690417037742, 0.008099717049158062, 0.005656408005062258, 0.004817700818565481, 0.005343348689069808, 0.004675334305628349, 0.0056054077917309765, 0.00462755924711173, 0.006048700759472536, 0.0052568266230260405, 0.005816875193795022, 0.00577353878171416, 0.004461963436337646, 0.006531945440417076, 0.006852839042330493, 0.005220830758197917, 0.008003334034990076, 0.004161067809414135, 0.0053812058902087305, 0.00484073540657073, 0.004807146255501857, 0.005313278471664308, 0.006312120139018498, 0.005351179768437942, 0.005721173975817237, 0.005408500549884047, 0.0053903558832258565, 0.00431622594033397, 0.004988743405620926, 0.004393885573071248, 0.0057673199945531455, 0.004346715968755052, 0.004305109784725119, 0.004182263395305381, 0.004884535239206616, 0.0038743191255304283, 0.0050991943466989825, 0.003889104308458104, 0.0036504741330168145, 0.005633002533539547, 0.004482014460952269, 0.00487491482030182, 0.004199645899895677, 0.004417262189810828, 0.004031381801905354, 0.006177223444293304, 0.005136303657590247, 0.0050221192226731545, 0.0048314577256431505, 0.004560092081130301, 0.003877015180945898, 0.004756484489280143, 0.0048420363590727, 0.00433370983348558, 0.0041438234405064235, 0.004273176817045725, 0.004141666868893037, 0.005425140111548626, 0.0038408640695265033, 0.004192398863005315, 0.004217261708907699, 0.004513093680591226, 0.004031222758256706, 0.005473056700565758, 0.0049141294203443354, 0.003780508524269226, 0.0040082884436192755, 0.003704362346584122, 0.0036540289174185545, 0.0037813583845333594, 0.0036538448683125124, 0.003645509580009514, 0.005390561938688188, 0.0034176546670628624, 0.003764377521614601, 0.003600871266569936, 0.0036853171036719343, 0.0033599974275065675, 0.004429774040657188, 0.00435665549736666, 0.0038343162394235747, 0.0034269574768742415, 0.0034833400143498864, 0.004230673407839961, 0.004090994624762921, 0.004086783948574246, 0.003804390303184172, 0.003438756752860026, 0.003517884728233162, 0.0033916690827635277, 0.0035769665464697384, 0.0035460696492476905, 0.003583048018261247, 0.003966596165244712, 0.004682839830350162, 0.003982346088117283, 0.003936673701571421, 0.0035609896800156476, 0.004248261849268184, 0.005430168046718552, 0.0034710946517640387, 0.004336287324252349, 0.004161373874877392, 0.0038289112135042416, 0.0037524865360841118, 0.0039030455344730313, 0.003662518827788995, 0.0036201495815872784, 0.0034910918081887117, 0.003273983036464037, 0.0035990016585773416, 0.004201785609692496, 0.0035014423467108983, 0.0033247864395918626, 0.00376995385543283, 0.003969375273942917, 0.003283055702672249, 0.004465268836017181, 0.004658738108412288, 0.0044500662868509405, 0.0040069931182491764, 0.003792978858017517, 0.0037059320617663237, 0.0035773698096450523, 0.0032281718523750513, 0.0033881064396575036, 0.0033440402688267343, 0.0032822248457956547, 0.003909935494508143, 0.003657459194529029, 0.003807633433928866, 0.003302993583058403, 0.0036724725886447145, 0.003783445001092079, 0.003426996467213016, 0.003572571439913424, 0.0034208149449182867, 0.003327683109820135, 0.0037373708940654053, 0.0035431134896845356]\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(accuracies)\nplt.title('Test Accuracy')\nplt.xlabel('Rounds')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.grid(True)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"mTQI9WGZ65fU","outputId":"7e81e0a0-ba97-460f-d980-bd2f5d4fb4d5","execution":{"iopub.status.busy":"2023-05-24T05:29:18.699560Z","iopub.execute_input":"2023-05-24T05:29:18.700064Z","iopub.status.idle":"2023-05-24T05:29:18.937492Z","shell.execute_reply.started":"2023-05-24T05:29:18.700031Z","shell.execute_reply":"2023-05-24T05:29:18.936633Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}