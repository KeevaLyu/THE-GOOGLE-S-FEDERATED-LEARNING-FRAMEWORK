{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"a5e36ac6a21e329c2cec267b08e4f28884519c7e5682f29504bd17199cc3d203"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library","metadata":{"id":"NsvvFSId2xB6"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nimport numpy as np\nimport random\nfrom collections import OrderedDict, ChainMap, Counter\nfrom tqdm.asyncio import tqdm\nimport math\nimport matplotlib.pyplot as plt\n\n# for reproducible results\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\ndevice = torch.device('cpu')\n# gpu\nif torch.backends.mps.is_available():\n    device = torch.device('mps')\nelif torch.cuda.is_available():\n    device = torch.device('cuda:0')\nprint(device)","metadata":{"id":"vDaWQfJ022KB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51b40344-98b9-44f0-ce98-b67d8e6c23bc","execution":{"iopub.status.busy":"2023-05-24T14:29:37.700610Z","iopub.execute_input":"2023-05-24T14:29:37.700988Z","iopub.status.idle":"2023-05-24T14:29:37.710020Z","shell.execute_reply.started":"2023-05-24T14:29:37.700959Z","shell.execute_reply":"2023-05-24T14:29:37.708792Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data processing","metadata":{"id":"t_RCPBAVzB9L"}},{"cell_type":"code","source":"transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))]) # scale from [0,255] to [0,1] and make mean and std to 0.0 and 1.0 respectively\ntraining_dataset = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)","metadata":{"id":"GrvHYZ_swCAM","execution":{"iopub.status.busy":"2023-05-24T14:29:37.712372Z","iopub.execute_input":"2023-05-24T14:29:37.713120Z","iopub.status.idle":"2023-05-24T14:29:37.795150Z","shell.execute_reply.started":"2023-05-24T14:29:37.713087Z","shell.execute_reply":"2023-05-24T14:29:37.794173Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# sort by labels\nsorted_indices = torch.argsort(torch.Tensor(training_dataset.targets))\nsorted_training_dataset = torch.utils.data.Subset(training_dataset, sorted_indices)\n\n# partition data into shards\ndef prepare_datashards(num_clients, num_shards, strict=False):\n    training_datashards = []\n\n    shards = []\n    # partition by class\n    if strict:\n        number_of_classes = len(sorted_training_dataset.dataset.classes)\n        shards_per_class = num_shards // number_of_classes\n\n        ptr = 0\n        # for each class\n        for label, size in sorted(Counter(sorted_training_dataset.dataset.targets.tolist()).items()):\n            shard_size = math.ceil(size / shards_per_class)\n\n            # for each shard\n            for i in range(shards_per_class):\n                shard = []\n                # fill shard of shard_size\n                for j in range(shard_size):\n                    shard.append(sorted_training_dataset[ptr])\n                    ptr += 1\n                    # break for next class\n                    if ptr >= len(sorted_training_dataset) or sorted_training_dataset[ptr][1] != label:\n                        break\n                shards.append(shard)\n\n    # partition by size\n    else:\n        shard_size = len(sorted_training_dataset) // num_shards\n\n        # for each shard\n        for i in range(num_shards):\n            shard = []\n            # fill shard of shard_size\n            for j in range(shard_size):\n                shard.append(sorted_training_dataset[i * shard_size + j])\n            shards.append(shard)\n    \n    # shuffled shard ids\n    random.seed(seed)\n    shard_ids = random.sample(list(range(num_shards)), num_shards)\n    print(\"Shards order - {}\".format(shard_ids))\n\n    # for each client\n    for k in range(num_clients):\n        client_shards = []\n        # number of shards per client\n        shards_per_client = num_shards // num_clients\n        for s in range(shards_per_client):\n            id = shard_ids[k * shards_per_client + s]\n            client_shards.append(shards[id])\n        training_datashards.append(client_shards)\n\n    return training_datashards","metadata":{"id":"ZohHDK7o65fH","execution":{"iopub.status.busy":"2023-05-24T14:29:37.797094Z","iopub.execute_input":"2023-05-24T14:29:37.797501Z","iopub.status.idle":"2023-05-24T14:29:37.817687Z","shell.execute_reply.started":"2023-05-24T14:29:37.797440Z","shell.execute_reply":"2023-05-24T14:29:37.816655Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Global","metadata":{"id":"mamL4quE65fI"}},{"cell_type":"code","source":"# clients training mode\nPARALLEL_TRAINING = True\n\n# clients and shards\nnum_clients = 100\nnum_shards = 200\n\n# prepare training data\ntraining_datashards = prepare_datashards(num_clients, num_shards)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPNbLHz865fI","outputId":"80b1bb83-032c-416d-c78d-c1fc8b9442f2","execution":{"iopub.status.busy":"2023-05-24T14:29:37.821574Z","iopub.execute_input":"2023-05-24T14:29:37.821896Z","iopub.status.idle":"2023-05-24T14:29:50.044467Z","shell.execute_reply.started":"2023-05-24T14:29:37.821868Z","shell.execute_reply":"2023-05-24T14:29:50.043472Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Shards order - [163, 28, 6, 189, 70, 62, 57, 35, 188, 26, 173, 139, 22, 151, 108, 8, 7, 23, 55, 59, 129, 154, 197, 143, 50, 166, 191, 107, 56, 114, 150, 71, 1, 40, 185, 87, 168, 39, 181, 86, 190, 182, 97, 24, 91, 88, 67, 11, 117, 137, 31, 96, 20, 141, 75, 92, 49, 17, 152, 58, 74, 147, 180, 25, 157, 199, 116, 93, 41, 94, 90, 53, 68, 89, 119, 164, 82, 9, 77, 81, 21, 127, 132, 149, 138, 169, 48, 34, 120, 178, 134, 198, 124, 131, 98, 99, 183, 29, 4, 174, 51, 112, 184, 27, 72, 155, 100, 148, 83, 63, 175, 123, 140, 18, 33, 142, 133, 109, 118, 85, 196, 54, 79, 104, 46, 165, 84, 65, 179, 146, 177, 14, 19, 115, 78, 135, 176, 156, 38, 102, 80, 16, 192, 161, 0, 43, 145, 103, 95, 105, 113, 73, 106, 125, 52, 160, 144, 10, 60, 171, 172, 32, 195, 61, 69, 153, 36, 12, 122, 37, 194, 5, 110, 47, 162, 186, 126, 42, 15, 159, 3, 30, 130, 45, 167, 158, 76, 128, 170, 136, 44, 64, 2, 13, 121, 111, 193, 101, 187, 66]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"e6vzuzLL1cP8"}},{"cell_type":"code","source":"class CNN(nn.Module):\n    # https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html#specify-how-data-will-pass-through-your-model\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 5x5 convolution layer with 32 channels\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same')\n        # 5x5 convolution layer with 64 channels\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same')\n        # fully connected layer with 512 units, in_features = channels * height * width from conv2\n        self.fc1 = nn.Linear(in_features=64*7*7, out_features=512)\n        self.fc2 = nn.Linear(in_features=512, out_features=10)\n\n    # x represents our data\n    def forward(self, x):\n        # Pass data through conv1\n        x = self.conv1(x)\n        # Use the rectified-linear activation function over x\n        x = F.relu(x)\n        # Run max pooling over x\n        x = F.max_pool2d(x, kernel_size=2)\n        \n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n\n        # Flatten x with start_dim=1\n        x = torch.flatten(x, start_dim=1)\n        # Pass data through fc1\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n\n        # Apply softmax to x\n        output = F.log_softmax(x, dim=1)\n        return output","metadata":{"id":"4KIxpXNR1dWg","execution":{"iopub.status.busy":"2023-05-24T14:29:50.047787Z","iopub.execute_input":"2023-05-24T14:29:50.048396Z","iopub.status.idle":"2023-05-24T14:29:50.058380Z","shell.execute_reply.started":"2023-05-24T14:29:50.048360Z","shell.execute_reply":"2023-05-24T14:29:50.057480Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_params = sum(p.numel() for p in CNN().parameters())\nprint(\"Total number of parameters:\", num_params)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLzdTLYt65fJ","outputId":"3f1223fb-5b0b-43c0-e35b-eab69d11a45c","execution":{"iopub.status.busy":"2023-05-24T14:29:50.059844Z","iopub.execute_input":"2023-05-24T14:29:50.060199Z","iopub.status.idle":"2023-05-24T14:29:50.091034Z","shell.execute_reply.started":"2023-05-24T14:29:50.060155Z","shell.execute_reply":"2023-05-24T14:29:50.090097Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Total number of parameters: 1663370\n","output_type":"stream"}]},{"cell_type":"code","source":"for p in CNN().parameters():\n    print(p.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY3Pl12PP4rP","outputId":"5c6d2ae1-1831-4068-d3a8-3ed4ae5e1cd8","execution":{"iopub.status.busy":"2023-05-24T14:29:50.092145Z","iopub.execute_input":"2023-05-24T14:29:50.093662Z","iopub.status.idle":"2023-05-24T14:29:50.114275Z","shell.execute_reply.started":"2023-05-24T14:29:50.093629Z","shell.execute_reply":"2023-05-24T14:29:50.113300Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([32, 1, 5, 5])\ntorch.Size([32])\ntorch.Size([64, 32, 5, 5])\ntorch.Size([64])\ntorch.Size([512, 3136])\ntorch.Size([512])\ntorch.Size([10, 512])\ntorch.Size([10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Client\n","metadata":{"id":"RtdxFdsz1h0m"}},{"cell_type":"code","source":"class Client():\n    def __init__(self, k, model, args):\n        # inititalize client\n        self.id = k\n        self.model = model\n        self.args = args\n\n        # load dataset\n        self.dataset = []\n        self._load_dataset(k)\n        self.training_loader = torch.utils.data.DataLoader(self.dataset, batch_size=self.args['B'], shuffle=True)\n\n        # state_dict\n        self.state_dict = self.model.state_dict()\n\n    def _load_dataset(self, k):\n        # load dataset\n        for shard in training_datashards[k]:\n            self.dataset += shard\n        return\n\n    def labels(self):\n        return dict(Counter(data[1] for data in self.dataset))\n\n    def size(self):\n        return len(self.dataset)\n\n    async def update(self):\n        # load state_dict\n        self.model.load_state_dict(self.state_dict)\n\n        # Sets the module in training mode\n        self.model.train(True)\n\n        optimizer = optim.SGD(self.model.parameters(), lr=self.args['lr'])\n        loss_fn = nn.CrossEntropyLoss()\n\n        # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n        for epoch in range(self.args['E']):\n            for inputs, labels in self.training_loader:\n                # Every data instance is an input + label pair\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                # Zero your gradients for every batch!\n                optimizer.zero_grad()\n\n                # Make predictions for this batch\n                outputs = self.model(inputs)\n\n                # Compute the loss and its gradients\n                loss = loss_fn(outputs, labels)\n                loss.backward()\n\n                # Adjust learning weights\n                optimizer.step()\n        \n        # save state_dict\n        self.state_dict = self.model.state_dict()\n\n        return { self.id: self.state_dict }\n\n    def model_sync(self, state_dict):\n        self.state_dict = state_dict","metadata":{"id":"bzCVn4hfAOhX","execution":{"iopub.status.busy":"2023-05-24T14:29:50.115779Z","iopub.execute_input":"2023-05-24T14:29:50.116104Z","iopub.status.idle":"2023-05-24T14:29:50.128001Z","shell.execute_reply.started":"2023-05-24T14:29:50.116074Z","shell.execute_reply":"2023-05-24T14:29:50.126834Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Server","metadata":{"id":"unKQT-qEPnKL"}},{"cell_type":"code","source":"class Server():\n    def __init__(self, args):\n        self.model = CNN().to(device)\n        # number of rounds of communication\n        self.rounds = 0\n        # client fraction C\n        self.c = args['C']\n        # client list\n        self.clients = []\n        # inititalize clients according to num_clients\n        if PARALLEL_TRAINING:\n            for k in range(num_clients):\n                torch.manual_seed(seed)\n                client_model = CNN().to(device)\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n        else:\n            torch.manual_seed(seed)\n            client_model = CNN().to(device)\n            for k in range(num_clients):\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n\n    def _fed_avg(self, state_dicts):\n        # total number of data\n        len_total = 0\n        for k in ChainMap(*state_dicts).keys():\n            len_total += self.clients[k].size()\n\n        dict = OrderedDict()\n        # for each client's state_dict\n        for k, state_dict in ChainMap(*state_dicts).items():\n            # for each tensor param\n            for param_tensor in self.model.state_dict().keys():\n                # param = w0 * wf0 + w1 * wf1 + ... wk * wfk\n                if param_tensor in dict:\n                    dict[param_tensor] += state_dict[param_tensor] * (self.clients[k].size() / len_total)\n                else:\n                    dict[param_tensor] = state_dict[param_tensor] * (self.clients[k].size() / len_total)\n\n        return dict\n\n    def clients_info(self):\n        for i, client in enumerate(self.clients):\n            print(\"Client {} - {}\".format(i, client.labels()))\n\n    async def model_sync(self):\n        selected_clients = self.clients\n\n        # clients random selection\n        if self.c < 1.0:\n            # clients per round\n            k = max(int(self.c * num_clients), 1)\n            # client selection\n            random.seed(self.rounds)\n            selected_clients = random.sample(self.clients, k=k)\n            client_ids = []\n            for client in selected_clients:\n                client_ids.append(client.id)\n            print(\"Selected clients - {}\".format(client_ids))\n\n        state_dicts = []\n        # for each selected client do client update\n        if PARALLEL_TRAINING:\n            state_dicts = await tqdm.gather(*[client.update() for client in selected_clients])\n        else:\n            for client in tqdm(selected_clients):\n                state_dict = await client.update()\n                state_dicts.append(state_dict)\n        \n        # update server weights\n        avg_state_dict = self._fed_avg(state_dicts)\n        self.model.load_state_dict(avg_state_dict)\n\n        # sync with all clients\n        for client in self.clients:\n            client.model_sync(avg_state_dict)\n\n        # increase rounds count\n        self.rounds += 1","metadata":{"id":"rjIkYahr1jVG","execution":{"iopub.status.busy":"2023-05-24T14:29:50.129622Z","iopub.execute_input":"2023-05-24T14:29:50.130318Z","iopub.status.idle":"2023-05-24T14:29:50.147667Z","shell.execute_reply.started":"2023-05-24T14:29:50.130286Z","shell.execute_reply":"2023-05-24T14:29:50.146809Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def test_model(model):\n    # https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-analysis-train-model#test-the-model-on-the-test-data\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Sets the module in evaluate mode\n    model.eval()\n    model.to(device)\n    \n    correct = 0\n    loss = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            # Every data instance is an input + label pair\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Make predictions for this batch\n            outputs = model(inputs)\n            _, pred = torch.max(outputs, dim=1)\n            total += labels.size(0)\n\n            # Compute the loss and accuracy\n            loss += loss_fn(outputs, labels).item()\n            correct += (pred == labels).sum().item()\n\n    loss /= total\n    accuracy = correct / total\n\n    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n        loss, correct, total, accuracy * 100))\n    return accuracy, loss","metadata":{"id":"v-JVTN0sCHlk","execution":{"iopub.status.busy":"2023-05-24T14:29:50.148913Z","iopub.execute_input":"2023-05-24T14:29:50.149310Z","iopub.status.idle":"2023-05-24T14:29:50.161654Z","shell.execute_reply.started":"2023-05-24T14:29:50.149277Z","shell.execute_reply":"2023-05-24T14:29:50.160753Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"async def execute(server, T, target_accuracy, es=None, min_delta=0.0, patience=0):\n    _patience = patience\n\n    # initial values\n    record_round = 0\n    best_round = 0\n    best_accuracy = 0.0\n    last_loss = None\n    state_dict, accuracies, losses = [], [], []\n\n    # loop until rounds\n    while server.rounds < T:\n        print(\"Round {}/{}\".format(server.rounds + 1, T))\n\n        # model sync\n        await server.model_sync()\n        \n        # test accuracy\n        accuracy, loss = test_model(server.model)\n\n        if accuracy >= best_accuracy:\n            # save best record\n            best_accuracy = accuracy\n            best_round = server.rounds\n\n            if best_accuracy >= target_accuracy or server.rounds > T - 10:\n                # save state_dict\n                state_dict = server.model.state_dict()\n\n        # statistics\n        accuracies.append(accuracy)\n        losses.append(loss)\n\n        # early stopping\n        if es == 'loss':\n            if last_loss is None:\n                last_loss = loss\n                continue\n\n            if last_loss - loss < min_delta:\n                # break if patience equal to 0\n                if patience == 0:\n                    break\n                else:\n                    patience -= 1\n            else:\n                # reset patience and update last loss\n                patience = _patience\n                last_loss = loss\n\n        # target accuracy reached\n        if accuracy >= target_accuracy and record_round == 0:\n            record_round = server.rounds\n\n    if record_round > 0:\n        print(\"Target accuracy reached at round: {}\".format(record_round))\n    print(\"Best round: {}, accuracy: {}\".format(best_round, best_accuracy))\n\n    return state_dict, accuracies, losses","metadata":{"id":"BQ7wc8Q_FAkU","execution":{"iopub.status.busy":"2023-05-24T14:29:50.163163Z","iopub.execute_input":"2023-05-24T14:29:50.163523Z","iopub.status.idle":"2023-05-24T14:29:50.174807Z","shell.execute_reply.started":"2023-05-24T14:29:50.163492Z","shell.execute_reply":"2023-05-24T14:29:50.173798Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Execute","metadata":{"id":"OE0VQHt_65fS"}},{"cell_type":"code","source":"# model params\nargs = { 'C': 0.5, 'E': 5, 'B': 10 , 'lr': 0.09 }\n\n# server\nserver = Server(args)\n\n# data distribution\nprint(\"Training dataset - {}\".format(dict(sorted(Counter(training_dataset.targets.tolist()).items()))))\nserver.clients_info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gas3rs865fT","outputId":"f06e8ff8-8899-47c4-c709-f4aeb088613b","execution":{"iopub.status.busy":"2023-05-24T14:29:50.176241Z","iopub.execute_input":"2023-05-24T14:29:50.176843Z","iopub.status.idle":"2023-05-24T14:29:52.080242Z","shell.execute_reply.started":"2023-05-24T14:29:50.176795Z","shell.execute_reply":"2023-05-24T14:29:52.079309Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training dataset - {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\nClient 0 - {8: 300, 1: 300}\nClient 1 - {0: 300, 9: 300}\nClient 2 - {3: 577, 2: 23}\nClient 3 - {2: 300, 1: 300}\nClient 4 - {9: 300, 1: 300}\nClient 5 - {8: 300, 6: 235, 7: 65}\nClient 6 - {1: 300, 7: 300}\nClient 7 - {5: 300, 0: 300}\nClient 8 - {0: 300, 1: 300}\nClient 9 - {2: 600}\nClient 10 - {6: 300, 7: 300}\nClient 11 - {9: 300, 7: 300}\nClient 12 - {2: 300, 8: 300}\nClient 13 - {9: 300, 5: 300}\nClient 14 - {2: 300, 5: 300}\nClient 15 - {7: 300, 3: 300}\nClient 16 - {0: 300, 1: 300}\nClient 17 - {9: 300, 4: 300}\nClient 18 - {8: 300, 1: 300}\nClient 19 - {9: 300, 4: 300}\nClient 20 - {9: 600}\nClient 21 - {4: 300, 1: 300}\nClient 22 - {4: 600}\nClient 23 - {3: 300, 0: 300}\nClient 24 - {5: 300, 6: 300}\nClient 25 - {1: 300, 4: 300}\nClient 26 - {1: 300, 7: 300}\nClient 27 - {3: 300, 4: 300}\nClient 28 - {2: 300, 0: 300}\nClient 29 - {7: 300, 2: 300}\nClient 30 - {3: 300, 7: 300}\nClient 31 - {8: 51, 9: 249, 1: 300}\nClient 32 - {7: 300, 9: 300}\nClient 33 - {5: 300, 4: 300}\nClient 34 - {1: 300, 4: 300}\nClient 35 - {4: 300, 2: 300}\nClient 36 - {3: 300, 4: 300}\nClient 37 - {5: 300, 8: 300}\nClient 38 - {3: 154, 4: 146, 0: 300}\nClient 39 - {3: 600}\nClient 40 - {1: 300, 6: 300}\nClient 41 - {6: 300, 7: 300}\nClient 42 - {6: 300, 8: 300}\nClient 43 - {2: 300, 1: 300}\nClient 44 - {5: 17, 6: 283, 8: 300}\nClient 45 - {6: 300, 9: 300}\nClient 46 - {6: 600}\nClient 47 - {4: 600}\nClient 48 - {9: 300, 1: 300}\nClient 49 - {0: 300, 8: 300}\nClient 50 - {2: 300, 5: 300}\nClient 51 - {9: 300, 1: 300}\nClient 52 - {3: 300, 7: 300}\nClient 53 - {4: 300, 7: 300}\nClient 54 - {4: 300, 3: 300}\nClient 55 - {8: 300, 6: 300}\nClient 56 - {7: 300, 0: 300}\nClient 57 - {1: 300, 7: 300}\nClient 58 - {6: 300, 5: 300}\nClient 59 - {5: 300, 4: 300}\nClient 60 - {9: 300, 2: 300}\nClient 61 - {3: 300, 5: 300}\nClient 62 - {2: 300, 8: 300}\nClient 63 - {4: 300, 3: 300}\nClient 64 - {8: 300, 7: 300}\nClient 65 - {8: 300, 0: 300}\nClient 66 - {0: 223, 1: 77, 5: 300}\nClient 67 - {3: 300, 6: 300}\nClient 68 - {8: 300, 7: 300}\nClient 69 - {1: 300, 5: 300}\nClient 70 - {3: 300, 0: 300}\nClient 71 - {9: 300, 8: 300}\nClient 72 - {0: 300, 2: 300}\nClient 73 - {7: 300, 5: 300}\nClient 74 - {4: 300, 5: 300}\nClient 75 - {5: 300, 3: 300}\nClient 76 - {5: 300, 6: 300}\nClient 77 - {2: 300, 7: 200, 8: 100}\nClient 78 - {7: 300, 0: 300}\nClient 79 - {2: 300, 8: 300}\nClient 80 - {8: 300, 1: 300}\nClient 81 - {9: 300, 2: 300}\nClient 82 - {3: 300, 7: 300}\nClient 83 - {1: 300, 0: 300}\nClient 84 - {6: 300, 1: 300}\nClient 85 - {9: 300, 0: 300}\nClient 86 - {5: 300, 2: 300}\nClient 87 - {8: 300, 9: 300}\nClient 88 - {6: 300, 1: 65, 2: 235}\nClient 89 - {0: 300, 7: 300}\nClient 90 - {0: 300, 1: 300}\nClient 91 - {6: 300, 2: 300}\nClient 92 - {8: 300, 7: 300}\nClient 93 - {3: 300, 6: 300}\nClient 94 - {8: 300, 6: 300}\nClient 95 - {2: 300, 3: 300}\nClient 96 - {0: 600}\nClient 97 - {6: 300, 5: 300}\nClient 98 - {9: 300, 4: 296, 5: 4}\nClient 99 - {9: 300, 3: 300}\n","output_type":"stream"}]},{"cell_type":"code","source":"# rounds and target accuracy\nT = 200\ntarget_accuracy = 0.99\n\nstate_dict, accuracies, losses = await execute(server, T, target_accuracy)\n\n# save model to file\ntorch.save(state_dict, \"cnn_state_dict.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjbFmiTb65fT","outputId":"1467fbfb-3b0e-4bb3-bd3d-df056b1cbfaa","execution":{"iopub.status.busy":"2023-05-24T14:29:52.082185Z","iopub.execute_input":"2023-05-24T14:29:52.083215Z","iopub.status.idle":"2023-05-24T15:55:14.743115Z","shell.execute_reply.started":"2023-05-24T14:29:52.083180Z","shell.execute_reply":"2023-05-24T15:55:14.742146Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Round 1/200\nSelected clients - [49, 97, 53, 5, 33, 65, 62, 51, 38, 61, 45, 74, 27, 64, 17, 36, 85, 12, 79, 32, 68, 77, 18, 39, 82, 9, 42, 60, 71, 75, 89, 55, 40, 26, 90, 56, 95, 3, 92, 58, 35, 72, 0, 96, 46, 98, 25, 69, 50, 73]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.2294, Accuracy: 1109/10000 (11.09%)\nRound 2/200\nSelected clients - [17, 72, 97, 8, 32, 15, 63, 57, 60, 83, 48, 26, 12, 62, 3, 49, 55, 77, 0, 92, 34, 29, 75, 13, 40, 85, 2, 74, 69, 1, 89, 27, 54, 98, 28, 56, 93, 35, 14, 22, 61, 43, 59, 71, 78, 18, 70, 88, 86, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1980, Accuracy: 4803/10000 (48.03%)\nRound 3/200\nSelected clients - [7, 11, 10, 46, 21, 94, 85, 39, 32, 77, 27, 90, 4, 74, 20, 55, 81, 50, 65, 47, 69, 56, 64, 34, 87, 3, 96, 59, 40, 48, 54, 67, 95, 22, 30, 29, 86, 98, 93, 62, 8, 91, 58, 23, 57, 43, 35, 60, 28, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1318, Accuracy: 8217/10000 (82.17%)\nRound 4/200\nSelected clients - [30, 75, 69, 16, 47, 77, 60, 80, 74, 8, 94, 1, 93, 33, 70, 29, 24, 87, 97, 85, 82, 50, 19, 84, 89, 66, 49, 88, 90, 20, 5, 38, 3, 34, 79, 73, 54, 25, 46, 51, 36, 28, 71, 56, 23, 6, 2, 57, 31, 13]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0764, Accuracy: 8709/10000 (87.09%)\nRound 5/200\nSelected clients - [30, 38, 13, 92, 50, 61, 19, 11, 8, 2, 51, 70, 37, 7, 28, 66, 68, 46, 35, 22, 97, 33, 27, 3, 78, 34, 24, 21, 39, 87, 47, 96, 43, 49, 64, 31, 80, 15, 99, 17, 5, 52, 55, 81, 53, 93, 0, 18, 36, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0573, Accuracy: 9214/10000 (92.14%)\nRound 6/200\nSelected clients - [79, 32, 94, 45, 88, 97, 83, 67, 3, 59, 31, 93, 6, 20, 14, 47, 60, 89, 48, 69, 13, 73, 82, 1, 27, 52, 35, 23, 49, 86, 9, 17, 56, 16, 66, 0, 64, 99, 71, 62, 10, 55, 90, 18, 70, 12, 34, 43, 40, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0361, Accuracy: 9130/10000 (91.30%)\nRound 7/200\nSelected clients - [73, 10, 62, 33, 4, 0, 18, 84, 75, 60, 47, 40, 2, 34, 97, 25, 52, 68, 69, 12, 24, 72, 70, 96, 11, 54, 42, 91, 46, 83, 32, 56, 80, 92, 37, 67, 5, 65, 57, 64, 77, 41, 23, 31, 53, 90, 81, 36, 58, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0408, Accuracy: 9012/10000 (90.12%)\nRound 8/200\nSelected clients - [41, 19, 50, 83, 6, 9, 68, 12, 46, 74, 7, 64, 27, 4, 11, 55, 53, 8, 30, 85, 70, 54, 89, 72, 15, 28, 77, 97, 95, 90, 5, 17, 37, 96, 18, 75, 39, 35, 52, 43, 80, 71, 67, 36, 40, 92, 23, 58, 62, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0294, Accuracy: 9419/10000 (94.19%)\nRound 9/200\nSelected clients - [29, 47, 48, 16, 24, 90, 5, 10, 17, 31, 64, 26, 51, 82, 3, 58, 62, 84, 49, 63, 73, 95, 87, 11, 83, 99, 2, 34, 66, 52, 60, 97, 14, 33, 12, 8, 81, 39, 53, 78, 6, 42, 85, 21, 15, 44, 93, 94, 41, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0214, Accuracy: 9447/10000 (94.47%)\nRound 10/200\nSelected clients - [59, 78, 47, 34, 17, 23, 86, 0, 43, 64, 99, 77, 10, 42, 70, 98, 5, 48, 21, 57, 54, 20, 81, 30, 6, 14, 16, 90, 8, 49, 13, 37, 26, 28, 53, 11, 96, 58, 69, 25, 95, 88, 51, 2, 12, 45, 92, 67, 3, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0200, Accuracy: 9509/10000 (95.09%)\nRound 11/200\nSelected clients - [73, 4, 54, 61, 99, 1, 26, 59, 62, 35, 83, 20, 98, 66, 91, 41, 9, 31, 46, 5, 53, 17, 77, 45, 48, 79, 36, 33, 58, 22, 38, 81, 78, 71, 30, 56, 75, 2, 37, 0, 15, 8, 12, 19, 34, 23, 49, 92, 88, 42]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0203, Accuracy: 9567/10000 (95.67%)\nRound 12/200\nSelected clients - [57, 71, 59, 99, 65, 75, 24, 23, 95, 60, 80, 78, 92, 12, 96, 38, 18, 11, 68, 5, 76, 50, 85, 20, 1, 67, 8, 7, 4, 93, 30, 3, 97, 41, 56, 25, 29, 40, 83, 31, 0, 42, 89, 63, 66, 17, 26, 35, 77, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0166, Accuracy: 9567/10000 (95.67%)\nRound 13/200\nSelected clients - [60, 34, 84, 67, 85, 44, 18, 48, 1, 47, 61, 35, 82, 58, 76, 29, 71, 0, 79, 93, 56, 90, 20, 43, 26, 7, 73, 25, 9, 65, 95, 51, 11, 2, 74, 28, 96, 27, 99, 64, 70, 42, 62, 8, 98, 77, 39, 88, 10, 94]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0151, Accuracy: 9582/10000 (95.82%)\nRound 14/200\nSelected clients - [33, 37, 87, 97, 23, 83, 29, 85, 18, 28, 82, 95, 16, 9, 68, 27, 98, 3, 55, 96, 77, 1, 35, 91, 10, 99, 57, 81, 17, 32, 45, 93, 62, 54, 46, 72, 40, 41, 7, 22, 52, 38, 51, 63, 80, 44, 90, 79, 39, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0138, Accuracy: 9589/10000 (95.89%)\nRound 15/200\nSelected clients - [13, 78, 89, 96, 83, 67, 31, 34, 32, 37, 9, 84, 57, 38, 59, 50, 88, 15, 33, 28, 40, 45, 81, 46, 66, 19, 20, 70, 35, 21, 1, 8, 82, 43, 3, 10, 71, 99, 54, 24, 25, 90, 80, 86, 6, 41, 75, 7, 58, 51]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0114, Accuracy: 9654/10000 (96.54%)\nRound 16/200\nSelected clients - [26, 1, 66, 94, 4, 20, 30, 2, 7, 87, 18, 88, 47, 93, 14, 43, 59, 45, 35, 50, 33, 44, 29, 99, 82, 40, 28, 39, 65, 53, 77, 58, 70, 62, 10, 83, 46, 73, 36, 96, 64, 78, 41, 97, 25, 49, 51, 95, 31, 98]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0105, Accuracy: 9711/10000 (97.11%)\nRound 17/200\nSelected clients - [46, 60, 61, 36, 53, 29, 57, 0, 52, 84, 33, 30, 81, 28, 1, 37, 38, 42, 18, 77, 39, 2, 86, 32, 78, 19, 3, 59, 58, 90, 80, 79, 99, 89, 95, 11, 44, 31, 27, 66, 41, 64, 96, 87, 70, 75, 56, 5, 50, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0115, Accuracy: 9702/10000 (97.02%)\nRound 18/200\nSelected clients - [66, 53, 38, 46, 37, 22, 90, 93, 69, 84, 35, 14, 3, 31, 49, 98, 32, 64, 40, 51, 17, 70, 7, 79, 25, 19, 68, 71, 26, 42, 91, 15, 8, 39, 52, 10, 60, 81, 97, 9, 43, 80, 72, 65, 83, 21, 1, 27, 23, 36]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0096, Accuracy: 9704/10000 (97.04%)\nRound 19/200\nSelected clients - [23, 15, 84, 57, 42, 30, 25, 62, 80, 63, 99, 61, 37, 58, 33, 93, 32, 98, 41, 66, 22, 94, 21, 78, 97, 46, 73, 64, 75, 90, 27, 38, 85, 0, 43, 51, 28, 49, 74, 71, 34, 79, 87, 36, 67, 17, 52, 54, 68, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0117, Accuracy: 9699/10000 (96.99%)\nRound 20/200\nSelected clients - [86, 5, 66, 15, 65, 25, 50, 44, 67, 37, 74, 18, 76, 33, 13, 99, 52, 41, 34, 85, 82, 39, 2, 72, 94, 9, 75, 14, 69, 58, 49, 89, 12, 53, 77, 91, 54, 48, 63, 73, 28, 42, 19, 36, 32, 97, 10, 93, 40, 26]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0086, Accuracy: 9754/10000 (97.54%)\nRound 21/200\nSelected clients - [92, 87, 19, 33, 86, 81, 12, 41, 73, 21, 3, 52, 88, 9, 13, 16, 40, 60, 74, 57, 98, 26, 25, 83, 42, 75, 54, 11, 66, 62, 51, 10, 78, 31, 4, 77, 93, 5, 63, 84, 44, 48, 18, 97, 59, 82, 68, 39, 7, 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0085, Accuracy: 9732/10000 (97.32%)\nRound 22/200\nSelected clients - [21, 53, 88, 98, 81, 36, 61, 27, 60, 65, 23, 64, 67, 30, 0, 1, 47, 74, 54, 8, 18, 29, 78, 5, 55, 52, 56, 4, 42, 69, 63, 14, 83, 2, 19, 11, 15, 51, 59, 84, 77, 10, 35, 46, 99, 25, 31, 9, 97, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0071, Accuracy: 9784/10000 (97.84%)\nRound 23/200\nSelected clients - [17, 31, 3, 78, 57, 23, 89, 15, 83, 44, 10, 29, 34, 6, 40, 76, 22, 70, 55, 86, 73, 2, 75, 33, 39, 53, 24, 94, 14, 67, 7, 41, 42, 84, 72, 50, 77, 95, 49, 81, 68, 32, 9, 99, 52, 56, 82, 90, 11, 27]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0074, Accuracy: 9777/10000 (97.77%)\nRound 24/200\nSelected clients - [99, 37, 10, 2, 75, 39, 54, 48, 67, 45, 16, 24, 34, 56, 1, 28, 79, 58, 3, 13, 97, 63, 53, 96, 65, 55, 90, 7, 26, 4, 47, 22, 27, 46, 69, 36, 40, 64, 5, 52, 30, 11, 73, 59, 98, 50, 84, 43, 41, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0071, Accuracy: 9782/10000 (97.82%)\nRound 25/200\nSelected clients - [91, 49, 74, 23, 27, 21, 24, 94, 85, 87, 11, 19, 36, 1, 56, 59, 81, 14, 3, 66, 92, 62, 99, 38, 63, 10, 32, 20, 41, 39, 9, 46, 4, 95, 40, 43, 8, 88, 6, 15, 42, 76, 51, 69, 52, 54, 31, 18, 17, 35]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0073, Accuracy: 9762/10000 (97.62%)\nRound 26/200\nSelected clients - [48, 98, 1, 27, 39, 81, 60, 5, 32, 4, 95, 72, 54, 12, 75, 15, 73, 25, 65, 79, 40, 23, 70, 45, 94, 93, 67, 13, 86, 76, 53, 77, 24, 20, 58, 9, 64, 82, 36, 90, 91, 80, 8, 46, 2, 34, 11, 74, 37, 14]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0073, Accuracy: 9760/10000 (97.60%)\nRound 27/200\nSelected clients - [95, 25, 84, 26, 55, 76, 69, 7, 16, 61, 5, 87, 79, 64, 21, 81, 54, 31, 52, 98, 3, 28, 18, 91, 27, 90, 49, 46, 82, 88, 70, 37, 15, 65, 89, 0, 59, 38, 42, 35, 20, 97, 63, 83, 74, 75, 56, 44, 12, 93]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0069, Accuracy: 9792/10000 (97.92%)\nRound 28/200\nSelected clients - [83, 61, 89, 35, 36, 25, 9, 8, 32, 69, 42, 91, 47, 51, 23, 31, 30, 62, 93, 73, 10, 78, 54, 53, 6, 56, 44, 1, 98, 88, 17, 43, 29, 18, 12, 50, 38, 58, 87, 64, 59, 2, 49, 68, 33, 5, 79, 67, 45, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0061, Accuracy: 9808/10000 (98.08%)\nRound 29/200\nSelected clients - [14, 95, 16, 69, 76, 91, 22, 28, 97, 81, 59, 53, 26, 27, 18, 50, 20, 94, 77, 24, 25, 3, 52, 30, 8, 12, 88, 40, 82, 93, 64, 66, 34, 29, 57, 71, 79, 0, 89, 49, 85, 72, 43, 96, 5, 33, 67, 17, 46, 7]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0063, Accuracy: 9804/10000 (98.04%)\nRound 30/200\nSelected clients - [70, 9, 44, 76, 77, 36, 11, 65, 97, 50, 53, 2, 4, 13, 56, 83, 28, 91, 10, 63, 42, 95, 69, 89, 25, 57, 21, 84, 55, 52, 67, 75, 54, 38, 35, 72, 99, 61, 90, 30, 33, 98, 48, 19, 74, 85, 37, 45, 41, 60]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0062, Accuracy: 9807/10000 (98.07%)\nRound 31/200\nSelected clients - [69, 37, 78, 3, 79, 83, 26, 32, 6, 50, 48, 82, 17, 10, 59, 0, 66, 31, 96, 9, 20, 76, 67, 51, 44, 68, 8, 97, 81, 88, 35, 54, 12, 99, 14, 63, 39, 73, 53, 19, 56, 60, 16, 92, 5, 62, 15, 75, 95, 7]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0055, Accuracy: 9823/10000 (98.23%)\nRound 32/200\nSelected clients - [1, 60, 14, 50, 18, 87, 5, 17, 97, 68, 29, 92, 95, 4, 84, 7, 88, 89, 90, 57, 67, 52, 26, 75, 11, 15, 2, 51, 43, 25, 77, 42, 96, 46, 31, 69, 27, 64, 37, 81, 35, 3, 58, 53, 76, 22, 8, 13, 9, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0061, Accuracy: 9813/10000 (98.13%)\nRound 33/200\nSelected clients - [9, 27, 18, 38, 89, 30, 63, 3, 4, 12, 41, 65, 42, 7, 66, 60, 47, 76, 0, 69, 16, 67, 1, 62, 25, 36, 75, 57, 10, 87, 15, 91, 78, 14, 20, 56, 2, 98, 92, 58, 93, 35, 22, 85, 71, 29, 19, 46, 31, 55]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0053, Accuracy: 9833/10000 (98.33%)\nRound 34/200\nSelected clients - [73, 21, 80, 29, 35, 61, 83, 68, 67, 23, 93, 78, 64, 41, 91, 94, 56, 36, 81, 9, 38, 52, 39, 66, 63, 6, 54, 95, 40, 31, 15, 7, 71, 82, 27, 8, 46, 92, 86, 20, 49, 69, 32, 17, 60, 0, 22, 33, 42, 19]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0052, Accuracy: 9834/10000 (98.34%)\nRound 35/200\nSelected clients - [67, 45, 74, 3, 29, 96, 49, 46, 8, 54, 39, 43, 12, 97, 65, 19, 87, 35, 44, 78, 0, 84, 99, 11, 7, 47, 32, 70, 75, 93, 21, 89, 37, 48, 40, 27, 26, 28, 34, 76, 38, 91, 36, 98, 25, 61, 64, 15, 52, 88]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0052, Accuracy: 9829/10000 (98.29%)\nRound 36/200\nSelected clients - [70, 42, 96, 16, 95, 43, 19, 36, 55, 32, 72, 7, 67, 35, 83, 46, 74, 12, 84, 1, 65, 80, 82, 63, 47, 3, 94, 76, 6, 2, 30, 41, 10, 20, 73, 21, 9, 69, 54, 23, 5, 18, 87, 92, 4, 79, 8, 34, 81, 28]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0050, Accuracy: 9825/10000 (98.25%)\nRound 37/200\nSelected clients - [42, 7, 2, 36, 10, 0, 64, 80, 22, 31, 34, 83, 55, 46, 71, 89, 69, 9, 73, 52, 62, 49, 44, 50, 90, 76, 21, 15, 65, 63, 26, 67, 37, 23, 79, 41, 81, 94, 38, 24, 57, 75, 8, 48, 13, 88, 66, 51, 87, 58]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0052, Accuracy: 9825/10000 (98.25%)\nRound 38/200\nSelected clients - [87, 77, 11, 79, 85, 81, 65, 4, 80, 47, 56, 67, 13, 58, 76, 36, 48, 54, 89, 18, 6, 97, 52, 9, 69, 84, 46, 55, 73, 92, 88, 27, 64, 53, 8, 1, 0, 41, 32, 86, 23, 70, 45, 37, 14, 75, 20, 22, 33, 10]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0050, Accuracy: 9831/10000 (98.31%)\nRound 39/200\nSelected clients - [81, 53, 54, 96, 92, 13, 8, 46, 89, 59, 47, 5, 77, 85, 21, 75, 44, 41, 34, 42, 79, 39, 60, 74, 51, 28, 10, 67, 62, 18, 55, 72, 31, 1, 48, 91, 3, 9, 30, 6, 16, 7, 64, 93, 29, 88, 58, 49, 25, 70]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0048, Accuracy: 9842/10000 (98.42%)\nRound 40/200\nSelected clients - [26, 33, 49, 3, 24, 28, 50, 72, 0, 82, 32, 86, 45, 22, 96, 37, 9, 46, 1, 13, 54, 44, 79, 12, 93, 65, 38, 34, 8, 58, 55, 89, 41, 91, 5, 95, 61, 39, 48, 40, 64, 51, 20, 70, 18, 59, 67, 88, 30, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0046, Accuracy: 9839/10000 (98.39%)\nRound 41/200\nSelected clients - [58, 74, 67, 4, 31, 36, 85, 81, 93, 26, 16, 44, 35, 56, 3, 97, 89, 7, 25, 79, 99, 6, 22, 40, 14, 32, 41, 18, 65, 66, 12, 52, 78, 76, 42, 29, 19, 63, 10, 33, 62, 88, 68, 72, 64, 50, 61, 37, 13, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9854/10000 (98.54%)\nRound 42/200\nSelected clients - [48, 42, 29, 21, 49, 73, 88, 36, 70, 35, 95, 94, 1, 31, 84, 2, 56, 19, 82, 40, 96, 32, 74, 7, 15, 4, 55, 92, 27, 9, 46, 60, 16, 85, 75, 12, 18, 44, 57, 11, 3, 17, 20, 14, 39, 87, 38, 72, 68, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0049, Accuracy: 9837/10000 (98.37%)\nRound 43/200\nSelected clients - [81, 14, 3, 94, 35, 31, 28, 17, 13, 86, 69, 11, 75, 54, 4, 97, 88, 27, 29, 64, 77, 84, 71, 25, 89, 53, 93, 57, 95, 0, 20, 90, 43, 79, 19, 82, 67, 6, 5, 24, 62, 22, 68, 58, 38, 16, 51, 2, 46, 99]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0046, Accuracy: 9846/10000 (98.46%)\nRound 44/200\nSelected clients - [4, 36, 89, 18, 59, 47, 85, 97, 12, 58, 76, 63, 77, 2, 65, 55, 73, 94, 79, 70, 84, 50, 22, 7, 13, 15, 48, 19, 91, 20, 93, 88, 16, 49, 64, 34, 23, 24, 99, 3, 37, 60, 11, 90, 53, 10, 96, 17, 61, 33]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9847/10000 (98.47%)\nRound 45/200\nSelected clients - [52, 66, 69, 89, 14, 22, 48, 28, 37, 3, 92, 95, 72, 1, 12, 20, 65, 38, 81, 93, 75, 51, 41, 45, 9, 43, 36, 84, 88, 83, 8, 85, 34, 40, 13, 91, 4, 94, 24, 6, 30, 59, 68, 57, 97, 16, 47, 15, 49, 90]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9841/10000 (98.41%)\nRound 46/200\nSelected clients - [34, 53, 62, 32, 10, 38, 43, 2, 9, 61, 1, 14, 36, 15, 39, 83, 4, 79, 8, 17, 99, 19, 27, 54, 91, 52, 18, 7, 84, 22, 41, 96, 45, 40, 12, 74, 11, 89, 48, 21, 20, 50, 24, 44, 47, 33, 42, 82, 66, 46]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9845/10000 (98.45%)\nRound 47/200\nSelected clients - [9, 51, 5, 75, 96, 29, 81, 66, 19, 74, 68, 4, 3, 8, 40, 80, 6, 87, 17, 70, 37, 67, 42, 11, 50, 61, 46, 91, 60, 59, 99, 58, 14, 55, 28, 43, 56, 49, 45, 93, 69, 83, 38, 22, 88, 57, 21, 94, 25, 76]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9851/10000 (98.51%)\nRound 48/200\nSelected clients - [45, 8, 55, 70, 58, 73, 43, 32, 65, 49, 50, 78, 5, 53, 84, 3, 13, 0, 33, 61, 69, 1, 40, 72, 54, 29, 30, 66, 91, 99, 56, 94, 4, 47, 96, 93, 25, 15, 89, 86, 46, 95, 2, 98, 21, 6, 23, 37, 24, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9855/10000 (98.55%)\nRound 49/200\nSelected clients - [70, 40, 16, 71, 91, 68, 38, 64, 24, 55, 21, 19, 84, 13, 63, 83, 28, 27, 65, 96, 81, 88, 60, 82, 3, 9, 54, 8, 97, 85, 20, 80, 7, 37, 43, 79, 12, 53, 15, 17, 94, 41, 0, 56, 36, 18, 98, 72, 22, 58]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9857/10000 (98.57%)\nRound 50/200\nSelected clients - [8, 44, 52, 14, 41, 70, 65, 6, 87, 5, 35, 19, 58, 90, 80, 69, 64, 28, 77, 36, 73, 47, 51, 3, 31, 17, 12, 54, 48, 95, 45, 34, 81, 92, 97, 26, 99, 85, 16, 68, 38, 60, 20, 63, 75, 96, 57, 61, 37, 27]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9855/10000 (98.55%)\nRound 51/200\nSelected clients - [63, 34, 46, 81, 31, 88, 60, 42, 10, 68, 40, 28, 86, 71, 91, 19, 44, 12, 83, 89, 94, 24, 8, 92, 54, 11, 77, 76, 55, 0, 29, 43, 98, 87, 13, 25, 56, 17, 57, 96, 37, 69, 73, 62, 39, 65, 67, 59, 7, 26]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9848/10000 (98.48%)\nRound 52/200\nSelected clients - [31, 64, 70, 20, 99, 29, 97, 32, 50, 93, 59, 90, 67, 80, 43, 75, 46, 49, 35, 51, 0, 14, 3, 68, 33, 4, 61, 22, 44, 38, 47, 57, 24, 77, 56, 21, 60, 79, 58, 66, 6, 52, 91, 73, 69, 65, 76, 37, 89, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9845/10000 (98.45%)\nRound 53/200\nSelected clients - [34, 6, 92, 65, 61, 47, 52, 4, 17, 20, 93, 23, 44, 56, 80, 0, 97, 69, 49, 86, 1, 30, 8, 90, 21, 95, 29, 35, 62, 63, 53, 15, 83, 48, 11, 50, 46, 99, 77, 9, 25, 33, 42, 58, 45, 96, 91, 5, 76, 54]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9853/10000 (98.53%)\nRound 54/200\nSelected clients - [78, 27, 58, 64, 91, 61, 95, 66, 46, 97, 3, 4, 21, 44, 16, 33, 7, 87, 6, 93, 29, 56, 25, 79, 85, 17, 86, 96, 40, 65, 51, 83, 42, 35, 19, 11, 52, 24, 28, 15, 67, 49, 9, 48, 89, 94, 41, 63, 30, 14]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9854/10000 (98.54%)\nRound 55/200\nSelected clients - [17, 56, 71, 38, 61, 62, 48, 28, 57, 42, 73, 93, 26, 25, 7, 63, 70, 91, 76, 11, 69, 43, 66, 37, 53, 34, 79, 18, 12, 33, 35, 98, 4, 88, 1, 46, 74, 0, 14, 64, 65, 10, 82, 60, 8, 24, 15, 59, 44, 13]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9854/10000 (98.54%)\nRound 56/200\nSelected clients - [11, 25, 19, 94, 38, 10, 23, 95, 99, 45, 84, 60, 69, 49, 86, 64, 51, 40, 54, 68, 5, 32, 79, 29, 65, 1, 73, 59, 28, 6, 48, 76, 91, 89, 81, 24, 80, 87, 13, 26, 96, 97, 21, 53, 0, 70, 52, 88, 58, 20]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9861/10000 (98.61%)\nRound 57/200\nSelected clients - [71, 1, 60, 83, 66, 38, 69, 53, 90, 29, 12, 47, 79, 8, 43, 82, 32, 73, 26, 2, 84, 81, 6, 74, 99, 17, 49, 3, 19, 87, 31, 23, 89, 25, 27, 56, 68, 45, 24, 86, 57, 42, 4, 70, 13, 33, 85, 11, 67, 52]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9849/10000 (98.49%)\nRound 58/200\nSelected clients - [5, 47, 75, 77, 2, 28, 65, 41, 61, 37, 55, 81, 48, 95, 21, 66, 96, 98, 87, 50, 13, 74, 62, 69, 32, 17, 72, 18, 78, 88, 19, 54, 93, 22, 89, 46, 94, 15, 57, 68, 71, 25, 42, 79, 26, 63, 0, 40, 29, 60]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9865/10000 (98.65%)\nRound 59/200\nSelected clients - [74, 25, 26, 94, 82, 98, 5, 24, 57, 51, 45, 36, 33, 91, 78, 53, 88, 99, 13, 1, 62, 27, 60, 9, 86, 70, 48, 47, 7, 12, 17, 38, 4, 23, 37, 39, 22, 64, 68, 46, 15, 73, 43, 67, 10, 95, 28, 8, 52, 90]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9869/10000 (98.69%)\nRound 60/200\nSelected clients - [28, 10, 83, 58, 2, 17, 38, 91, 95, 87, 79, 1, 62, 48, 90, 68, 93, 20, 74, 43, 22, 67, 14, 12, 47, 5, 40, 39, 11, 81, 24, 98, 71, 32, 97, 78, 13, 55, 21, 36, 8, 42, 25, 0, 49, 70, 99, 18, 34, 66]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9858/10000 (98.58%)\nRound 61/200\nSelected clients - [39, 36, 73, 19, 33, 29, 61, 59, 42, 5, 11, 85, 23, 96, 49, 90, 30, 81, 1, 52, 21, 16, 99, 86, 65, 71, 6, 72, 13, 38, 76, 2, 28, 37, 83, 35, 8, 60, 14, 63, 45, 57, 78, 53, 74, 46, 56, 12, 66, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9860/10000 (98.60%)\nRound 62/200\nSelected clients - [63, 23, 71, 27, 41, 37, 95, 88, 3, 62, 45, 89, 8, 51, 59, 42, 21, 84, 80, 0, 64, 11, 22, 43, 91, 55, 18, 16, 86, 94, 70, 76, 56, 40, 47, 77, 33, 26, 90, 14, 87, 78, 75, 34, 98, 30, 81, 67, 24, 5]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9868/10000 (98.68%)\nRound 63/200\nSelected clients - [73, 22, 8, 30, 59, 39, 85, 45, 21, 65, 23, 20, 0, 33, 81, 91, 15, 3, 60, 93, 66, 2, 43, 75, 88, 27, 10, 41, 69, 57, 78, 50, 94, 77, 46, 95, 1, 19, 55, 18, 38, 74, 83, 44, 67, 17, 12, 11, 64, 90]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9868/10000 (98.68%)\nRound 64/200\nSelected clients - [56, 99, 37, 32, 61, 84, 11, 49, 10, 9, 94, 25, 97, 90, 80, 39, 78, 7, 28, 16, 42, 30, 35, 76, 3, 4, 20, 29, 71, 54, 55, 46, 62, 26, 13, 74, 64, 21, 89, 67, 48, 82, 1, 36, 91, 95, 0, 88, 81, 75]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9876/10000 (98.76%)\nRound 65/200\nSelected clients - [60, 15, 80, 78, 51, 68, 87, 2, 26, 34, 97, 25, 83, 18, 10, 53, 56, 88, 3, 85, 95, 0, 8, 22, 13, 5, 33, 28, 69, 82, 11, 81, 58, 50, 27, 37, 17, 35, 65, 76, 32, 19, 47, 23, 44, 31, 73, 71, 94, 96]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9875/10000 (98.75%)\nRound 66/200\nSelected clients - [53, 36, 98, 65, 28, 56, 58, 67, 94, 70, 43, 81, 55, 95, 9, 71, 59, 33, 25, 60, 79, 5, 32, 14, 20, 92, 17, 15, 73, 44, 47, 46, 29, 74, 50, 57, 80, 3, 90, 85, 48, 1, 49, 87, 21, 16, 75, 83, 84, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9873/10000 (98.73%)\nRound 67/200\nSelected clients - [9, 39, 55, 31, 57, 37, 32, 71, 12, 63, 23, 59, 66, 16, 8, 46, 21, 52, 58, 64, 3, 67, 14, 49, 17, 47, 79, 1, 26, 88, 92, 40, 61, 98, 25, 94, 85, 91, 48, 81, 20, 42, 56, 22, 50, 65, 4, 19, 5, 54]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9877/10000 (98.77%)\nRound 68/200\nSelected clients - [9, 14, 52, 59, 53, 34, 76, 54, 62, 79, 35, 26, 82, 5, 85, 22, 36, 4, 20, 56, 23, 15, 12, 91, 39, 31, 51, 1, 50, 67, 81, 19, 47, 66, 0, 80, 29, 41, 42, 43, 24, 97, 2, 64, 84, 10, 27, 89, 73, 65]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9885/10000 (98.85%)\nRound 69/200\nSelected clients - [94, 59, 88, 95, 64, 14, 77, 74, 31, 55, 60, 33, 86, 42, 56, 70, 46, 21, 84, 15, 5, 69, 61, 13, 43, 7, 11, 22, 24, 71, 0, 67, 54, 85, 48, 16, 3, 37, 40, 9, 62, 36, 72, 89, 50, 52, 92, 78, 30, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9865/10000 (98.65%)\nRound 70/200\nSelected clients - [87, 4, 12, 21, 8, 77, 44, 41, 70, 53, 59, 54, 72, 56, 66, 92, 71, 91, 86, 18, 52, 50, 95, 90, 36, 80, 25, 74, 39, 27, 64, 26, 13, 97, 49, 94, 33, 55, 51, 46, 38, 23, 81, 2, 98, 6, 67, 1, 9, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9884/10000 (98.84%)\nRound 71/200\nSelected clients - [15, 37, 89, 58, 57, 17, 41, 13, 19, 86, 90, 76, 27, 85, 52, 48, 30, 51, 9, 64, 40, 35, 84, 95, 12, 11, 4, 62, 44, 36, 94, 3, 33, 88, 99, 63, 8, 80, 22, 59, 34, 14, 38, 82, 5, 56, 68, 67, 25, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9877/10000 (98.77%)\nRound 72/200\nSelected clients - [41, 65, 79, 1, 33, 19, 25, 95, 11, 93, 98, 7, 76, 24, 64, 3, 67, 46, 58, 16, 44, 21, 4, 97, 84, 49, 86, 94, 99, 55, 57, 12, 2, 31, 18, 72, 66, 51, 47, 70, 32, 22, 85, 37, 96, 80, 81, 13, 90, 60]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9876/10000 (98.76%)\nRound 73/200\nSelected clients - [9, 76, 94, 23, 44, 89, 69, 79, 47, 39, 87, 98, 16, 43, 29, 48, 18, 81, 3, 28, 58, 1, 57, 8, 37, 11, 64, 40, 2, 53, 32, 34, 95, 91, 80, 66, 62, 72, 15, 22, 75, 31, 67, 74, 19, 26, 36, 21, 99, 85]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9882/10000 (98.82%)\nRound 74/200\nSelected clients - [35, 15, 64, 61, 72, 23, 59, 38, 75, 9, 62, 51, 66, 97, 25, 57, 14, 2, 32, 52, 3, 53, 45, 71, 54, 63, 70, 55, 94, 7, 33, 85, 11, 93, 44, 37, 16, 83, 1, 13, 95, 88, 58, 17, 56, 77, 79, 48, 98, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9876/10000 (98.76%)\nRound 75/200\nSelected clients - [78, 65, 14, 40, 15, 39, 23, 27, 44, 95, 56, 58, 67, 35, 57, 21, 96, 86, 64, 79, 0, 98, 5, 16, 29, 89, 19, 53, 30, 34, 32, 55, 80, 25, 20, 7, 92, 45, 88, 84, 2, 1, 61, 91, 54, 6, 66, 74, 36, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9879/10000 (98.79%)\nRound 76/200\nSelected clients - [57, 74, 55, 58, 5, 93, 65, 86, 85, 60, 92, 89, 44, 12, 40, 10, 32, 35, 63, 87, 77, 62, 34, 52, 3, 48, 69, 59, 25, 16, 71, 18, 38, 81, 21, 72, 2, 19, 39, 45, 75, 4, 64, 17, 20, 88, 99, 95, 26, 7]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9882/10000 (98.82%)\nRound 77/200\nSelected clients - [47, 59, 49, 25, 38, 6, 53, 30, 36, 95, 56, 62, 29, 10, 42, 90, 87, 85, 68, 7, 0, 52, 75, 97, 92, 82, 69, 58, 3, 8, 51, 19, 12, 31, 11, 84, 13, 55, 46, 32, 94, 79, 1, 63, 73, 78, 66, 93, 65, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9883/10000 (98.83%)\nRound 78/200\nSelected clients - [32, 41, 25, 30, 24, 14, 37, 60, 71, 78, 96, 18, 91, 80, 84, 64, 0, 35, 3, 63, 22, 95, 85, 49, 23, 42, 98, 15, 11, 70, 33, 68, 92, 26, 28, 90, 9, 5, 54, 12, 44, 82, 57, 65, 38, 45, 34, 4, 6, 61]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9885/10000 (98.85%)\nRound 79/200\nSelected clients - [24, 12, 38, 85, 93, 32, 54, 4, 83, 18, 91, 51, 84, 99, 60, 48, 69, 1, 30, 22, 44, 95, 43, 52, 23, 80, 46, 73, 6, 26, 98, 86, 90, 59, 37, 67, 94, 45, 66, 53, 10, 40, 63, 42, 47, 79, 68, 72, 5, 76]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9890/10000 (98.90%)\nRound 80/200\nSelected clients - [18, 56, 44, 76, 20, 30, 31, 92, 88, 63, 19, 8, 97, 3, 25, 14, 62, 39, 22, 52, 61, 47, 11, 48, 13, 33, 83, 5, 42, 58, 10, 7, 70, 12, 84, 94, 23, 85, 17, 81, 65, 87, 95, 29, 79, 77, 4, 2, 37, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9883/10000 (98.83%)\nRound 81/200\nSelected clients - [34, 50, 69, 90, 53, 47, 46, 68, 51, 94, 3, 70, 49, 28, 79, 6, 87, 30, 21, 67, 72, 1, 18, 57, 16, 20, 29, 96, 45, 22, 26, 99, 33, 10, 40, 12, 2, 85, 0, 9, 80, 77, 19, 23, 39, 37, 78, 74, 31, 62]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9878/10000 (98.78%)\nRound 82/200\nSelected clients - [64, 58, 43, 71, 68, 49, 61, 2, 20, 19, 57, 86, 77, 0, 40, 36, 45, 28, 39, 16, 87, 9, 27, 65, 38, 74, 96, 23, 42, 72, 94, 29, 89, 31, 67, 92, 55, 22, 18, 62, 47, 63, 17, 37, 60, 46, 69, 6, 10, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9881/10000 (98.81%)\nRound 83/200\nSelected clients - [18, 98, 62, 64, 37, 22, 21, 87, 33, 20, 4, 55, 60, 74, 12, 25, 39, 71, 17, 15, 61, 10, 41, 44, 97, 11, 75, 23, 0, 30, 45, 38, 3, 47, 56, 53, 49, 99, 77, 84, 58, 42, 16, 1, 94, 19, 7, 76, 80, 54]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9878/10000 (98.78%)\nRound 84/200\nSelected clients - [63, 58, 11, 16, 48, 4, 6, 83, 27, 24, 22, 39, 10, 93, 52, 19, 45, 38, 71, 25, 60, 29, 57, 21, 5, 3, 2, 59, 44, 49, 23, 40, 61, 98, 41, 56, 78, 8, 66, 95, 92, 26, 68, 32, 35, 97, 36, 62, 0, 69]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9884/10000 (98.84%)\nRound 85/200\nSelected clients - [93, 36, 4, 62, 0, 66, 84, 40, 25, 58, 63, 70, 46, 77, 19, 69, 33, 67, 59, 51, 42, 86, 28, 16, 60, 5, 65, 74, 85, 72, 89, 82, 37, 13, 1, 30, 91, 57, 27, 8, 18, 45, 7, 17, 96, 87, 6, 34, 97, 29]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9880/10000 (98.80%)\nRound 86/200\nSelected clients - [25, 89, 78, 13, 41, 24, 28, 59, 44, 74, 93, 87, 48, 68, 86, 98, 75, 76, 73, 92, 77, 55, 15, 0, 71, 9, 97, 60, 57, 61, 84, 69, 16, 53, 14, 91, 20, 82, 94, 36, 90, 32, 66, 43, 35, 65, 2, 29, 45, 21]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9889/10000 (98.89%)\nRound 87/200\nSelected clients - [99, 3, 71, 40, 95, 1, 8, 90, 64, 80, 38, 48, 13, 91, 12, 52, 58, 0, 74, 27, 26, 46, 7, 22, 50, 36, 10, 60, 75, 11, 37, 61, 17, 63, 47, 54, 86, 88, 24, 44, 85, 87, 45, 66, 2, 97, 25, 16, 20, 33]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9873/10000 (98.73%)\nRound 88/200\nSelected clients - [18, 94, 24, 69, 13, 35, 42, 82, 96, 90, 41, 15, 46, 1, 98, 49, 11, 63, 65, 78, 8, 25, 32, 23, 71, 10, 39, 3, 85, 53, 55, 89, 57, 26, 44, 97, 61, 52, 36, 37, 99, 2, 19, 6, 59, 70, 21, 48, 86, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9873/10000 (98.73%)\nRound 89/200\nSelected clients - [50, 24, 42, 23, 80, 1, 67, 89, 94, 43, 87, 59, 17, 28, 15, 92, 77, 22, 56, 52, 41, 55, 84, 39, 20, 85, 88, 90, 7, 19, 31, 81, 25, 86, 82, 91, 30, 62, 60, 79, 33, 29, 99, 73, 64, 95, 69, 45, 98, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9883/10000 (98.83%)\nRound 90/200\nSelected clients - [10, 98, 77, 90, 33, 17, 44, 8, 19, 53, 42, 26, 38, 89, 9, 73, 21, 59, 79, 0, 28, 18, 74, 82, 6, 71, 41, 11, 85, 52, 60, 99, 51, 35, 86, 94, 80, 1, 56, 97, 32, 14, 93, 5, 69, 83, 63, 50, 40, 22]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9885/10000 (98.85%)\nRound 91/200\nSelected clients - [26, 91, 11, 61, 84, 73, 75, 39, 81, 45, 57, 94, 92, 33, 62, 34, 47, 9, 69, 18, 5, 48, 83, 58, 13, 16, 98, 67, 23, 6, 82, 3, 15, 64, 36, 27, 72, 70, 42, 66, 4, 0, 76, 79, 63, 41, 10, 50, 1, 35]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9894/10000 (98.94%)\nRound 92/200\nSelected clients - [10, 75, 22, 87, 86, 20, 51, 58, 56, 59, 92, 32, 31, 24, 77, 47, 62, 27, 82, 49, 11, 79, 57, 69, 38, 80, 71, 44, 48, 70, 55, 97, 43, 68, 74, 84, 81, 89, 16, 50, 2, 33, 85, 3, 25, 63, 78, 34, 12, 4]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9882/10000 (98.82%)\nRound 93/200\nSelected clients - [53, 66, 72, 70, 71, 75, 34, 86, 12, 97, 98, 60, 20, 9, 73, 80, 43, 7, 5, 3, 21, 74, 87, 77, 52, 61, 79, 15, 19, 59, 8, 55, 46, 94, 4, 93, 85, 44, 11, 14, 38, 78, 88, 68, 96, 92, 30, 50, 0, 24]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9892/10000 (98.92%)\nRound 94/200\nSelected clients - [63, 72, 92, 45, 14, 11, 96, 18, 22, 50, 15, 20, 74, 4, 79, 70, 89, 85, 47, 51, 83, 9, 26, 28, 61, 88, 37, 73, 43, 27, 60, 8, 68, 7, 21, 13, 10, 5, 57, 48, 97, 80, 0, 64, 36, 49, 12, 55, 24, 78]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9885/10000 (98.85%)\nRound 95/200\nSelected clients - [69, 23, 15, 35, 38, 55, 2, 87, 63, 47, 39, 54, 76, 96, 68, 93, 94, 1, 83, 45, 58, 44, 27, 5, 52, 59, 20, 33, 16, 11, 95, 60, 86, 9, 90, 81, 78, 84, 34, 49, 82, 17, 42, 64, 14, 62, 28, 21, 97, 71]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9885/10000 (98.85%)\nRound 96/200\nSelected clients - [97, 68, 65, 94, 69, 16, 63, 3, 17, 1, 76, 10, 80, 35, 24, 5, 72, 67, 77, 85, 13, 46, 86, 49, 47, 19, 22, 23, 50, 43, 73, 71, 32, 99, 20, 14, 12, 70, 83, 55, 41, 30, 74, 0, 90, 61, 44, 33, 52, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9888/10000 (98.88%)\nRound 97/200\nSelected clients - [47, 40, 86, 50, 26, 12, 43, 5, 89, 2, 21, 52, 82, 98, 11, 32, 93, 45, 35, 16, 64, 1, 73, 61, 69, 76, 56, 97, 31, 44, 67, 65, 41, 3, 91, 7, 15, 28, 84, 88, 13, 23, 4, 8, 37, 99, 79, 81, 49, 19]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9893/10000 (98.93%)\nRound 98/200\nSelected clients - [24, 54, 47, 6, 73, 2, 71, 5, 94, 34, 97, 3, 9, 81, 56, 60, 14, 40, 31, 39, 23, 32, 52, 68, 99, 22, 13, 30, 69, 16, 8, 17, 95, 93, 35, 10, 7, 28, 4, 50, 15, 11, 1, 37, 87, 78, 12, 79, 92, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 99/200\nSelected clients - [45, 73, 5, 99, 53, 7, 60, 36, 86, 71, 8, 63, 25, 50, 4, 83, 46, 0, 82, 49, 38, 42, 97, 62, 24, 69, 21, 51, 22, 64, 75, 34, 65, 16, 27, 87, 52, 68, 6, 58, 56, 33, 80, 10, 88, 74, 59, 20, 31, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9888/10000 (98.88%)\nRound 100/200\nSelected clients - [51, 48, 25, 76, 22, 29, 31, 17, 11, 32, 49, 67, 87, 68, 91, 79, 62, 97, 53, 78, 75, 27, 47, 89, 80, 19, 59, 95, 43, 10, 88, 85, 60, 40, 99, 5, 34, 35, 0, 84, 13, 23, 63, 64, 94, 33, 12, 38, 55, 3]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 101/200\nSelected clients - [18, 58, 98, 22, 90, 50, 93, 44, 55, 64, 14, 68, 15, 10, 97, 33, 6, 82, 26, 42, 29, 39, 81, 96, 99, 24, 92, 47, 52, 77, 51, 59, 35, 48, 20, 87, 23, 0, 38, 25, 9, 49, 54, 36, 86, 12, 91, 1, 80, 95]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 102/200\nSelected clients - [74, 24, 69, 45, 59, 6, 84, 64, 27, 77, 28, 36, 62, 91, 42, 56, 9, 32, 98, 20, 11, 93, 68, 46, 81, 60, 41, 30, 51, 54, 26, 8, 55, 95, 38, 86, 14, 73, 52, 39, 43, 21, 85, 70, 17, 25, 50, 75, 63, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9891/10000 (98.91%)\nRound 103/200\nSelected clients - [18, 86, 78, 45, 21, 70, 91, 84, 77, 23, 49, 37, 79, 54, 72, 74, 5, 67, 69, 87, 66, 90, 48, 56, 29, 65, 16, 10, 6, 97, 76, 64, 28, 99, 62, 52, 61, 42, 4, 15, 39, 83, 53, 95, 24, 44, 12, 32, 27, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9891/10000 (98.91%)\nRound 104/200\nSelected clients - [91, 58, 92, 89, 94, 27, 88, 9, 77, 15, 83, 48, 59, 43, 90, 62, 10, 16, 28, 74, 3, 5, 81, 13, 82, 66, 37, 23, 52, 53, 29, 31, 11, 47, 25, 95, 60, 71, 75, 45, 18, 98, 76, 93, 33, 51, 69, 55, 12, 63]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 105/200\nSelected clients - [2, 25, 93, 29, 50, 42, 0, 91, 16, 99, 21, 13, 18, 15, 9, 83, 94, 47, 7, 98, 74, 32, 95, 41, 89, 38, 52, 5, 59, 57, 68, 31, 33, 23, 72, 12, 4, 79, 77, 51, 81, 73, 10, 92, 35, 26, 75, 63, 22, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 106/200\nSelected clients - [75, 44, 74, 13, 0, 39, 67, 73, 42, 37, 20, 98, 21, 18, 12, 84, 50, 88, 87, 55, 78, 49, 58, 63, 29, 23, 94, 93, 32, 7, 41, 14, 45, 97, 83, 64, 62, 52, 92, 71, 24, 90, 86, 56, 65, 76, 33, 82, 70, 36]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9892/10000 (98.92%)\nRound 107/200\nSelected clients - [90, 61, 2, 71, 67, 60, 7, 33, 8, 24, 63, 46, 55, 57, 83, 36, 28, 59, 35, 98, 17, 23, 81, 88, 62, 44, 9, 84, 74, 42, 22, 79, 87, 10, 4, 11, 41, 6, 76, 64, 50, 47, 78, 85, 96, 77, 19, 38, 16, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9888/10000 (98.88%)\nRound 108/200\nSelected clients - [31, 79, 74, 93, 84, 54, 61, 39, 17, 94, 69, 15, 32, 37, 76, 4, 35, 40, 24, 23, 75, 81, 19, 68, 91, 99, 47, 14, 9, 20, 8, 63, 78, 77, 58, 34, 11, 88, 98, 27, 60, 90, 52, 62, 95, 92, 66, 25, 18, 53]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9892/10000 (98.92%)\nRound 109/200\nSelected clients - [16, 91, 10, 84, 49, 93, 35, 48, 25, 97, 38, 27, 23, 98, 40, 24, 14, 96, 90, 71, 54, 13, 68, 41, 95, 88, 7, 72, 57, 4, 44, 42, 30, 86, 65, 62, 74, 1, 70, 67, 58, 80, 75, 56, 36, 73, 66, 11, 21, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9888/10000 (98.88%)\nRound 110/200\nSelected clients - [35, 29, 58, 57, 70, 7, 12, 98, 64, 63, 38, 72, 66, 10, 30, 96, 91, 99, 54, 21, 39, 95, 87, 40, 8, 77, 22, 1, 43, 25, 17, 23, 51, 84, 18, 81, 46, 9, 11, 2, 44, 88, 78, 56, 24, 76, 85, 94, 69, 59]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9888/10000 (98.88%)\nRound 111/200\nSelected clients - [49, 76, 31, 52, 61, 91, 35, 81, 69, 88, 9, 94, 53, 64, 40, 5, 14, 65, 10, 19, 56, 1, 67, 54, 75, 29, 93, 36, 46, 71, 86, 13, 96, 58, 73, 16, 24, 90, 26, 30, 83, 11, 28, 59, 98, 84, 97, 21, 77, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 112/200\nSelected clients - [27, 40, 63, 24, 50, 53, 78, 21, 80, 96, 89, 94, 71, 29, 23, 59, 88, 49, 35, 48, 28, 44, 97, 4, 98, 30, 72, 57, 52, 8, 54, 65, 13, 37, 12, 43, 58, 73, 67, 92, 15, 56, 32, 51, 1, 93, 55, 26, 75, 62]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9891/10000 (98.91%)\nRound 113/200\nSelected clients - [61, 85, 74, 79, 38, 89, 59, 53, 84, 20, 46, 28, 67, 58, 3, 49, 76, 30, 86, 93, 33, 44, 24, 29, 21, 57, 66, 78, 52, 51, 32, 2, 8, 87, 88, 39, 50, 41, 63, 81, 5, 37, 92, 70, 0, 4, 15, 16, 42, 35]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 114/200\nSelected clients - [3, 83, 92, 35, 2, 61, 70, 44, 30, 55, 99, 8, 38, 16, 76, 87, 63, 36, 84, 90, 43, 50, 24, 59, 49, 39, 4, 66, 45, 22, 28, 34, 98, 85, 21, 96, 52, 42, 17, 79, 12, 72, 97, 1, 95, 69, 11, 80, 71, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9888/10000 (98.88%)\nRound 115/200\nSelected clients - [30, 72, 12, 43, 85, 31, 80, 79, 6, 19, 66, 67, 86, 89, 37, 74, 8, 68, 47, 96, 13, 11, 59, 50, 14, 88, 38, 81, 84, 55, 58, 29, 61, 28, 42, 73, 97, 62, 5, 70, 83, 36, 65, 41, 16, 22, 10, 48, 33, 76]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9895/10000 (98.95%)\nRound 116/200\nSelected clients - [36, 25, 14, 68, 97, 42, 70, 37, 86, 81, 99, 87, 43, 61, 7, 93, 84, 18, 19, 5, 89, 22, 62, 75, 31, 21, 23, 82, 67, 27, 72, 54, 1, 98, 94, 76, 35, 38, 57, 95, 16, 53, 26, 96, 73, 63, 12, 30, 88, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9896/10000 (98.96%)\nRound 117/200\nSelected clients - [95, 76, 69, 92, 38, 1, 82, 15, 16, 61, 90, 31, 35, 52, 74, 54, 73, 9, 57, 8, 40, 66, 41, 63, 7, 71, 78, 13, 51, 56, 21, 46, 18, 62, 10, 59, 26, 36, 25, 34, 91, 45, 86, 23, 55, 89, 2, 27, 85, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9891/10000 (98.91%)\nRound 118/200\nSelected clients - [30, 23, 21, 26, 51, 20, 71, 52, 89, 15, 67, 72, 42, 44, 58, 83, 4, 16, 47, 55, 8, 94, 80, 49, 54, 53, 0, 78, 75, 98, 18, 61, 56, 76, 29, 22, 43, 7, 37, 57, 5, 39, 85, 1, 2, 13, 97, 70, 96, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 119/200\nSelected clients - [91, 80, 23, 39, 12, 89, 46, 37, 2, 38, 42, 3, 77, 63, 65, 87, 43, 72, 66, 18, 74, 85, 0, 26, 82, 16, 48, 36, 8, 7, 93, 94, 58, 55, 11, 57, 24, 79, 54, 53, 68, 41, 84, 49, 30, 5, 29, 64, 4, 9]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9891/10000 (98.91%)\nRound 120/200\nSelected clients - [36, 23, 94, 68, 85, 70, 55, 13, 10, 54, 80, 31, 22, 32, 35, 26, 60, 74, 2, 51, 86, 93, 7, 43, 84, 16, 59, 1, 66, 71, 63, 53, 92, 5, 30, 27, 61, 24, 65, 34, 38, 73, 95, 11, 49, 4, 0, 91, 46, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9897/10000 (98.97%)\nRound 122/200\nSelected clients - [11, 27, 74, 50, 80, 22, 78, 66, 94, 42, 36, 23, 81, 54, 7, 77, 55, 16, 3, 60, 86, 43, 57, 75, 29, 19, 44, 88, 83, 14, 41, 30, 79, 62, 72, 69, 70, 26, 1, 9, 56, 21, 76, 65, 59, 47, 38, 39, 0, 35]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9896/10000 (98.96%)\nRound 123/200\nSelected clients - [65, 27, 76, 38, 9, 93, 46, 28, 58, 85, 75, 20, 13, 96, 57, 30, 71, 50, 48, 80, 18, 42, 35, 60, 95, 49, 15, 66, 90, 10, 67, 63, 36, 47, 5, 40, 82, 98, 89, 43, 23, 24, 4, 29, 99, 86, 1, 0, 12, 84]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9890/10000 (98.90%)\nRound 126/200\nSelected clients - [31, 28, 76, 38, 72, 94, 23, 44, 19, 77, 39, 78, 80, 0, 9, 81, 91, 60, 64, 53, 12, 32, 37, 20, 62, 93, 75, 18, 6, 35, 68, 54, 3, 22, 97, 8, 7, 27, 50, 58, 90, 61, 5, 24, 29, 40, 33, 2, 30, 79]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 130/200\nSelected clients - [75, 66, 34, 5, 88, 51, 80, 28, 42, 29, 14, 70, 19, 17, 35, 72, 90, 86, 61, 76, 58, 82, 13, 33, 9, 93, 11, 54, 96, 30, 22, 12, 95, 81, 6, 32, 37, 20, 79, 99, 62, 67, 64, 39, 50, 84, 65, 46, 57, 45]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 131/200\nSelected clients - [66, 54, 34, 94, 84, 56, 82, 58, 2, 45, 30, 74, 43, 28, 87, 95, 67, 13, 71, 26, 90, 91, 53, 3, 47, 18, 76, 63, 98, 85, 62, 48, 50, 10, 5, 17, 16, 39, 81, 19, 7, 92, 9, 77, 57, 83, 65, 51, 86, 25]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 132/200\nSelected clients - [40, 47, 65, 11, 50, 36, 2, 49, 15, 44, 72, 76, 12, 21, 28, 70, 56, 62, 25, 85, 69, 6, 86, 57, 75, 26, 55, 8, 1, 63, 33, 73, 96, 19, 89, 77, 67, 58, 95, 38, 23, 7, 92, 34, 39, 24, 13, 10, 68, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 133/200\nSelected clients - [52, 19, 99, 7, 21, 5, 39, 15, 69, 3, 31, 57, 33, 25, 88, 95, 73, 51, 89, 63, 79, 68, 71, 47, 48, 42, 86, 8, 70, 94, 45, 67, 11, 98, 91, 72, 36, 16, 22, 50, 64, 40, 2, 76, 30, 14, 49, 6, 29, 59]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 134/200\nSelected clients - [63, 45, 61, 41, 78, 43, 69, 88, 79, 90, 4, 10, 36, 84, 33, 87, 27, 0, 48, 64, 54, 20, 11, 86, 19, 82, 52, 96, 23, 37, 8, 16, 15, 72, 92, 42, 32, 31, 56, 89, 55, 60, 99, 25, 53, 62, 14, 77, 68, 6]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 135/200\nSelected clients - [61, 66, 25, 92, 71, 96, 81, 16, 3, 83, 62, 14, 49, 28, 89, 31, 76, 69, 58, 91, 13, 36, 98, 35, 38, 8, 33, 48, 45, 73, 95, 18, 77, 50, 78, 75, 42, 65, 59, 80, 4, 97, 88, 15, 44, 74, 82, 6, 51, 11]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 136/200\nSelected clients - [85, 47, 80, 82, 74, 35, 62, 37, 90, 15, 57, 36, 1, 75, 19, 98, 81, 33, 46, 44, 39, 34, 86, 94, 32, 76, 4, 24, 88, 0, 77, 66, 10, 92, 96, 45, 43, 73, 14, 49, 54, 5, 61, 52, 64, 11, 55, 50, 97, 72]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 137/200\nSelected clients - [73, 54, 67, 7, 55, 63, 25, 98, 89, 17, 21, 81, 94, 5, 20, 96, 77, 6, 93, 24, 83, 35, 45, 51, 62, 3, 9, 33, 69, 74, 86, 22, 41, 65, 39, 26, 32, 16, 27, 95, 82, 42, 48, 47, 97, 76, 92, 75, 36, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9893/10000 (98.93%)\nRound 138/200\nSelected clients - [9, 23, 52, 41, 24, 29, 62, 44, 1, 51, 65, 96, 50, 67, 60, 17, 54, 66, 82, 42, 0, 78, 3, 18, 61, 46, 22, 92, 31, 93, 49, 88, 40, 91, 90, 43, 8, 74, 73, 72, 32, 7, 12, 2, 38, 20, 34, 36, 35, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9893/10000 (98.93%)\nRound 139/200\nSelected clients - [24, 48, 57, 89, 38, 26, 66, 34, 31, 23, 18, 56, 21, 43, 94, 10, 62, 69, 11, 17, 28, 19, 41, 2, 47, 29, 6, 78, 33, 53, 80, 95, 51, 8, 50, 76, 98, 88, 64, 65, 52, 77, 32, 63, 0, 1, 86, 97, 30, 15]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 140/200\nSelected clients - [0, 88, 78, 68, 77, 84, 38, 70, 99, 67, 43, 35, 44, 74, 19, 95, 34, 29, 72, 93, 62, 17, 40, 65, 1, 90, 23, 94, 96, 46, 8, 13, 32, 64, 3, 91, 57, 85, 49, 83, 76, 14, 37, 86, 4, 81, 5, 63, 27, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9896/10000 (98.96%)\nRound 141/200\nSelected clients - [98, 12, 3, 34, 2, 68, 93, 6, 86, 28, 1, 65, 24, 48, 81, 49, 39, 92, 22, 29, 77, 87, 52, 56, 37, 7, 69, 70, 54, 50, 25, 62, 82, 76, 18, 17, 21, 42, 73, 47, 51, 75, 67, 94, 96, 43, 59, 53, 30, 46]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 142/200\nSelected clients - [66, 3, 74, 60, 22, 73, 89, 59, 0, 34, 83, 71, 1, 43, 52, 30, 90, 65, 44, 79, 61, 69, 23, 20, 81, 46, 72, 28, 78, 32, 96, 88, 33, 80, 93, 53, 21, 67, 54, 14, 51, 77, 48, 2, 42, 38, 35, 31, 82, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 143/200\nSelected clients - [74, 88, 87, 81, 62, 21, 95, 36, 44, 45, 33, 4, 12, 37, 94, 73, 71, 26, 77, 68, 98, 60, 31, 97, 40, 66, 42, 11, 8, 61, 15, 34, 17, 0, 56, 48, 30, 90, 64, 20, 65, 25, 53, 7, 18, 84, 67, 93, 22, 1]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9898/10000 (98.98%)\nRound 144/200\nSelected clients - [23, 5, 2, 28, 18, 31, 10, 52, 63, 17, 73, 16, 11, 75, 37, 55, 12, 35, 77, 91, 49, 89, 14, 36, 85, 46, 59, 20, 54, 38, 87, 94, 41, 25, 61, 27, 29, 44, 97, 32, 30, 79, 58, 83, 76, 57, 22, 88, 92, 40]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9898/10000 (98.98%)\nRound 145/200\nSelected clients - [57, 4, 58, 10, 92, 21, 50, 11, 84, 52, 63, 75, 30, 59, 17, 28, 53, 98, 86, 15, 87, 64, 32, 79, 33, 5, 51, 96, 67, 44, 26, 76, 90, 95, 56, 55, 24, 48, 66, 38, 25, 19, 71, 9, 16, 6, 47, 91, 81, 43]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 146/200\nSelected clients - [96, 54, 66, 0, 56, 3, 84, 41, 83, 87, 60, 72, 65, 35, 14, 33, 23, 7, 77, 40, 95, 5, 81, 34, 86, 32, 51, 91, 92, 99, 90, 62, 4, 22, 6, 26, 78, 28, 45, 38, 27, 29, 47, 76, 43, 19, 42, 46, 59, 97]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 147/200\nSelected clients - [17, 99, 79, 42, 8, 20, 72, 36, 10, 44, 5, 27, 84, 52, 39, 68, 54, 19, 92, 96, 9, 4, 1, 56, 78, 50, 16, 76, 24, 59, 28, 49, 87, 43, 57, 65, 61, 93, 22, 31, 37, 97, 21, 80, 62, 81, 6, 15, 91, 77]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 148/200\nSelected clients - [77, 82, 19, 50, 56, 78, 57, 23, 80, 39, 53, 58, 13, 59, 45, 8, 89, 44, 98, 43, 75, 25, 30, 24, 7, 88, 16, 64, 9, 38, 29, 76, 4, 92, 36, 33, 51, 31, 47, 87, 32, 5, 15, 65, 26, 85, 60, 46, 74, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 149/200\nSelected clients - [51, 89, 81, 4, 86, 99, 44, 36, 34, 13, 24, 63, 80, 9, 32, 68, 73, 28, 53, 40, 52, 78, 1, 48, 43, 38, 3, 33, 83, 42, 23, 65, 95, 91, 31, 55, 54, 87, 59, 62, 29, 47, 8, 98, 72, 97, 69, 66, 20, 0]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 150/200\nSelected clients - [9, 12, 32, 48, 17, 95, 7, 2, 22, 73, 5, 51, 6, 93, 38, 98, 24, 63, 94, 8, 49, 11, 20, 4, 88, 43, 60, 58, 33, 52, 97, 90, 18, 36, 3, 46, 68, 84, 23, 62, 99, 61, 64, 71, 81, 66, 0, 10, 80, 74]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 151/200\nSelected clients - [41, 51, 24, 29, 38, 61, 18, 20, 53, 11, 37, 42, 36, 56, 50, 6, 17, 83, 62, 47, 90, 95, 94, 44, 16, 1, 7, 13, 93, 26, 34, 63, 59, 3, 58, 21, 28, 2, 49, 19, 68, 12, 77, 35, 71, 73, 74, 48, 82, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 152/200\nSelected clients - [90, 52, 91, 80, 92, 26, 45, 36, 47, 73, 14, 59, 62, 99, 9, 58, 13, 51, 95, 23, 74, 46, 71, 15, 17, 19, 38, 22, 72, 77, 43, 53, 7, 69, 56, 83, 81, 50, 97, 79, 10, 33, 93, 32, 63, 42, 29, 89, 8, 6]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9900/10000 (99.00%)\nRound 153/200\nSelected clients - [96, 50, 80, 18, 48, 25, 11, 79, 2, 15, 97, 14, 3, 44, 62, 77, 22, 58, 31, 30, 9, 37, 69, 4, 38, 41, 82, 74, 33, 27, 65, 55, 76, 12, 93, 88, 90, 95, 67, 54, 84, 94, 70, 0, 83, 73, 66, 71, 5, 64]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9900/10000 (99.00%)\nRound 154/200\nSelected clients - [62, 9, 4, 33, 90, 53, 74, 72, 76, 71, 40, 54, 31, 65, 86, 89, 91, 26, 87, 28, 94, 77, 92, 98, 32, 27, 44, 37, 7, 45, 52, 63, 21, 5, 67, 85, 79, 80, 48, 84, 2, 10, 13, 88, 24, 11, 20, 78, 19, 47]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 155/200\nSelected clients - [26, 48, 62, 99, 56, 65, 0, 57, 33, 50, 54, 83, 81, 74, 6, 92, 67, 7, 49, 69, 52, 84, 59, 76, 9, 91, 37, 21, 4, 45, 38, 13, 61, 23, 71, 34, 28, 79, 10, 3, 36, 20, 35, 85, 25, 63, 95, 80, 12, 55]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 156/200\nSelected clients - [74, 64, 69, 36, 87, 53, 97, 68, 94, 99, 35, 24, 83, 7, 73, 3, 67, 11, 22, 81, 30, 12, 8, 95, 4, 29, 43, 10, 62, 26, 86, 65, 27, 15, 78, 55, 44, 37, 93, 58, 33, 18, 89, 40, 79, 28, 84, 0, 39, 31]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9903/10000 (99.03%)\nRound 157/200\nSelected clients - [62, 53, 94, 31, 45, 19, 28, 20, 17, 71, 57, 48, 42, 97, 10, 86, 91, 1, 56, 4, 68, 50, 88, 0, 73, 44, 13, 37, 46, 6, 18, 64, 58, 21, 32, 3, 5, 15, 80, 61, 9, 78, 77, 93, 83, 69, 8, 22, 27, 39]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 158/200\nSelected clients - [78, 62, 28, 20, 2, 3, 44, 93, 29, 40, 17, 11, 22, 97, 13, 95, 14, 50, 52, 48, 38, 71, 85, 55, 60, 21, 94, 83, 42, 43, 47, 46, 31, 34, 88, 37, 92, 84, 76, 5, 35, 4, 32, 45, 1, 70, 8, 99, 56, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 159/200\nSelected clients - [87, 28, 13, 7, 53, 72, 42, 81, 59, 92, 5, 8, 14, 0, 71, 36, 6, 96, 10, 77, 68, 35, 4, 26, 82, 60, 30, 11, 49, 40, 69, 99, 20, 90, 17, 97, 44, 33, 19, 67, 21, 78, 43, 61, 15, 16, 54, 63, 56, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 160/200\nSelected clients - [50, 21, 86, 57, 31, 66, 25, 79, 24, 2, 62, 48, 4, 34, 85, 49, 28, 60, 52, 37, 41, 32, 40, 30, 3, 74, 27, 51, 63, 82, 7, 11, 23, 43, 71, 95, 26, 78, 14, 10, 97, 17, 53, 16, 38, 1, 5, 96, 70, 73]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 161/200\nSelected clients - [15, 64, 43, 51, 22, 75, 44, 91, 66, 63, 68, 27, 54, 60, 1, 35, 99, 42, 6, 29, 81, 55, 53, 65, 47, 58, 37, 36, 39, 25, 2, 72, 23, 74, 9, 24, 19, 76, 26, 80, 90, 45, 93, 0, 70, 73, 18, 67, 85, 92]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 162/200\nSelected clients - [66, 26, 70, 21, 29, 81, 75, 61, 4, 89, 92, 62, 6, 58, 7, 90, 79, 9, 76, 60, 0, 1, 33, 67, 35, 51, 80, 98, 44, 59, 68, 77, 53, 19, 56, 87, 88, 10, 14, 24, 17, 49, 34, 42, 72, 2, 78, 97, 57, 30]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9898/10000 (98.98%)\nRound 163/200\nSelected clients - [6, 88, 80, 26, 64, 25, 52, 63, 78, 37, 57, 58, 3, 23, 15, 53, 40, 82, 71, 8, 98, 73, 2, 35, 9, 18, 93, 79, 5, 0, 27, 22, 95, 70, 14, 89, 32, 65, 76, 17, 13, 94, 56, 47, 85, 84, 16, 72, 12, 42]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9898/10000 (98.98%)\nRound 164/200\nSelected clients - [69, 79, 58, 74, 22, 63, 36, 27, 45, 26, 46, 17, 18, 95, 78, 7, 8, 43, 19, 84, 9, 59, 99, 83, 66, 93, 56, 20, 89, 67, 87, 76, 41, 44, 62, 73, 70, 65, 60, 94, 15, 11, 37, 39, 1, 42, 23, 32, 6, 57]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 165/200\nSelected clients - [12, 94, 38, 32, 59, 62, 77, 49, 15, 10, 53, 50, 0, 75, 24, 19, 39, 40, 14, 57, 93, 9, 70, 81, 11, 46, 7, 36, 4, 43, 91, 67, 25, 56, 90, 69, 71, 80, 99, 17, 5, 61, 41, 66, 2, 79, 54, 28, 76, 68]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9898/10000 (98.98%)\nRound 166/200\nSelected clients - [2, 7, 91, 55, 9, 63, 29, 22, 54, 86, 40, 74, 61, 98, 25, 8, 53, 16, 77, 52, 6, 96, 67, 48, 31, 13, 87, 62, 97, 33, 19, 81, 35, 24, 23, 39, 26, 4, 66, 84, 95, 44, 85, 21, 90, 41, 68, 46, 56, 99]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 167/200\nSelected clients - [22, 80, 77, 52, 54, 1, 41, 4, 62, 72, 47, 37, 86, 25, 21, 94, 63, 12, 24, 49, 15, 0, 20, 34, 74, 27, 91, 65, 97, 40, 57, 35, 26, 66, 71, 30, 59, 60, 76, 73, 3, 16, 29, 17, 50, 48, 93, 10, 45, 70]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 168/200\nSelected clients - [29, 11, 42, 54, 41, 94, 92, 10, 66, 0, 55, 78, 63, 31, 7, 14, 98, 19, 38, 52, 85, 91, 36, 21, 9, 75, 90, 8, 64, 53, 83, 3, 45, 57, 95, 18, 65, 97, 23, 1, 28, 46, 80, 73, 87, 58, 69, 44, 16, 82]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 169/200\nSelected clients - [95, 14, 66, 47, 48, 23, 28, 68, 24, 25, 69, 65, 63, 77, 27, 78, 49, 98, 82, 53, 67, 44, 84, 41, 75, 21, 99, 70, 32, 58, 3, 0, 26, 76, 91, 19, 52, 93, 83, 38, 1, 51, 79, 20, 18, 85, 9, 42, 57, 87]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 170/200\nSelected clients - [32, 66, 79, 22, 71, 65, 15, 67, 44, 68, 34, 60, 72, 26, 9, 77, 0, 16, 88, 5, 29, 56, 18, 6, 64, 86, 40, 38, 95, 80, 55, 21, 24, 49, 7, 58, 63, 23, 75, 47, 17, 74, 69, 13, 61, 87, 11, 62, 41, 12]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 171/200\nSelected clients - [44, 75, 40, 97, 11, 31, 41, 33, 74, 15, 27, 1, 49, 64, 38, 73, 63, 90, 66, 99, 84, 94, 0, 23, 58, 96, 22, 59, 79, 71, 93, 77, 56, 88, 98, 14, 45, 37, 2, 82, 92, 48, 68, 21, 25, 76, 4, 46, 67, 32]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 172/200\nSelected clients - [71, 49, 52, 15, 75, 59, 86, 22, 48, 39, 41, 23, 92, 87, 17, 29, 18, 99, 79, 31, 24, 13, 88, 7, 82, 40, 10, 42, 50, 96, 61, 16, 68, 66, 69, 55, 3, 27, 46, 73, 0, 14, 77, 80, 74, 57, 63, 33, 51, 12]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 173/200\nSelected clients - [45, 24, 27, 38, 99, 94, 6, 50, 59, 71, 56, 26, 73, 93, 89, 96, 87, 12, 54, 0, 67, 17, 28, 79, 85, 34, 44, 43, 15, 31, 52, 86, 61, 81, 57, 76, 41, 19, 80, 55, 25, 1, 60, 91, 63, 46, 97, 29, 39, 88]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 174/200\nSelected clients - [41, 62, 85, 92, 65, 76, 46, 31, 52, 0, 44, 90, 19, 57, 87, 58, 80, 28, 24, 9, 74, 72, 88, 84, 18, 40, 49, 12, 73, 81, 39, 15, 35, 48, 66, 77, 21, 29, 30, 5, 8, 78, 82, 43, 69, 13, 42, 17, 26, 94]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9900/10000 (99.00%)\nRound 175/200\nSelected clients - [0, 56, 3, 63, 46, 8, 28, 30, 13, 43, 55, 83, 47, 86, 72, 11, 41, 42, 76, 88, 58, 2, 68, 14, 70, 7, 36, 98, 96, 34, 74, 32, 87, 59, 69, 82, 4, 97, 15, 90, 84, 10, 93, 49, 66, 37, 31, 23, 78, 91]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 176/200\nSelected clients - [56, 30, 6, 92, 73, 88, 94, 64, 24, 32, 76, 9, 63, 65, 62, 58, 4, 35, 77, 23, 69, 38, 80, 85, 71, 59, 99, 44, 26, 74, 72, 79, 60, 13, 5, 83, 68, 14, 2, 43, 12, 81, 46, 33, 50, 57, 91, 53, 54, 17]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9903/10000 (99.03%)\nRound 177/200\nSelected clients - [3, 7, 28, 14, 49, 81, 40, 80, 83, 73, 61, 12, 0, 99, 39, 78, 45, 93, 60, 85, 33, 41, 71, 54, 94, 2, 22, 57, 29, 76, 1, 5, 36, 48, 58, 42, 79, 34, 20, 26, 23, 74, 24, 16, 6, 97, 72, 4, 77, 98]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 178/200\nSelected clients - [27, 63, 53, 74, 24, 90, 51, 5, 54, 82, 76, 38, 35, 11, 15, 13, 70, 45, 52, 47, 83, 58, 93, 9, 12, 72, 29, 37, 20, 55, 89, 25, 16, 46, 17, 81, 44, 94, 22, 56, 61, 21, 98, 0, 60, 79, 87, 73, 88, 36]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9902/10000 (99.02%)\nRound 179/200\nSelected clients - [14, 71, 59, 82, 30, 43, 93, 61, 36, 23, 10, 57, 95, 70, 28, 35, 92, 87, 21, 66, 64, 49, 97, 99, 12, 22, 15, 33, 84, 51, 89, 2, 54, 80, 32, 46, 13, 1, 55, 11, 63, 40, 6, 39, 78, 85, 42, 50, 34, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 180/200\nSelected clients - [25, 15, 8, 7, 66, 38, 56, 6, 74, 32, 28, 72, 31, 94, 40, 70, 63, 16, 42, 20, 76, 75, 33, 21, 22, 24, 10, 86, 3, 96, 61, 13, 92, 71, 69, 9, 14, 35, 51, 50, 0, 49, 5, 77, 36, 82, 11, 79, 83, 64]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9897/10000 (98.97%)\nRound 181/200\nSelected clients - [18, 10, 86, 1, 79, 33, 15, 75, 64, 57, 31, 76, 4, 17, 93, 0, 83, 3, 97, 24, 14, 23, 52, 67, 60, 85, 34, 42, 82, 29, 7, 71, 51, 94, 91, 49, 54, 56, 19, 38, 5, 96, 78, 65, 95, 74, 22, 2, 88, 44]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 182/200\nSelected clients - [74, 89, 13, 7, 42, 43, 24, 39, 95, 29, 57, 58, 31, 8, 28, 3, 96, 92, 46, 35, 36, 80, 76, 49, 81, 50, 78, 25, 4, 88, 48, 97, 55, 85, 27, 16, 98, 63, 94, 9, 75, 44, 56, 59, 2, 53, 51, 70, 14, 83]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 183/200\nSelected clients - [57, 45, 29, 97, 40, 44, 36, 9, 91, 34, 4, 80, 64, 59, 35, 11, 84, 27, 47, 3, 12, 19, 73, 20, 70, 28, 68, 2, 30, 66, 58, 16, 87, 41, 67, 21, 98, 24, 31, 49, 13, 69, 86, 71, 0, 62, 61, 92, 82, 56]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 184/200\nSelected clients - [13, 11, 95, 0, 45, 38, 28, 98, 66, 92, 1, 82, 4, 9, 54, 79, 75, 81, 29, 68, 89, 57, 5, 73, 77, 52, 48, 6, 19, 12, 41, 50, 51, 94, 34, 37, 3, 61, 24, 74, 18, 40, 83, 26, 15, 87, 2, 16, 14, 43]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9905/10000 (99.05%)\nRound 185/200\nSelected clients - [35, 0, 30, 88, 89, 41, 42, 43, 79, 68, 26, 57, 74, 85, 1, 16, 65, 99, 93, 22, 45, 29, 8, 94, 19, 13, 69, 9, 64, 40, 86, 76, 53, 72, 36, 3, 46, 49, 44, 51, 52, 96, 80, 60, 33, 95, 34, 6, 61, 81]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 186/200\nSelected clients - [14, 19, 98, 38, 75, 62, 60, 51, 22, 0, 74, 30, 33, 55, 68, 3, 81, 26, 48, 87, 67, 78, 80, 61, 23, 71, 83, 44, 16, 15, 95, 69, 64, 5, 92, 93, 45, 84, 41, 8, 76, 99, 66, 54, 65, 28, 85, 24, 18, 10]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 187/200\nSelected clients - [43, 84, 53, 70, 57, 13, 60, 87, 15, 0, 25, 99, 71, 91, 56, 44, 5, 95, 50, 93, 58, 17, 73, 12, 65, 45, 10, 37, 8, 14, 96, 64, 21, 30, 4, 90, 34, 62, 3, 48, 86, 7, 9, 80, 89, 18, 75, 81, 55, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 188/200\nSelected clients - [44, 60, 75, 19, 74, 3, 95, 70, 31, 63, 58, 21, 97, 57, 99, 28, 42, 30, 32, 79, 76, 43, 86, 9, 85, 66, 65, 50, 55, 23, 20, 61, 92, 47, 37, 33, 10, 89, 8, 46, 45, 64, 36, 62, 91, 6, 22, 18, 96, 26]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 189/200\nSelected clients - [90, 28, 33, 0, 30, 9, 88, 34, 50, 97, 44, 38, 92, 14, 13, 3, 65, 63, 60, 89, 86, 31, 99, 5, 40, 51, 26, 83, 81, 94, 25, 6, 22, 24, 43, 42, 77, 19, 72, 46, 54, 7, 36, 79, 96, 48, 82, 74, 95, 91]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9900/10000 (99.00%)\nRound 190/200\nSelected clients - [61, 95, 35, 18, 73, 70, 14, 51, 0, 67, 1, 87, 4, 98, 96, 25, 39, 37, 88, 92, 12, 74, 93, 58, 68, 26, 91, 50, 20, 28, 84, 71, 55, 52, 2, 83, 43, 6, 5, 65, 45, 29, 33, 23, 81, 21, 3, 46, 22, 41]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 191/200\nSelected clients - [9, 21, 96, 42, 47, 26, 28, 60, 50, 99, 19, 10, 67, 7, 75, 68, 8, 66, 45, 39, 91, 6, 43, 94, 49, 83, 57, 61, 36, 70, 15, 87, 17, 97, 76, 0, 48, 54, 37, 12, 25, 34, 56, 31, 62, 24, 71, 77, 30, 98]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9905/10000 (99.05%)\nRound 192/200\nSelected clients - [97, 67, 70, 65, 64, 18, 51, 81, 89, 61, 7, 78, 14, 6, 93, 90, 46, 54, 47, 86, 10, 28, 37, 3, 96, 71, 83, 1, 77, 34, 73, 29, 76, 69, 88, 20, 41, 30, 39, 15, 68, 25, 59, 26, 33, 62, 22, 85, 50, 98]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 193/200\nSelected clients - [47, 38, 11, 59, 39, 54, 42, 94, 35, 87, 29, 99, 23, 16, 50, 90, 21, 34, 58, 25, 33, 43, 36, 63, 85, 30, 89, 32, 65, 80, 28, 72, 20, 46, 69, 51, 40, 45, 79, 88, 6, 44, 24, 3, 12, 98, 81, 68, 61, 8]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 194/200\nSelected clients - [71, 59, 97, 22, 38, 99, 34, 67, 28, 3, 39, 19, 58, 69, 85, 76, 26, 27, 62, 64, 94, 35, 41, 79, 44, 84, 29, 82, 33, 23, 36, 55, 45, 11, 42, 66, 65, 24, 53, 88, 32, 12, 47, 13, 9, 89, 6, 18, 5, 70]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9903/10000 (99.03%)\nRound 195/200\nSelected clients - [77, 8, 74, 19, 45, 49, 32, 55, 56, 69, 92, 52, 47, 18, 81, 13, 80, 21, 53, 15, 72, 27, 70, 84, 71, 86, 95, 59, 35, 11, 78, 90, 51, 58, 82, 91, 28, 30, 79, 61, 76, 44, 5, 65, 68, 41, 34, 75, 24, 16]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 196/200\nSelected clients - [76, 50, 5, 82, 25, 86, 26, 98, 10, 96, 38, 72, 79, 95, 40, 43, 30, 8, 70, 65, 55, 18, 13, 83, 12, 91, 66, 7, 6, 78, 69, 20, 17, 85, 2, 52, 39, 73, 71, 22, 14, 87, 89, 62, 84, 93, 59, 63, 57, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9905/10000 (99.05%)\nRound 197/200\nSelected clients - [83, 64, 91, 99, 97, 3, 26, 54, 84, 82, 40, 10, 38, 19, 98, 35, 76, 13, 17, 70, 39, 78, 95, 45, 73, 92, 8, 72, 61, 80, 77, 21, 7, 52, 48, 14, 49, 11, 81, 16, 51, 32, 89, 53, 96, 34, 75, 12, 42, 55]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9906/10000 (99.06%)\nRound 198/200\nSelected clients - [69, 1, 16, 20, 2, 88, 24, 74, 15, 5, 92, 62, 58, 12, 26, 89, 53, 28, 79, 21, 19, 84, 94, 52, 63, 99, 70, 38, 61, 72, 9, 31, 83, 30, 60, 75, 45, 86, 18, 51, 34, 33, 47, 56, 96, 17, 80, 50, 73, 68]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0027, Accuracy: 9907/10000 (99.07%)\nRound 199/200\nSelected clients - [6, 73, 91, 61, 12, 85, 96, 58, 99, 67, 37, 25, 55, 23, 49, 3, 76, 62, 68, 74, 75, 43, 32, 41, 30, 95, 7, 28, 50, 69, 24, 64, 87, 53, 16, 14, 36, 79, 52, 86, 70, 20, 44, 84, 81, 18, 80, 4, 56, 26]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9906/10000 (99.06%)\nRound 200/200\nSelected clients - [44, 95, 50, 35, 85, 91, 39, 1, 61, 88, 65, 99, 32, 30, 73, 43, 68, 48, 3, 66, 98, 97, 63, 64, 29, 77, 18, 80, 40, 82, 71, 55, 47, 2, 70, 24, 38, 52, 17, 79, 5, 51, 72, 92, 41, 49, 96, 67, 89, 37]\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:22<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nTarget accuracy reached at round: 118\nBest round: 198, accuracy: 0.9907\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Statistics","metadata":{"id":"VIENpKmy65fT"}},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(accuracies)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Um5mHx2E65fT","outputId":"3be8cfe8-3876-4205-bdbd-aebf5b2bed9f","execution":{"iopub.status.busy":"2023-05-24T15:55:14.744752Z","iopub.execute_input":"2023-05-24T15:55:14.745346Z","iopub.status.idle":"2023-05-24T15:55:14.750653Z","shell.execute_reply.started":"2023-05-24T15:55:14.745311Z","shell.execute_reply":"2023-05-24T15:55:14.749685Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[0.1109, 0.4803, 0.8217, 0.8709, 0.9214, 0.913, 0.9012, 0.9419, 0.9447, 0.9509, 0.9567, 0.9567, 0.9582, 0.9589, 0.9654, 0.9711, 0.9702, 0.9704, 0.9699, 0.9754, 0.9732, 0.9784, 0.9777, 0.9782, 0.9762, 0.976, 0.9792, 0.9808, 0.9804, 0.9807, 0.9823, 0.9813, 0.9833, 0.9834, 0.9829, 0.9825, 0.9825, 0.9831, 0.9842, 0.9839, 0.9854, 0.9837, 0.9846, 0.9847, 0.9841, 0.9845, 0.9851, 0.9855, 0.9857, 0.9855, 0.9848, 0.9845, 0.9853, 0.9854, 0.9854, 0.9861, 0.9849, 0.9865, 0.9869, 0.9858, 0.986, 0.9868, 0.9868, 0.9876, 0.9875, 0.9873, 0.9877, 0.9885, 0.9865, 0.9884, 0.9877, 0.9876, 0.9882, 0.9876, 0.9879, 0.9882, 0.9883, 0.9885, 0.989, 0.9883, 0.9878, 0.9881, 0.9878, 0.9884, 0.988, 0.9889, 0.9873, 0.9873, 0.9883, 0.9885, 0.9894, 0.9882, 0.9892, 0.9885, 0.9885, 0.9888, 0.9893, 0.9892, 0.9888, 0.9894, 0.9894, 0.9891, 0.9891, 0.9892, 0.9894, 0.9892, 0.9888, 0.9892, 0.9888, 0.9888, 0.9895, 0.9891, 0.9895, 0.9888, 0.9895, 0.9896, 0.9891, 0.9902, 0.9891, 0.9892, 0.9897, 0.9896, 0.9897, 0.9896, 0.989, 0.9894, 0.9896, 0.9901, 0.99, 0.9898, 0.9899, 0.9899, 0.9899, 0.9899, 0.9897, 0.9899, 0.9893, 0.9893, 0.9898, 0.9896, 0.99, 0.9897, 0.9898, 0.9898, 0.9904, 0.9904, 0.9901, 0.9897, 0.9898, 0.9901, 0.99, 0.99, 0.99, 0.9904, 0.9898, 0.9903, 0.9901, 0.9904, 0.9904, 0.99, 0.9895, 0.9898, 0.9898, 0.9904, 0.9898, 0.9897, 0.9904, 0.99, 0.9902, 0.9899, 0.9899, 0.9901, 0.9904, 0.99, 0.9902, 0.9903, 0.9901, 0.9902, 0.9903, 0.9897, 0.9904, 0.99, 0.9899, 0.9905, 0.9904, 0.9901, 0.9903, 0.9898, 0.99, 0.9902, 0.9905, 0.9903, 0.9901, 0.9903, 0.9904, 0.9905, 0.9906, 0.9907, 0.9906, 0.9904]\n","output_type":"stream"}]},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(losses)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfI_uBW-65fU","outputId":"938c6c2f-03c1-4a42-9ee7-e32cd9ad093b","execution":{"iopub.status.busy":"2023-05-24T15:55:14.752085Z","iopub.execute_input":"2023-05-24T15:55:14.752664Z","iopub.status.idle":"2023-05-24T15:55:14.762480Z","shell.execute_reply.started":"2023-05-24T15:55:14.752632Z","shell.execute_reply":"2023-05-24T15:55:14.761503Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[0.2294428565979004, 0.19804232438802719, 0.1317692805111408, 0.07640471901297569, 0.05734062692970038, 0.03607885385155678, 0.04077600905299187, 0.029380396170541643, 0.02140809791125357, 0.019989163278741763, 0.020334548178408296, 0.016551808602223172, 0.015141839401121251, 0.01377578034211183, 0.011361411269719247, 0.010474561111052754, 0.0114865773455007, 0.00964682058171602, 0.011701201695040799, 0.008623648743252853, 0.008480763771786587, 0.007121284171115985, 0.007420122751622693, 0.007071013072690402, 0.0072542840704962145, 0.007332738568112836, 0.006944817556775524, 0.006113700397926004, 0.00625926952347545, 0.0061744255090445226, 0.005537753997753316, 0.006086923043275601, 0.005299459336951259, 0.005163455037471067, 0.005154629146066145, 0.004965312772064499, 0.005203712236442152, 0.005029957718623336, 0.004756618438960868, 0.0046074315479238065, 0.00453642847899373, 0.0048681165707694166, 0.004588576889791512, 0.004427014121866523, 0.004540557055029422, 0.004396330147421304, 0.004421710995337708, 0.004351225044177136, 0.004141697913342068, 0.004106231263718291, 0.00442919345393093, 0.004247476739430749, 0.004094313491690809, 0.0041628532397207894, 0.004071079863646628, 0.0038586085052783347, 0.004065125971622183, 0.003716140315062148, 0.0036709161858459083, 0.003716500154754431, 0.0038424164224765264, 0.0035915301668063876, 0.0035784402263496305, 0.0034887166201298895, 0.003399569698548703, 0.0035016963249339824, 0.0034546063107171905, 0.0032734423473262495, 0.003844399699626774, 0.0033402875373487405, 0.0032493259921510115, 0.0032942519069697027, 0.0032627492603002793, 0.003470387362732572, 0.003192657414332575, 0.0032366017898112203, 0.003220895510782816, 0.0031974000470291683, 0.0031918379442976174, 0.0032739570205312703, 0.003204080951976675, 0.0031257392797923787, 0.0032935140509673146, 0.003248945435122209, 0.0032586359294717797, 0.0031379494686326554, 0.003293851931859808, 0.0033957008738074138, 0.0030902489409180816, 0.003144460768564659, 0.0030466769430061843, 0.002999203894636969, 0.003033740219701548, 0.003091723277711202, 0.002987280813374912, 0.002993912281073324, 0.0029263590880918857, 0.0028864210666184136, 0.003026778842083752, 0.002872519848589127, 0.0028776566502192965, 0.0029557017364585363, 0.0029635264068378687, 0.0028671186614561634, 0.0029487296737552883, 0.0030030759014041566, 0.0029610287888744095, 0.002983940481800505, 0.003062935501994292, 0.0029890775183954873, 0.0029454085821920386, 0.0029537343243779134, 0.002917362655967145, 0.0030779653437487753, 0.002951661238243662, 0.003070344982397762, 0.0031749308232642947, 0.0028991012680621565, 0.002905608126240506, 0.002888082559660177, 0.002838273341979206, 0.003065561142978059, 0.0028362931153288287, 0.002824010053692521, 0.0029315254494600594, 0.0029173815634944617, 0.0029231788230721463, 0.002805142169440975, 0.0028694911362179424, 0.0028887326006454997, 0.002841941969810557, 0.002933607403377654, 0.0028850396696252917, 0.0028487525438575965, 0.002938061946367965, 0.002906868089175673, 0.0029322077332784944, 0.00289934495509992, 0.0028933753157404504, 0.002870586258379903, 0.002882410143714247, 0.0029240870734674814, 0.0028300855817665577, 0.0027836807791043697, 0.0028265552466915814, 0.0028556686297528245, 0.0028039735998139632, 0.0029123851648667127, 0.002916369044238786, 0.0027883201803424683, 0.002865378600651257, 0.00295575158494578, 0.0028440666200591574, 0.002768888636279152, 0.002855564521679102, 0.00282681430766248, 0.0028275598758103556, 0.0028526688829767664, 0.002889131979471412, 0.002910625803370067, 0.002882527650288236, 0.0028436798239814516, 0.002821710497666617, 0.002809657257347272, 0.0028298988515166514, 0.002863656590913354, 0.0028275775755840548, 0.0028807296611254806, 0.0028550352494576842, 0.0028706805750260364, 0.0028476480489837653, 0.002844162202021579, 0.002753108784970726, 0.0027952800687185, 0.0028626287935216888, 0.002840979178229027, 0.0028329897429079554, 0.002797418626022255, 0.0029032285130542596, 0.002955416002565112, 0.0028308144843839284, 0.002936828672826242, 0.002787053645521569, 0.0027990373436526527, 0.002824772650621619, 0.002833317630279946, 0.002885425373472736, 0.0029364677376298447, 0.0029934599073944373, 0.002850793066274443, 0.0028636342889896507, 0.002853935703804753, 0.0028323272754988272, 0.0027855720303682427, 0.0029209035047619123, 0.0028602429510958534, 0.002770784107354933, 0.002722435373780332, 0.002763770051298567, 0.0027616817291051996]\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(accuracies)\nplt.title('Test Accuracy')\nplt.xlabel('Rounds')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.grid(True)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"mTQI9WGZ65fU","outputId":"7e81e0a0-ba97-460f-d980-bd2f5d4fb4d5","execution":{"iopub.status.busy":"2023-05-24T15:55:14.763931Z","iopub.execute_input":"2023-05-24T15:55:14.764271Z","iopub.status.idle":"2023-05-24T15:55:15.001189Z","shell.execute_reply.started":"2023-05-24T15:55:14.764240Z","shell.execute_reply":"2023-05-24T15:55:15.000308Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABOKklEQVR4nO3deXwTZeI/8M/k7kkpvWi5yiGIIKdUvNFyiQiKyOFPEFEUQdAquqBS0O8K4oroiriyXKtci6u4KoKlUJClFKFUxAM5rQJtgdKDHskk8/z+SBMILdDCJNPEz/tFXzSTmcnzZNrMp88xIwkhBIiIiIgChE7rAhARERGpieGGiIiIAgrDDREREQUUhhsiIiIKKAw3REREFFAYboiIiCigMNwQERFRQGG4ISIiooDCcENEREQBheGGiIiIAgrDDdGfiCRJtfrKyMi46tcqLy/HjBkzrmhf69atgyRJiI+Ph6IoV10WIvpzMWhdACLynY8++sjj8b/+9S+kpaVVW37ttdde9WuVl5dj5syZAIA77rijTtsuX74cLVq0wNGjR7Fp0yYkJydfdXmI6M+D4YboT+T//b//5/F4x44dSEtLq7ZcS2VlZfj8888xa9YsLFmyBMuXL6+34aasrAwhISFaF4OILsBuKSLyoCgK5s2bh+uuuw4WiwWxsbF44okncObMGY/1du3ahb59+yIqKgpBQUFITEzEo48+CgA4evQooqOjAQAzZ850d3fNmDHjsq//2WefoaKiAkOHDsXw4cPx6aeforKystp6lZWVmDFjBq655hpYLBY0btwY999/Pw4dOuRRl3feeQcdO3aExWJBdHQ0+vXrh127drnLKUkSli5dWm3/F5Z3xowZkCQJP/30E0aOHImGDRvilltuAQDs3bsXjzzyCFq2bAmLxYK4uDg8+uijOH36dLX9Hjt2DGPHjkV8fDzMZjMSExMxfvx42Gw2HD58GJIk4e2336623fbt2yFJElauXHnZ95Doz44tN0Tk4YknnsDSpUsxZswYTJo0CUeOHMF7772HPXv24H//+x+MRiMKCgrQp08fREdH4y9/+QsiIiJw9OhRfPrppwCA6OhoLFiwAOPHj8d9992H+++/HwBw/fXXX/b1ly9fjl69eiEuLg7Dhw/HX/7yF3zxxRcYOnSoex2Hw4F77rkH6enpGD58OCZPnozS0lKkpaVh3759aNWqFQBg7NixWLp0Kfr374/HHnsMdrsd3377LXbs2IHu3btf0fszdOhQtGnTBq+//jqEEACAtLQ0HD58GGPGjEFcXBx+/PFHfPjhh/jxxx+xY8cOSJIEADh+/Dh69OiBoqIijBs3Du3atcOxY8fwySefoLy8HC1btsTNN9+M5cuX49lnn632voSFhWHQoEFXVG6iPxVBRH9aEyZMEOd/DHz77bcCgFi+fLnHeuvXr/dY/tlnnwkA4rvvvrvovk+ePCkAiNTU1FqXJz8/XxgMBrFw4UL3sptuukkMGjTIY73FixcLAGLu3LnV9qEoihBCiE2bNgkAYtKkSRdd58iRIwKAWLJkSbV1Lix7amqqACBGjBhRbd3y8vJqy1auXCkAiK1bt7qXjRo1Suh0uhrfN1eZ/vGPfwgA4ueff3Y/Z7PZRFRUlBg9enS17YioOnZLEZHbmjVr0KBBA/Tu3RunTp1yf3Xr1g2hoaHYvHkzACAiIgIA8OWXX0KWZdVef9WqVdDpdBgyZIh72YgRI/D11197dIv95z//QVRUFJ5++ulq+3C1kvznP/+BJElITU296DpX4sknn6y2LCgoyP19ZWUlTp06hRtvvBEAkJ2dDcDZRbZ27VoMHDiwxlYjV5kefPBBWCwWLF++3P3chg0bcOrUqXo1NoqoPmO4ISK3AwcOoLi4GDExMYiOjvb4Onv2LAoKCgAAt99+O4YMGYKZM2ciKioKgwYNwpIlS2C1Wq/q9T/++GP06NEDp0+fxsGDB3Hw4EF06dIFNpsNa9asca936NAhtG3bFgbDxXvWDx06hPj4eERGRl5VmS6UmJhYbVlhYSEmT56M2NhYBAUFITo62r1ecXExAODkyZMoKSlBhw4dLrn/iIgIDBw4ECtWrHAvW758ORISEnDnnXeqWBOiwMUxN0TkpigKYmJiPFoNzucaJCxJEj755BPs2LEDX3zxBTZs2IBHH30Ub731Fnbs2IHQ0NA6v/aBAwfw3XffAQDatGlT7fnly5dj3Lhxdd7vpVysBcfhcFx0m/NbaVwefPBBbN++HVOmTEHnzp0RGhoKRVHQr1+/K7pOz6hRo7BmzRps374dHTt2xH//+1889dRT0On49yhRbTDcEJFbq1atsHHjRtx88801nsQvdOONN+LGG2/EX//6V6xYsQIPPfQQVq1ahccee6zOXT/Lly+H0WjERx99BL1e7/Hctm3b8O677yI3NxfNmjVDq1atkJWVBVmWYTQaL1qXDRs2oLCw8KKtNw0bNgQAFBUVeSz/7bffal3uM2fOID09HTNnzsT06dPdyw8cOOCxXnR0NMLDw7Fv377L7rNfv36Ijo7G8uXLkZSUhPLycjz88MO1LhPRnx3/DCAitwcffBAOhwOvvfZatefsdrs7BJw5c8Y9U8ilc+fOAODumgoODgZQPThczPLly3Hrrbdi2LBheOCBBzy+pkyZAgDuadBDhgzBqVOn8N5771Xbj6tcQ4YMgRDCfSHBmtYJDw9HVFQUtm7d6vH8+++/X6syA3AHsQvfj3nz5nk81ul0GDx4ML744gv3VPSaygQABoMBI0aMwL///W8sXboUHTt2rNVMMyJyYssNEbndfvvteOKJJzBr1izk5OSgT58+MBqNOHDgANasWYN33nkHDzzwAJYtW4b3338f9913H1q1aoXS0lIsXLgQ4eHhuPvuuwE4u2/at2+P1atX45prrkFkZCQ6dOhQ45iTrKwsHDx4EBMnTqyxXAkJCejatSuWL1+OF198EaNGjcK//vUvpKSkYOfOnbj11ltRVlaGjRs34qmnnsKgQYPQq1cvPPzww3j33Xdx4MABdxfRt99+i169erlf67HHHsPs2bPx2GOPoXv37ti6dSt+/fXXWr9n4eHhuO222zBnzhzIsoyEhAR88803OHLkSLV1X3/9dXzzzTe4/fbbMW7cOFx77bU4ceIE1qxZg23btrkHagPOrql3330XmzdvxhtvvFHr8hAROBWc6M/swqngLh9++KHo1q2bCAoKEmFhYaJjx47ihRdeEMePHxdCCJGdnS1GjBghmjVrJsxms4iJiRH33HOP2LVrl8d+tm/fLrp16yZMJtMlp4U//fTTAoA4dOjQRcs6Y8YMAUB8//33Qgjn9OuXXnpJJCYmCqPRKOLi4sQDDzzgsQ+73S7efPNN0a5dO2EymUR0dLTo37+/2L17t3ud8vJyMXbsWNGgQQMRFhYmHnzwQVFQUHDRqeAnT56sVrY//vhD3HfffSIiIkI0aNBADB06VBw/frzGOv/2229i1KhRIjo6WpjNZtGyZUsxYcIEYbVaq+33uuuuEzqdTvzxxx8XfV+IqDpJiAvaUomIqF7o0qULIiMjkZ6ernVRiPwKx9wQEdVDu3btQk5ODkaNGqV1UYj8DltuiIjqkX379mH37t146623cOrUKRw+fBgWi0XrYhH5FbbcEBHVI5988gnGjBkDWZaxcuVKBhuiK6BpuNm6dSsGDhyI+Ph4SJKEtWvXXnabjIwMdO3aFWazGa1bt67xbr5ERP5qxowZUBQFP//8M26//Xati0PklzQNN2VlZejUqRPmz59fq/WPHDmCAQMGoFevXsjJycEzzzyDxx57DBs2bPBySYmIiMhf1JsxN5Ik4bPPPsPgwYMvus6LL76Ir776yuMKn8OHD0dRURHWr1/vg1ISERFRfedXF/HLzMxEcnKyx7K+ffvimWeeueg2VqvV42Z+iqKgsLAQjRo1uqo7AxMREZHvCCFQWlqK+Pj4y95nza/CTV5eHmJjYz2WxcbGoqSkBBUVFTXeC2fWrFk1Xn6diIiI/M/vv/+OJk2aXHIdvwo3V2Lq1KlISUlxPy4uLkazZs1w5MgRhIWFqfpasixj8+bN6NWr10Vv5ufPAr1+AOsYCAK9fgDrGAgCvX6A+nUsLS1FYmJirc7dfhVu4uLikJ+f77EsPz8f4eHhF72DsdlshtlsrrY8MjIS4eHhqpZPlmUEBwejUaNGAfnDGuj1A1jHQODN+imKgCIEDHpnk7gQArJDwGTQeaxTITtgV5zDGcPMBuh0EoorZPyaXwqDTkLbuDAEm859/NrsCorKbXAIAb0kQZIk6HUSdBKg00nQSxJ0kgSdDtBJEhS7HeagYJhDG0CBDpV2BVbZAatdQaXsgIBzPZ3k/B8A6tILHxFsQnSo2V0vRREorpBRXCHDoJdgMuhglRUUV8hwKAIhZgMsRh2EAIQAFCHgEAJF5TJOllai3OaAUa+DUa+D2aCDyaBDqNmA8CAjDDoJskOBQ3G+l3ZFgewQqLRJ+F0OwY+FAgJ22BXnc3aH8xhEhpgQHWaGza6gsMwG2aHAbNBDr5NgVxTY7AKyQ4HsUGAx6hERbETDYBMaBpsQYtajwubAWasd5e7/7ThrdQAAokPNiA4zwaTXQ5KAU2etOFFcCYci0CDICItRD5tdgc3hgEHnrJfJIMGo10ERQIXNgQrZjgqbAqvdgRCzAeEWI3QSIDsEbA4HKqx27C8PQcgJGSajcB5zSYIiBOyKgFGvQ3SYGeEWAwpKrcgvqYQkSQg26hFkcn4JAZwsrcTpMhtw3jGXXD8vVcdfpzvv+/OetzsUlNkcsNodMOl1MBv1sBic/wOAver9O/+42Ku+t9mVGn92zAYdzAY9YsLNuLllI1V/F137qM2QEr8KNz179sS6des8lqWlpaFnz54alYioZpWyA4oQHicwF0URsFZ9MFTIDvxeWI4TxRUAJJgMEkx6PYx6CQ5FoKRSxukyG34vrEBBSSXax4ejX4c4lNscSPspH8eKKhAXbkFsuBlmg/ODuKhcRkFpJSRIiAk3I8xiQIVNQbnN+UFeWmHDz4d1yPh0Hypl54dbhc2OMqvzQy4i2ISYMLPzK9wCi1GPcqsdNoeCIJMeFoMeReU2nDxrBSChQZARdoeCo6fLcLrMhusTGqBnqyhEh5kgBJBfYsWBglLkFVeiUnaeSH47XY7cwnJEhZrRISEcJoMeB/JLcbrMhthwM+LCndd2sTkEZLvzA/as1Y7TZTacrbTDYtQh6LwP+XKrAwWlVpy12gEAEvRIyUqDhKqTu/MfdJIEqepDXnKuCJ0kIcSkR3iQ84OzpEKG1a4gzOI8+eokCUIInC6zIb+kErJDIMSkh8WoR2ml830JNRvQuIEFNoeCE0WVsDnOffDrdRJCzQYUV8juZZIENAoxQwgBm11BaVW568YA7Nh0BdvVnsmggwRAdihQNJl6ogd+ytbihX1Ej6UH9mpdCK/o3DQCN4/rodnraxpuzp49i4MHD7ofHzlyBDk5OYiMjESzZs0wdepUHDt2DP/6178AAE8++STee+89vPDCC3j00UexadMm/Pvf/8ZXX32lVRXIByplB2SHgmCTAUXlNnx3tBCHTpahY0ID9EiMBADkFpajqFyGXVGglyREhZnRKMSEcpsDxRUySqr+6iyukFFSaXcvK620w6iXYDbo0DDEhNgwE46ckRB99AxMRgOOFVXgeFElrHYHFOH8S10RAmVWB44XVaC4QkbL6FC0jQ3FoZNlyDx8GrmF5e6/apo0DELrmFBIACplBXkllTh2psLj5FcXn+45hv/76mcV3lUdkH/8Is+VXdWe9+QWYVnmb7Va91hRBY4VVXgsO1lqxb5jJZfcrkJ24Azkiz4v4AyHrkeXU1wh43hxpccy11/DNSmzOVBmc7gfn7XacaDgbI3rOqpaPQAgISIINoeCk6VWnDpr9VhPkuD+y72uQcJkcLaIWIx6mPQ66HXO/QjhfH2lDpNiFQEUV9icLQwX/HUeYtLDXhXOLUYdwi1G6HUSyqx2VNqV81oHnCEy3GJETLgZoWaDuwVAdiiwys6wWlzh/J016nQw6CUY9DoYdRL0egkGSUJFeRkaNgiHyaCDQa+DQSfBoJcgQcKps8730GzQIzLEBLNBB2tVEDYZdFUtRc7WlAqbA2fKbSiukHGm3NnapJOAEJMBIWYDgs16hJoNCDbpoQjgVKkVp8tssDsU2BVnK1HjBhYY9ToUV4VfVwuU3SFgc7Vw2BVIkuQM3Ubnl9moc9cVAEx653YGnYTiM2fQMLIhAKmqtQvQS4BBp4PV7gzsJRUyosPMiGvgDPwVsoJKmwPlsjMQR4eaERlihk6Cx2eUUtWC5mpJcy0T5z2nlySEmA0wGXSQHc5WP2frnwIJgLHqmBh0krvMBr0OJr3zeOkuaEFRqsK61a6gZVRI3X6IVaZpuNm1axd69erlfuwaGzN69GgsXboUJ06cQG5urvv5xMREfPXVV3j22WfxzjvvoEmTJvjnP/+Jvn37+rzsdGmnz1qx67czMBt0aBMbhlOlVny9Lw85v5+B7BBwKAJhFgMigk1oGGxERLAJISZny4PsEDhZakVecSV+LSjF0VNlF/2wN+l1kBUF6l7QQI8Pf/mu1mtnHSm86HN/nKnAH2cqLvo8AMSGmxEfEQSd5GyedzZ3K9BJzlaRhsFGJEQEITLEjO2HTuG7o4Uw6HW4uVUjdEhogIISKwpKK53N9g5ns3lMuBlCAAWllThrtSPY5PzgDjYZEGSQcCz3CK5v3xbhQaZzz5kNMOl1KCq3oaDUuc/8EisqZQdCqz4AK2wOlMsORAQZER1mhgRnd4skAS2iQhBuMWDX0TP47mghKmTnyb9hsAltYkLRNDIYwVUtHk0jg9EsMhj5JZXYd6wYDkWgTWwookMtyC+pREGpFToJ552kdAg2OU9iYRYDbHYF5TYHKmQHKmwOBJn0iAkzIzzICFmWsXFjOu686y7o9QYInPtQd3WbnL/MFVZdJ58GQUaYjTqUVNhRWim7f/YaBhsRHxGEIKMexRUyKmQHwoOMCDHpcbrMhhNFlTAZdIiPsKBRiBkGvfOEVVwuo6hCRmy4BQ2qWodOnbWioMQKvU6CUS+hYbAJDYKM0OmcJwtx3knJcUFIURTAKtuwMW0jBt7dFyEWs3s7tSiKQFFVHQHAqJMQEWxyd1MJIbw+21SWZaxbtw53391T1e5FIYQ7nGg5Y/Zc/XoEZPcw4KyjVjQNN3fccQcudZmdmq4+fMcdd2DPnj1eLBXVxr5jxdh64CQyD51GcYWMcIsRFqMOZVYHTp21XvSvWDW0jQ1D69hQZP92Bieq/toOsxgQFWqGQSfBrjjD0VmrHQadMyA0CDIivOrL+diABkFGhJqNUIRApews97Ez5Th8/BSMlhDIikB8RBCaRAQhyKSHrmochCQBFqMe8Q0sCLMYsT+/FL/mlaJJwyDc1DoK7RuHIyLYCLtDYH++M5zpdM7WoZgwC5pGBqFhsAlS1V9o54/XuJzJyW1QXCHDqJdq7PKqDeeH6iHcfWuiVz5UB3VOqPW6iVEhuLFlI49lHdHgql5flnUINwExYWavnTQahpg8HkcEm9AqOrTGdWPC9YgJ97yFQlSoGVGh1ccCukiu7jNINX5IyzIQYnT+HKodbADnOJ/IC+p4Yfn8lSRJsFSNKaHA5Vdjbsg7hBB4P+MQVmTlItRsQGwDCyplB86U2RAbbkHfDnG4tXUULHqBo6XAmGW7se3g6cvut21sGBQhcORUGUwGHXq1i8Ed10QjzGKEJAFnK+04U25DUbmMM+U2VFQ18+t1zm6lmDAzWkWHol1cGMKDjCiz2mHQ69x//Qoh8HthBULMzr/oL/zAtdkVGPVSnT6Iz/01dYsqJ8YbWzaqdvK+Wq76ExFRzRhu/oQKSivx0mf7YNLrcG/neKz74QQ+zzk3/mJ/fqn7+wMFZ7Ht4KnztjYAOA2DTsIdbWNwS+tGaBoZjJJKGZWygmCTHuEWIzo2aeD+y1R2OPtvXTNMrtSFf21JkoRmjYIvun5dWkSIiChwMNwEoILSSpyttKNpZDCMFwSKI6fKMGpxFn4vdI4D+eqHEwAAg07CywOuRWJ0KPJLKhFUNXXyp+MlWLcvDz+fKIHNrkAHgUGd4/Fs73aXDBbnu7AMRERE3sRwE2A+3vEbXvl8H4Rwdu+EWwyolBUoQiAi2Igyq3MqbrPIYPRuH4sv9x6Hza7gvZFdcXPrqGr7u7VNNJ64vRUAwGq14auvv8bAAR0DdgAcERH5P4abAOEaN/Pmhv0AnF0yNruCM+XnRqvnlzinnnZICMeSR3ogOsyMlwdcC4ciatVl5LyYmHfKT0REpBaGmwAxb+MBvJN+AADw9J2t8WzyNSgotaK0UnaPVTlTbkOlrKBz0wj3eBRJcl43goiIKFAw3ASAhVsPu4PNtLvbYdxtzm6kuAYW94WfAKBpZO3GyBAREfkzhhs/45r+nHXkNA4WnEVuYTm+3pcHAJjSt6072BAREf1ZMdz4gU+z/8DbG39FudV5G4KSyur3oXni9pZ46g4GGyIiIoabem5FVi6mffaDxzKjXsL1TSLQMaEBEiKC0K5xGG5pHeXXVw0lIiJSC8NNPbZs+1Gk/vdHAMAjN7XAyKRmkAA0aRiMIBMvH05ERFQThpt66p/fHnbf/XncbS0xtX87tswQERHVAsNNPWO1O/BBxmG8vfFXAMCEXq3wfJ+2DDZERES1xHBTT9gdChZtO4JF246goNR5sb3Jd7XBM8ltGGyIiIjqgOGmnvjmp3zM+voXAEBcuAWT7mqDkUnNNC4VERGR/2G4qSd+OVECAOh3XRzeHdGFd7QmIiK6QjyD1hOHT5UBALo1b8hgQ0REdBV4Fq0nDp90hpuW0SEal4SIiMi/MdzUA0IIHKlquUmMYrghIiK6Ggw39UBeSSUqZAcMOok3tyQiIrpKDDf1wJGqLqlmkcEw6nlIiIiIrgbPpD5kdyh48qPd+L8vf4IQwr380CmOtyEiIlILp4L70I/HS7D+xzwAQPNGwXi4ZwsAwOGTZwFwvA0REZEa2HLjQ3+cqXB//9pXP+OXPOe1bY64W25CNSkXERFRIGG48aFjReXu7212BRNX7EGl7HBPA2fLDRER0dVjuPGhY1UtN8NvaIqYMDMOFpzF4v8dwR9nnKGHY26IiIiuHsOND7m6pTo2aYCU3tcAAOZtPABFAKFmA6JDzVoWj4iIKCAw3PjQsSJnuGnSMBhDujVBi0bBsNkVAM5WG979m4iI6Oox3PiIEMLdcpMQEQSjXodnq1pvAI63ISIiUgvDjY+UVNhx1moHADRpGAQAGHh9PNrGhgEAWnOmFBERkSoYbnzk96pBw1GhJliMegCATifh7yO74OEbm+OhG5trWTwiIqKAwYv4+YhrvE1CQ897R10TG4bXBnfQokhEREQBiS03PuIab9MkIkjjkhAREQU2hhsfcV3jxjXehoiIiLyD4cZHXBfqS2C4ISIi8iqGGx9xj7lhtxQREZFXMdz4iHvMzQUDiomIiEhdDDc+UFopo7hCBsBuKSIiIm9juPEBV5dURLARoWbOviciIvImhhsfOHaG422IiIh8heHGB/7gNHAiIiKfYbjxgXMzpTiYmIiIyNsYbnzAdY0bttwQERF5H8OND7jH3DDcEBEReR3DjQ9wzA0REZHvMNx4WYXNgdNlNgBAE465ISIi8jqGGy87VuQcbxNmNiA8iNe4ISIi8jaGGy/747zxNpIkaVwaIiKiwMdw42Ucb0NERORbDDdexruBExER+RbDjZcd493AiYiIfIrhxstcF/DjNW6IiIh8g+HGy1zdUhxzQ0RE5BsMN15ktTuQX2IFwDE3REREvsJw40UniioBAEFGPSJDTBqXhoiI6M+B4caLeI0bIiIi32O48SLX1Yk53oaIiMh3GG68yN1yw/E2REREPsNw40W8xg0REZHvMdx4UXGFDACIDDFqXBIiIqI/D4YbL5IVAQAw6Pg2ExER+QrPul7kUBQAgEHPmVJERES+wnDjRbKDLTdERES+pvlZd/78+WjRogUsFguSkpKwc+fOS64/b948tG3bFkFBQWjatCmeffZZVFZW+qi0deOo6pbS69hyQ0RE5CuahpvVq1cjJSUFqampyM7ORqdOndC3b18UFBTUuP6KFSvwl7/8Bampqfj555+xaNEirF69GtOmTfNxyWvH7nB2SxnZLUVEROQzmoabuXPn4vHHH8eYMWPQvn17fPDBBwgODsbixYtrXH/79u24+eabMXLkSLRo0QJ9+vTBiBEjLtvaoxV3t5Re8wYyIiKiPw2DVi9ss9mwe/duTJ061b1Mp9MhOTkZmZmZNW5z00034eOPP8bOnTvRo0cPHD58GOvWrcPDDz980dexWq2wWq3uxyUlJQAAWZYhy7JKtYF7n+f/72q5geJQ/bW0cGH9AhHr6P8CvX4A6xgIAr1+gPp1rMt+JCGEUOVV6+j48eNISEjA9u3b0bNnT/fyF154AVu2bEFWVlaN27377rt4/vnnIYSA3W7Hk08+iQULFlz0dWbMmIGZM2dWW75ixQoEB3v34np/3aNHQaWEp6+zo3W4V1+KiIgooJWXl2PkyJEoLi5GePilT6qatdxciYyMDLz++ut4//33kZSUhIMHD2Ly5Ml47bXX8Morr9S4zdSpU5GSkuJ+XFJSgqZNm6JPnz6XfXPqSpZlpKWloXfv3jAajXhr/7dAZQVuuekmdG0WoepraeHC+gUi1tH/BXr9ANYxEAR6/QD16+jqeakNzcJNVFQU9Ho98vPzPZbn5+cjLi6uxm1eeeUVPPzww3jssccAAB07dkRZWRnGjRuHl156CboaplybzWaYzeZqy41Go9d+oFz7dvVKWUzeey0tePO9qy9YR/8X6PUDWMdAEOj1A9SrY132odlIV5PJhG7duiE9Pd29TFEUpKene3RTna+8vLxagNHr9QAAjXrXLkl28CJ+REREvqZpt1RKSgpGjx6N7t27o0ePHpg3bx7KysowZswYAMCoUaOQkJCAWbNmAQAGDhyIuXPnokuXLu5uqVdeeQUDBw50h5z6xMHbLxAREfmcpuFm2LBhOHnyJKZPn468vDx07twZ69evR2xsLAAgNzfXo6Xm5ZdfhiRJePnll3Hs2DFER0dj4MCB+Otf/6pVFS6JLTdERES+p/mA4okTJ2LixIk1PpeRkeHx2GAwIDU1FampqT4o2dU713LDcENEROQr7C/xIvddwXkRPyIiIp/hWdeL3LdfYMsNERGRzzDceImiCFQ13PDGmURERD7EcOMlduXc1HR2SxEREfkOz7pe4jg/3LDlhoiIyGcYbrxEVhT395wKTkRE5DsMN15id5xruTHyIn5EREQ+w7Oul9irWm4kCdCxW4qIiMhnGG68xNVyw1YbIiIi3+KZ10tcA4o5DZyIiMi3GG68hPeVIiIi0gbDjZe4rnNj5DVuiIiIfIpnXi9xjblhtxQREZFvMdx4iWu2FO8rRURE5FsMN17i6pbSc8wNERGRTzHceAmnghMREWmDZ14vsXO2FBERkSYYbrzE3S3FlhsiIiKf4pnXS9wDitlyQ0RE5FMMN17CqeBERETaYLjxEvdF/NgtRURE5FM883oJb79ARESkDYYbL+GNM4mIiLTBcOMl7uvc8N5SREREPsUzr5fY2XJDRESkCYYbL+FUcCIiIm0w3HiJXNUtZeBsKSIiIp/imddLHFUtNwZ2SxEREfkUw42XuFtu2C1FRETkUww3XuLgvaWIiIg0wTOvl7juCs4BxURERL7FcOMlssIBxURERFrgmddLXN1SHHNDRETkWww3XuK+txRnSxEREfkUw42XuFtuGG6IiIh8iuHGS85NBedbTERE5Es883qJa7YUx9wQERH5FsONl7BbioiISBsMN17CqeBERETa4JnXS9z3lmK3FBERkU8x3HgJ7wpORESkDZ55vYQX8SMiItIGw42X8CJ+RERE2mC48RI7r3NDRESkCZ55vYRTwYmIiLTBcOMlssJuKSIiIi0w3HiJq+XGyG4pIiIin+KZ10tcU8H1bLkhIiLyKYYbL+G9pYiIiLTBcOMlDt5+gYiISBM883qJzNsvEBERaYLhxkscVWNujGy5ISIi8imeeb3EdVdwDigmIiLyLYYbL3ENKDayW4qIiMinGG68xM6WGyIiIk0w3HiJ695SvIgfERGRb/HM6yXuqeDsliIiIvIphhsvcU0FZ7cUERGRbzHceIFDERDOhhtOBSciIvIxnnm9wDWYGAD07JYiIiLyKYYbL3BNAwfYckNERORrPPN6geO8lhsOKCYiIvIthhsvkM8PNxxQTERE5FOah5v58+ejRYsWsFgsSEpKws6dOy+5flFRESZMmIDGjRvDbDbjmmuuwbp163xU2tpxdUvpdRIkieGGiIjIlwxavvjq1auRkpKCDz74AElJSZg3bx769u2L/fv3IyYmptr6NpsNvXv3RkxMDD755BMkJCTgt99+Q0REhO8LfwkOXp2YiIhIM5qGm7lz5+Lxxx/HmDFjAAAffPABvvrqKyxevBh/+ctfqq2/ePFiFBYWYvv27TAajQCAFi1a+LLIteLqljIy3BAREfmcZuHGZrNh9+7dmDp1qnuZTqdDcnIyMjMza9zmv//9L3r27IkJEybg888/R3R0NEaOHIkXX3wRer2+xm2sViusVqv7cUlJCQBAlmXIsqxijeDen9Xq/N+gl1R/DS256hJIdboQ6+j/Ar1+AOsYCAK9foD6dazLfiQhhLj8auo7fvw4EhISsH37dvTs2dO9/IUXXsCWLVuQlZVVbZt27drh6NGjeOihh/DUU0/h4MGDeOqppzBp0iSkpqbW+DozZszAzJkzqy1fsWIFgoOD1avQeY6XA298b0CoQeCvNzi88hpERER/JuXl5Rg5ciSKi4sRHh5+yXU17ZaqK0VREBMTgw8//BB6vR7dunXDsWPH8Oabb1403EydOhUpKSnuxyUlJWjatCn69Olz2TenrmRZRlpaGm7ocSPw/S6EBFlw9923q/oaWnLVr3fv3u5uwUDDOvq/QK8fwDoGgkCvH6B+HV09L7WhWbiJioqCXq9Hfn6+x/L8/HzExcXVuE3jxo1hNBo9uqCuvfZa5OXlwWazwWQyVdvGbDbDbDZXW240Gr32AyXpnOUz6HUB+UPrzfeuvmAd/V+g1w9gHQNBoNcPUK+OddmHZlPBTSYTunXrhvT0dPcyRVGQnp7u0U11vptvvhkHDx6Eopy7AvCvv/6Kxo0b1xhstGLnHcGJiIg0o+l1blJSUrBw4UIsW7YMP//8M8aPH4+ysjL37KlRo0Z5DDgeP348CgsLMXnyZPz666/46quv8Prrr2PChAlaVaFG9qrwxQv4ERER+Z6mY26GDRuGkydPYvr06cjLy0Pnzp2xfv16xMbGAgByc3OhO+/eTE2bNsWGDRvw7LPP4vrrr0dCQgImT56MF198Uasq1MjuqGq54X2liIiIfE7zAcUTJ07ExIkTa3wuIyOj2rKePXtix44dXi7V1WG3FBERkXbYtOAF7nDDbikiIiKfq3O4adGiBV599VXk5uZ6ozwBwXVvKYOe2ZGIiMjX6nz2feaZZ/Dpp5+iZcuW6N27N1atWuVxBWA6d28pttwQERH53hWFm5ycHOzcuRPXXnstnn76aTRu3BgTJ05Edna2N8rod2QHx9wQERFp5Yr7Tbp27Yp3330Xx48fR2pqKv75z3/ihhtuQOfOnbF48WJodFeHeuHcVHB2SxEREfnaFc+WkmUZn332GZYsWYK0tDTceOONGDt2LP744w9MmzYNGzduxIoVK9Qsq99gtxQREZF26hxusrOzsWTJEqxcuRI6nQ6jRo3C22+/jXbt2rnXue+++3DDDTeoWlB/wm4pIiIi7dQ53Nxwww3o3bs3FixYgMGDB9d4r4fExEQMHz5clQL6I3fLDWdLERER+Vydw83hw4fRvHnzS64TEhKCJUuWXHGh/B2vc0NERKSdOjctFBQUICsrq9ryrKws7Nq1S5VC+TvZwQHFREREWqnz2XfChAn4/fffqy0/duxYvbuBpVY4oJiIiEg7dQ43P/30E7p27VpteZcuXfDTTz+pUih/Z+eAYiIiIs3UOdyYzWbk5+dXW37ixAkYDJrfh7NecI25MXJAMRERkc/V+ezbp08fTJ06FcXFxe5lRUVFmDZtGnr37q1q4fyV6yJ+enZLERER+Vydm1r+9re/4bbbbkPz5s3RpUsXAEBOTg5iY2Px0UcfqV5Af8RuKSIiIu3UOdwkJCRg7969WL58Ob7//nsEBQVhzJgxGDFiRI3XvPkz4lRwIiIi7VzRIJmQkBCMGzdO7bIEDN5bioiISDtXPAL4p59+Qm5uLmw2m8fye++996oL5e8c7gHFbLkhIiLytSu6QvF9992HH374AZIkue/+LUnOE7nD4VC3hH7IdW8pPVtuiIiIfK7OZ9/JkycjMTERBQUFCA4Oxo8//oitW7eie/fuyMjI8EIR/Y9rQDFbboiIiHyvzi03mZmZ2LRpE6KioqDT6aDT6XDLLbdg1qxZmDRpEvbs2eONcvoVV7cUp4ITERH5Xp1bbhwOB8LCwgAAUVFROH78OACgefPm2L9/v7ql81Oya0AxL+JHRETkc3VuuenQoQO+//57JCYmIikpCXPmzIHJZMKHH36Ili1beqOMfof3liIiItJOncPNyy+/jLKyMgDAq6++invuuQe33norGjVqhNWrV6teQH/kvogfww0REZHP1Tnc9O3b1/1969at8csvv6CwsBANGzZ0z5j6s+O9pYiIiLRTp7OvLMswGAzYt2+fx/LIyEgGm/Pw3lJERETaqVO4MRqNaNasGa9lcxmcCk5ERKSdOvebvPTSS5g2bRoKCwu9UZ6AYFd4ET8iIiKt1HnMzXvvvYeDBw8iPj4ezZs3R0hIiMfz2dnZqhXOX7nvLcWWGyIiIp+rc7gZPHiwF4oRWByubim23BAREflcncNNamqqN8oRUGReoZiIiEgzbFrwAg4oJiIi0k6dW250Ot0lp31zJhXg4FRwIiIizdQ53Hz22Wcej2VZxp49e7Bs2TLMnDlTtYL5M5kX8SMiItJMncPNoEGDqi174IEHcN1112H16tUYO3asKgXzZ+57S7FbioiIyOdUa1q48cYbkZ6ertbu/BrvLUVERKQdVcJNRUUF3n33XSQkJKixO78nu65zw6ngREREPlfnbqkLb5AphEBpaSmCg4Px8ccfq1o4f+XgVHAiIiLN1DncvP322x7hRqfTITo6GklJSWjYsKGqhfNXDg4oJiIi0kydw80jjzzihWIEFjtbboiIiDRT56aFJUuWYM2aNdWWr1mzBsuWLVOlUP5MEYBwZhsOKCYiItJAncPNrFmzEBUVVW15TEwMXn/9dVUK5c+qGm0AcCo4ERGRFuocbnJzc5GYmFhtefPmzZGbm6tKofyZ4/xww9lSREREPlfns29MTAz27t1bbfn333+PRo0aqVIof3Z+yw3H3BAREflencPNiBEjMGnSJGzevBkOhwMOhwObNm3C5MmTMXz4cG+U0a94ttww3BAREflanWdLvfbaazh69CjuuusuGAzOzRVFwahRozjmBudabnQSoGO4ISIi8rk6hxuTyYTVq1fj//7v/5CTk4OgoCB07NgRzZs390b5/I7ininF8TZERERaqHO4cWnTpg3atGmjZlkCgqtbiuNtiIiItFHn5oUhQ4bgjTfeqLZ8zpw5GDp0qCqF8mcOXuOGiIhIU3UON1u3bsXdd99dbXn//v2xdetWVQrlz1zdUnpe44aIiEgTdQ43Z8+ehclkqrbcaDSipKRElUL5M465ISIi0ladz8AdO3bE6tWrqy1ftWoV2rdvr0qh/JlS9T+7pYiIiLRR5wHFr7zyCu6//34cOnQId955JwAgPT0dK1aswCeffKJ6Af2NoyrdcEAxERGRNuocbgYOHIi1a9fi9ddfxyeffIKgoCB06tQJmzZtQmRkpDfK6FfcLTccc0NERKSJK5oKPmDAAAwYMAAAUFJSgpUrV+L555/H7t274XA4VC2gv+FsKSIiIm1d8ajXrVu3YvTo0YiPj8dbb72FO++8Ezt27FCzbH5JEc5QwwHFRERE2qhTy01eXh6WLl2KRYsWoaSkBA8++CCsVivWrl3LwcRVeBE/IiIibdW6eWHgwIFo27Yt9u7di3nz5uH48eP4+9//7s2y+SX3VHCOuSEiItJErVtuvv76a0yaNAnjx4/nbRcuQeGYGyIiIk3VuuVm27ZtKC0tRbdu3ZCUlIT33nsPp06d8mbZ/JKDF/EjIiLSVK3PwDfeeCMWLlyIEydO4IknnsCqVasQHx8PRVGQlpaG0tJSb5bTbygcc0NERKSpOjcvhISE4NFHH8W2bdvwww8/4LnnnsPs2bMRExODe++91xtl9CsOjrkhIiLS1FX1nbRt2xZz5szBH3/8gZUrV6pVJr/GMTdERETaUmVgiF6vx+DBg/Hf//73irafP38+WrRoAYvFgqSkJOzcubNW261atQqSJGHw4MFX9LrecK5bimNuiIiItKD5GXj16tVISUlBamoqsrOz0alTJ/Tt2xcFBQWX3O7o0aN4/vnnceutt/qopLXDKxQTERFpS/NwM3fuXDz++OMYM2YM2rdvjw8++ADBwcFYvHjxRbdxOBx46KGHMHPmTLRs2dKHpb08d8sNx9wQERFp4oruLaUWm82G3bt3Y+rUqe5lOp0OycnJyMzMvOh2r776KmJiYjB27Fh8++23l3wNq9UKq9XqflxSUgIAkGUZsixfZQ08ybJ87grFVY8Dias+gVav87GO/i/Q6wewjoEg0OsHqF/HuuxH03Bz6tQpOBwOxMbGeiyPjY3FL7/8UuM227Ztw6JFi5CTk1Or15g1axZmzpxZbfk333yD4ODgOpf5clz3lso7cQzr1v2u+v7rg7S0NK2L4HWso/8L9PoBrGMgCPT6AerVsby8vNbrahpu6qq0tBQPP/wwFi5ciKioqFptM3XqVKSkpLgfl5SUoGnTpujTpw/Cw8NVLZ8sy/hmyUYAQPNmTXH33depun+tybKMtLQ09O7dG0ajUevieAXr6P8CvX4A6xgIAr1+gPp1dPW81Iam4SYqKgp6vR75+fkey/Pz8xEXF1dt/UOHDuHo0aMYOHCge5miKAAAg8GA/fv3o1WrVh7bmM1mmM3mavsyGo1e+YFyjbkxGvQB+wPrrfeuPmEd/V+g1w9gHQNBoNcPUK+OddmHpgOKTSYTunXrhvT0dPcyRVGQnp6Onj17Vlu/Xbt2+OGHH5CTk+P+uvfee9GrVy/k5OSgadOmvix+jVzdUkbOliIiItKE5t1SKSkpGD16NLp3744ePXpg3rx5KCsrw5gxYwAAo0aNQkJCAmbNmgWLxYIOHTp4bB8REQEA1ZZrxVH1P69zQ0REpA3Nw82wYcNw8uRJTJ8+HXl5eejcuTPWr1/vHmScm5sLnR8FhapeMt5+gYiISCOahxsAmDhxIiZOnFjjcxkZGZfcdunSpeoX6Cqca7lhuCEiItKC/zSJ+An3gGKGGyIiIk0w3KiM95YiIiLSFs/AKnPfW4pjboiIiDTBcKOycy03DDdERERaYLhRGe8KTkREpC2GG5UpDDdERESaYrhRmbtbSs+3loiISAs8A6uM3VJERETaYrhRGbuliIiItMVwozKFU8GJiIg0xXCjMgcv4kdERKQpnoFVpghniw27pYiIiLTBcKMyDigmIiLSFsONyjjmhoiISFsMNypTqv7nmBsiIiJt8AysMkdVumG3FBERkTYYblTmarlhuCEiItIGw43KHBxzQ0REpCmGG5UpvM4NERGRpngGVhmnghMREWmL4UZlnApORESkLYYblfHGmURERNpiuFEZx9wQERFpi2dglXHMDRERkbYYblTGqeBERETaYrhR2bluKYYbIiIiLTDcqEhRBAScocbAMTdERESa4BlYRXZXsw3YckNERKQVhhsVOc4LNxxQTEREpA2GGxWd33LDAcVERETaYLhRkWfLDd9aIiIiLfAMrCK7ori/Z68UERGRNhhuVOTqljLoJEgS0w0REZEWGG5U5OqW4ngbIiIi7TDcqMjVcsNp4ERERNphuFGR3XGuW4qIiIi0wXCjIkfVgGK23BAREWmH4UZFrm4pI6eBExERaYZnYRU5OOaGiIhIcww3KnKNuWG4ISIi0g7DjYrOv84NERERaYPhRkW8zg0REZH2GG5UdO46N3xbiYiItMKzsIpc95ZitxQREZF2GG5U5OCAYiIiIs0x3KjIfZ0bjrkhIiLSDMONinidGyIiIu0x3KhIZrghIiLSHMONihwcUExERKQ5hhsVua9zw6ngREREmuFZWEV2dksRERFpjuFGRa57S7FbioiISDsMNypiyw0REZH2GG5U5OB1boiIiDTHcKMiB+8tRUREpDmehVUkO5xTwdktRUREpB2GGxWdmwrOcENERKQVhhsVucMNx9wQERFphuFGRXa23BAREWmO4UZFvHEmERGR9hhuVMQbZxIREWmP4UZFrhtnGjkVnIiISDM8C6uI3VJERETaqxfhZv78+WjRogUsFguSkpKwc+fOi667cOFC3HrrrWjYsCEaNmyI5OTkS67vS7z9AhERkfY0DzerV69GSkoKUlNTkZ2djU6dOqFv374oKCiocf2MjAyMGDECmzdvRmZmJpo2bYo+ffrg2LFjPi55de4bZ3IqOBERkWY0Dzdz587F448/jjFjxqB9+/b44IMPEBwcjMWLF9e4/vLly/HUU0+hc+fOaNeuHf75z39CURSkp6f7uOTVcSo4ERGR9gxavrjNZsPu3bsxdepU9zKdTofk5GRkZmbWah/l5eWQZRmRkZE1Pm+1WmG1Wt2PS0pKAACyLEOW5asofXWy3QEAkIRQfd/1gatOgVg3F9bR/wV6/QDWMRAEev0A9etYl/1IQgihyqtegePHjyMhIQHbt29Hz5493ctfeOEFbNmyBVlZWZfdx1NPPYUNGzbgxx9/hMViqfb8jBkzMHPmzGrLV6xYgeDg4KurwAX++YsOP5zRYVhLB26K1extJSIiCjjl5eUYOXIkiouLER4efsl1NW25uVqzZ8/GqlWrkJGRUWOwAYCpU6ciJSXF/bikpMQ9Tudyb05dfXpqN3DmNDpcdx3u7tFM1X3XB7IsIy0tDb1794bRaNS6OF7BOvq/QK8fwDoGgkCvH6B+HV09L7WhabiJioqCXq9Hfn6+x/L8/HzExcVdctu//e1vmD17NjZu3Ijrr7/+ouuZzWaYzeZqy41Go+o/UFVDbmAxGQL2hxXwzntX37CO/i/Q6wewjoEg0OsHqFfHuuxD0wHFJpMJ3bp18xgM7BocfH431YXmzJmD1157DevXr0f37t19UdRa4XVuiIiItKd5t1RKSgpGjx6N7t27o0ePHpg3bx7KysowZswYAMCoUaOQkJCAWbNmAQDeeOMNTJ8+HStWrECLFi2Ql5cHAAgNDUVoaKhm9QA4W4qIiKg+0DzcDBs2DCdPnsT06dORl5eHzp07Y/369YiNjQUA5ObmQnfe7QwWLFgAm82GBx54wGM/qampmDFjhi+LXg0v4kdERKQ9zcMNAEycOBETJ06s8bmMjAyPx0ePHvV+ga6QvereUga95pcPIiIi+tPiWVhFDnZLERERaY7hRkUOB7uliIiItMZwoyKZLTdERESaY7hREaeCExERaY/hRkWcCk5ERKQ9hhsVnRtQzLeViIhIKzwLq8jucE4FZ7cUERGRdhhuVMRuKSIiIu0x3KjI3S2lZ7ghIiLSCsONijhbioiISHsMNyridW6IiIi0x3CjIrbcEBERaY/hRiVCiPPG3PBtJSIi0grPwipxBRuA3VJERERaYrhRif28cMNuKSIiIu0w3KjEzpYbIiKieoHhRiUOB8MNERFRfcBwoxK7ori/Z7cUERGRdhhuVOLqltJBQJIYboiIiLTCcKMSd7hhriEiItIUw41KXGNueFspIiIibTHcqMQ15oYtN0RERNpiuFEJu6WIiIjqB4YbldjZLUVERFQvMNyoxMGWGyIionqB4UYlrjE3bLkhIiLSlkHrAgSKIJMeXZtFwHG2UOuiEBER/amx5UYl7eLCsfrxHni0rXL5lYmIiMhrGG6IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhhoiIiAIKww0REREFFIYbIiIiCigMN0RERBRQGG6IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhhoiIiAIKww0REREFFIYbIiIiCigMN0RERBRQGG6IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhhoiIiAIKww0REREFFIYbIiIiCigMN0RERBRQGG6IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhhoiIiAIKww0REREFFIYbIiIiCigMN0RERBRQGG6IiIgooDDcEBERUUCpF+Fm/vz5aNGiBSwWC5KSkrBz585Lrr9mzRq0a9cOFosFHTt2xLp163xUUiIiIqrvNA83q1evRkpKClJTU5GdnY1OnTqhb9++KCgoqHH97du3Y8SIERg7diz27NmDwYMHY/Dgwdi3b5+PS05ERET1kebhZu7cuXj88ccxZswYtG/fHh988AGCg4OxePHiGtd/55130K9fP0yZMgXXXnstXnvtNXTt2hXvvfeej0tORERE9ZGm4cZms2H37t1ITk52L9PpdEhOTkZmZmaN22RmZnqsDwB9+/a96PpERET052LQ8sVPnToFh8OB2NhYj+WxsbH45ZdfatwmLy+vxvXz8vJqXN9qtcJqtbofFxcXAwAKCwshy/LVFL8aWZZRXl6O06dPw2g0qrrv+iDQ6wewjoEg0OsHsI6BINDrB6hfx9LSUgCAEOKy62oabnxh1qxZmDlzZrXliYmJGpSGiIiIrkZpaSkaNGhwyXU0DTdRUVHQ6/XIz8/3WJ6fn4+4uLgat4mLi6vT+lOnTkVKSor7saIoKCwsRKNGjSBJ0lXWwFNJSQmaNm2K33//HeHh4aruuz4I9PoBrGMgCPT6AaxjIAj0+gHq11EIgdLSUsTHx192XU3DjclkQrdu3ZCeno7BgwcDcIaP9PR0TJw4scZtevbsifT0dDzzzDPuZWlpaejZs2eN65vNZpjNZo9lERERahT/osLDwwP2hxUI/PoBrGMgCPT6AaxjIAj0+gHq1vFyLTYumndLpaSkYPTo0ejevTt69OiBefPmoaysDGPGjAEAjBo1CgkJCZg1axYAYPLkybj99tvx1ltvYcCAAVi1ahV27dqFDz/8UMtqEBERUT2hebgZNmwYTp48ienTpyMvLw+dO3fG+vXr3YOGc3NzodOdm9R10003YcWKFXj55Zcxbdo0tGnTBmvXrkWHDh20qgIRERHVI5qHGwCYOHHiRbuhMjIyqi0bOnQohg4d6uVS1Z3ZbEZqamq1brBAEej1A1jHQBDo9QNYx0AQ6PUDtK2jJGozp4qIiIjIT2h+hWIiIiIiNTHcEBERUUBhuCEiIqKAwnBDREREAYXhRiXz589HixYtYLFYkJSUhJ07d2pdpCs2a9Ys3HDDDQgLC0NMTAwGDx6M/fv3e6xzxx13QJIkj68nn3xSoxLXzYwZM6qVvV27du7nKysrMWHCBDRq1AihoaEYMmRItati13ctWrSoVkdJkjBhwgQA/nn8tm7dioEDByI+Ph6SJGHt2rUezwshMH36dDRu3BhBQUFITk7GgQMHPNYpLCzEQw89hPDwcERERGDs2LE4e/asD2txcZeqnyzLePHFF9GxY0eEhIQgPj4eo0aNwvHjxz32UdNxnz17to9rcnGXO4aPPPJItfL369fPY536fAyBy9expt9LSZLw5ptvutepz8exNueH2nyG5ubmYsCAAQgODkZMTAymTJkCu92uWjkZblSwevVqpKSkIDU1FdnZ2ejUqRP69u2LgoICrYt2RbZs2YIJEyZgx44dSEtLgyzL6NOnD8rKyjzWe/zxx3HixAn315w5czQqcd1dd911HmXftm2b+7lnn30WX3zxBdasWYMtW7bg+PHjuP/++zUsbd199913HvVLS0sDAI9LKPjb8SsrK0OnTp0wf/78Gp+fM2cO3n33XXzwwQfIyspCSEgI+vbti8rKSvc6Dz30EH788UekpaXhyy+/xNatWzFu3DhfVeGSLlW/8vJyZGdn45VXXkF2djY+/fRT7N+/H/fee2+1dV999VWP4/r000/7ovi1crljCAD9+vXzKP/KlSs9nq/PxxC4fB3Pr9uJEyewePFiSJKEIUOGeKxXX49jbc4Pl/sMdTgcGDBgAGw2G7Zv345ly5Zh6dKlmD59unoFFXTVevToISZMmOB+7HA4RHx8vJg1a5aGpVJPQUGBACC2bNniXnb77beLyZMna1eoq5Camio6depU43NFRUXCaDSKNWvWuJf9/PPPAoDIzMz0UQnVN3nyZNGqVSuhKIoQwr+PnxBCABCfffaZ+7GiKCIuLk68+eab7mVFRUXCbDaLlStXCiGE+OmnnwQA8d1337nX+frrr4UkSeLYsWM+K3ttXFi/muzcuVMAEL/99pt7WfPmzcXbb7/t3cKppKY6jh49WgwaNOii2/jTMRSidsdx0KBB4s477/RY5k/H8cLzQ20+Q9etWyd0Op3Iy8tzr7NgwQIRHh4urFarKuViy81Vstls2L17N5KTk93LdDodkpOTkZmZqWHJ1FNcXAwAiIyM9Fi+fPlyREVFoUOHDpg6dSrKy8u1KN4VOXDgAOLj49GyZUs89NBDyM3NBQDs3r0bsix7HM927dqhWbNmfns8bTYbPv74Yzz66KMeN4v15+N3oSNHjiAvL8/juDVo0ABJSUnu45aZmYmIiAh0797dvU5ycjJ0Oh2ysrJ8XuarVVxcDEmSqt0rb/bs2WjUqBG6dOmCN998U9Wmfl/IyMhATEwM2rZti/Hjx+P06dPu5wLtGObn5+Orr77C2LFjqz3nL8fxwvNDbT5DMzMz0bFjR/edCACgb9++KCkpwY8//qhKuerFFYr92alTp+BwODwOEgDExsbil19+0ahU6lEUBc888wxuvvlmj1tcjBw5Es2bN0d8fDz27t2LF198Efv378enn36qYWlrJykpCUuXLkXbtm1x4sQJzJw5E7feeiv27duHvLw8mEymaieM2NhY5OXlaVPgq7R27VoUFRXhkUcecS/z5+NXE9exqen30PVcXl4eYmJiPJ43GAyIjIz0u2NbWVmJF198ESNGjPC4IeGkSZPQtWtXREZGYvv27Zg6dSpOnDiBuXPnalja2uvXrx/uv/9+JCYm4tChQ5g2bRr69++PzMxM6PX6gDqGALBs2TKEhYVV6/b2l+NY0/mhNp+heXl5Nf6uup5TA8MNXdKECROwb98+jzEpADz6uDt27IjGjRvjrrvuwqFDh9CqVStfF7NO+vfv7/7++uuvR1JSEpo3b45///vfCAoK0rBk3rFo0SL0798f8fHx7mX+fPz+7GRZxoMPPgghBBYsWODxXEpKivv766+/HiaTCU888QRmzZrlF5f5Hz58uPv7jh074vrrr0erVq2QkZGBu+66S8OSecfixYvx0EMPwWKxeCz3l+N4sfNDfcBuqasUFRUFvV5fbSR4fn4+4uLiNCqVOiZOnIgvv/wSmzdvRpMmTS65blJSEgDg4MGDviiaqiIiInDNNdfg4MGDiIuLg81mQ1FRkcc6/no8f/vtN2zcuBGPPfbYJdfz5+MHwH1sLvV7GBcXV22Qv91uR2Fhod8cW1ew+e2335CWlubRalOTpKQk2O12HD161DcFVFnLli0RFRXl/rkMhGPo8u2332L//v2X/d0E6udxvNj5oTafoXFxcTX+rrqeUwPDzVUymUzo1q0b0tPT3csURUF6ejp69uypYcmunBACEydOxGeffYZNmzYhMTHxstvk5OQAABo3buzl0qnv7NmzOHToEBo3boxu3brBaDR6HM/9+/cjNzfXL4/nkiVLEBMTgwEDBlxyPX8+fgCQmJiIuLg4j+NWUlKCrKws93Hr2bMnioqKsHv3bvc6mzZtgqIo7nBXn7mCzYEDB7Bx40Y0atTostvk5ORAp9NV68rxF3/88QdOnz7t/rn092N4vkWLFqFbt27o1KnTZdetT8fxcueH2nyG9uzZEz/88INHUHWF9fbt26tWULpKq1atEmazWSxdulT89NNPYty4cSIiIsJjJLg/GT9+vGjQoIHIyMgQJ06ccH+Vl5cLIYQ4ePCgePXVV8WuXbvEkSNHxOeffy5atmwpbrvtNo1LXjvPPfecyMjIEEeOHBH/+9//RHJysoiKihIFBQVCCCGefPJJ0axZM7Fp0yaxa9cu0bNnT9GzZ0+NS113DodDNGvWTLz44osey/31+JWWloo9e/aIPXv2CABi7ty5Ys+ePe7ZQrNnzxYRERHi888/F3v37hWDBg0SiYmJoqKiwr2Pfv36iS5duoisrCyxbds20aZNGzFixAitquThUvWz2Wzi3nvvFU2aNBE5OTkev5eu2SXbt28Xb7/9tsjJyRGHDh0SH3/8sYiOjhajRo3SuGbnXKqOpaWl4vnnnxeZmZniyJEjYuPGjaJr166iTZs2orKy0r2P+nwMhbj8z6kQQhQXF4vg4GCxYMGCatvX9+N4ufODEJf/DLXb7aJDhw6iT58+IicnR6xfv15ER0eLqVOnqlZOhhuV/P3vfxfNmjUTJpNJ9OjRQ+zYsUPrIl0xADV+LVmyRAghRG5urrjttttEZGSkMJvNonXr1mLKlCmiuLhY24LX0rBhw0Tjxo2FyWQSCQkJYtiwYeLgwYPu5ysqKsRTTz0lGjZsKIKDg8V9990nTpw4oWGJr8yGDRsEALF//36P5f56/DZv3lzjz+Xo0aOFEM7p4K+88oqIjY0VZrNZ3HXXXdXqfvr0aTFixAgRGhoqwsPDxZgxY0RpaakGtanuUvU7cuTIRX8vN2/eLIQQYvfu3SIpKUk0aNBAWCwWce2114rXX3/dIxho7VJ1LC8vF3369BHR0dHCaDSK5s2bi8cff7zaH4n1+RgKcfmfUyGE+Mc//iGCgoJEUVFRte3r+3G83PlBiNp9hh49elT0799fBAUFiaioKPHcc88JWZZVK6dUVVgiIiKigMAxN0RERBRQGG6IiIgooDDcEBERUUBhuCEiIqKAwnBDREREAYXhhoiIiAIKww0REREFFIYbIqIqd9xxB5555hmti0FEV4nhhoh86pFHHoEkSZAkCUajEYmJiXjhhRdQWVmpddGIKEAYtC4AEf359OvXD0uWLIEsy9i9ezdGjx4NSZLwxhtvaF00IgoAbLkhIp8zm82Ii4tD06ZNMXjwYCQnJyMtLQ0AYLVaMWnSJMTExMBiseCWW27Bd99959526dKliIiI8Njf2rVrIUmS+/GMGTPQuXNnfPTRR2jRogUaNGiA4cOHo7S01L1OWVkZRo0ahdDQUDRu3BhvvfVWtXK+//77aNOmDSwWC2JjY/HAAw+o/E4QkTcw3BCRpvbt24ft27fDZDIBAF544QX85z//wbJly5CdnY3WrVujb9++KCwsrNN+Dx06hLVr1+LLL7/El19+iS1btmD27Nnu56dMmYItW7bg888/xzfffIOMjAxkZ2e7n9+1axcmTZqEV199Ffv378f69etx2223qVNpIvIqdksRkc99+eWXCA0Nhd1uh9VqhU6nw3vvvYeysjIsWLAAS5cuRf/+/QEACxcuRFpaGhYtWoQpU6bU+jUURcHSpUsRFhYGAHj44YeRnp6Ov/71rzh79iwWLVqEjz/+GHfddRcAYNmyZWjSpIl7+9zcXISEhOCee+5BWFgYmjdvji5duqj4LhCRtzDcEJHP9erVCwsWLEBZWRnefvttGAwGDBkyBHv37oUsy7j55pvd6xqNRvTo0QM///xznV6jRYsW7mADAI0bN0ZBQQEAZ6uOzWZDUlKS+/nIyEi0bdvW/bh3795o3rw5WrZsiX79+qFfv3647777EBwcfKXVJiIfYbcUEflcSEgIWrdujU6dOmHx4sXIysrCokWLarWtTqeDEMJjmSzL1dYzGo0ejyVJgqIotS5jWFgYsrOzsXLlSjRu3BjTp09Hp06dUFRUVOt9EJE2GG6ISFM6nQ7Tpk3Dyy+/jFatWsFkMuF///uf+3lZlvHdd9+hffv2AIDo6GiUlpairKzMvU5OTk6dXrNVq1YwGo3IyspyLztz5gx+/fVXj/UMBgOSk5MxZ84c7N27F0ePHsWmTZuuoJZE5EvsliIizQ0dOhRTpkzBggULMH78eEyZMgWRkZFo1qwZ5syZg/LycowdOxYAkJSUhODgYEybNg2TJk1CVlYWli5dWqfXCw0NxdixYzFlyhQ0atQIMTExeOmll6DTnft778svv8Thw4dx2223oWHDhli3bh0URfHouiKi+onhhog0ZzAYMHHiRMyZMwdHjhyBoih4+OGHUVpaiu7du2PDhg1o2LAhAOfYmI8//hhTpkzBwoULcdddd2HGjBkYN25cnV7zzTffxNmzZzFw4ECEhYXhueeeQ3Fxsfv5iIgIfPrpp5gxYwYqKyvRpk0brFy5Etddd52qdSci9Uniws5rIiIiIj/GMTdEREQUUBhuiIiIKKAw3BAREVFAYbghIiKigMJwQ0RERAGF4YaIiIgCCsMNERERBRSGGyIiIgooDDdEREQUUBhuiIiIKKAw3BAREVFAYbghIiKigPL/AdL7yNTgKP0YAAAAAElFTkSuQmCC"},"metadata":{}}]}]}