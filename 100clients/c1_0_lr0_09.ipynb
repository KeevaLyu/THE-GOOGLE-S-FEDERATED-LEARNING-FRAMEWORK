{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"a5e36ac6a21e329c2cec267b08e4f28884519c7e5682f29504bd17199cc3d203"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library","metadata":{"id":"NsvvFSId2xB6"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nimport numpy as np\nimport random\nfrom collections import OrderedDict, ChainMap, Counter\nfrom tqdm.asyncio import tqdm\nimport math\nimport matplotlib.pyplot as plt\n\n# for reproducible results\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\ndevice = torch.device('cpu')\n# gpu\nif torch.backends.mps.is_available():\n    device = torch.device('mps')\nelif torch.cuda.is_available():\n    device = torch.device('cuda:0')\nprint(device)","metadata":{"id":"vDaWQfJ022KB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51b40344-98b9-44f0-ce98-b67d8e6c23bc","execution":{"iopub.status.busy":"2023-05-24T01:57:03.680712Z","iopub.execute_input":"2023-05-24T01:57:03.681171Z","iopub.status.idle":"2023-05-24T01:57:07.988574Z","shell.execute_reply.started":"2023-05-24T01:57:03.681133Z","shell.execute_reply":"2023-05-24T01:57:07.987622Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data processing","metadata":{"id":"t_RCPBAVzB9L"}},{"cell_type":"code","source":"transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.1307,), (0.3081,))]) # scale from [0,255] to [0,1] and make mean and std to 0.0 and 1.0 respectively\ntraining_dataset = datasets.MNIST('./data/mnist/', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST('./data/mnist/', train=False, download=True, transform=transform)","metadata":{"id":"GrvHYZ_swCAM","execution":{"iopub.status.busy":"2023-05-24T01:57:07.993590Z","iopub.execute_input":"2023-05-24T01:57:07.994554Z","iopub.status.idle":"2023-05-24T01:57:09.062563Z","shell.execute_reply.started":"2023-05-24T01:57:07.994516Z","shell.execute_reply":"2023-05-24T01:57:09.061633Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 137407662.45it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 69738453.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 50226526.91it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 13685724.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# sort by labels\nsorted_indices = torch.argsort(torch.Tensor(training_dataset.targets))\nsorted_training_dataset = torch.utils.data.Subset(training_dataset, sorted_indices)\n\n# partition data into shards\ndef prepare_datashards(num_clients, num_shards, strict=False):\n    training_datashards = []\n\n    shards = []\n    # partition by class\n    if strict:\n        number_of_classes = len(sorted_training_dataset.dataset.classes)\n        shards_per_class = num_shards // number_of_classes\n\n        ptr = 0\n        # for each class\n        for label, size in sorted(Counter(sorted_training_dataset.dataset.targets.tolist()).items()):\n            shard_size = math.ceil(size / shards_per_class)\n\n            # for each shard\n            for i in range(shards_per_class):\n                shard = []\n                # fill shard of shard_size\n                for j in range(shard_size):\n                    shard.append(sorted_training_dataset[ptr])\n                    ptr += 1\n                    # break for next class\n                    if ptr >= len(sorted_training_dataset) or sorted_training_dataset[ptr][1] != label:\n                        break\n                shards.append(shard)\n\n    # partition by size\n    else:\n        shard_size = len(sorted_training_dataset) // num_shards\n\n        # for each shard\n        for i in range(num_shards):\n            shard = []\n            # fill shard of shard_size\n            for j in range(shard_size):\n                shard.append(sorted_training_dataset[i * shard_size + j])\n            shards.append(shard)\n    \n    # shuffled shard ids\n    random.seed(seed)\n    shard_ids = random.sample(list(range(num_shards)), num_shards)\n    print(\"Shards order - {}\".format(shard_ids))\n\n    # for each client\n    for k in range(num_clients):\n        client_shards = []\n        # number of shards per client\n        shards_per_client = num_shards // num_clients\n        for s in range(shards_per_client):\n            id = shard_ids[k * shards_per_client + s]\n            client_shards.append(shards[id])\n        training_datashards.append(client_shards)\n\n    return training_datashards","metadata":{"id":"ZohHDK7o65fH","execution":{"iopub.status.busy":"2023-05-24T01:57:09.067230Z","iopub.execute_input":"2023-05-24T01:57:09.069429Z","iopub.status.idle":"2023-05-24T01:57:09.110911Z","shell.execute_reply.started":"2023-05-24T01:57:09.069396Z","shell.execute_reply":"2023-05-24T01:57:09.110061Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Global","metadata":{"id":"mamL4quE65fI"}},{"cell_type":"code","source":"# clients training mode\nPARALLEL_TRAINING = True\n\n# clients and shards\nnum_clients = 100\nnum_shards = 200\n\n# prepare training data\ntraining_datashards = prepare_datashards(num_clients, num_shards)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tPNbLHz865fI","outputId":"80b1bb83-032c-416d-c78d-c1fc8b9442f2","execution":{"iopub.status.busy":"2023-05-24T01:57:09.116518Z","iopub.execute_input":"2023-05-24T01:57:09.118624Z","iopub.status.idle":"2023-05-24T01:57:22.889993Z","shell.execute_reply.started":"2023-05-24T01:57:09.118593Z","shell.execute_reply":"2023-05-24T01:57:22.888197Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shards order - [163, 28, 6, 189, 70, 62, 57, 35, 188, 26, 173, 139, 22, 151, 108, 8, 7, 23, 55, 59, 129, 154, 197, 143, 50, 166, 191, 107, 56, 114, 150, 71, 1, 40, 185, 87, 168, 39, 181, 86, 190, 182, 97, 24, 91, 88, 67, 11, 117, 137, 31, 96, 20, 141, 75, 92, 49, 17, 152, 58, 74, 147, 180, 25, 157, 199, 116, 93, 41, 94, 90, 53, 68, 89, 119, 164, 82, 9, 77, 81, 21, 127, 132, 149, 138, 169, 48, 34, 120, 178, 134, 198, 124, 131, 98, 99, 183, 29, 4, 174, 51, 112, 184, 27, 72, 155, 100, 148, 83, 63, 175, 123, 140, 18, 33, 142, 133, 109, 118, 85, 196, 54, 79, 104, 46, 165, 84, 65, 179, 146, 177, 14, 19, 115, 78, 135, 176, 156, 38, 102, 80, 16, 192, 161, 0, 43, 145, 103, 95, 105, 113, 73, 106, 125, 52, 160, 144, 10, 60, 171, 172, 32, 195, 61, 69, 153, 36, 12, 122, 37, 194, 5, 110, 47, 162, 186, 126, 42, 15, 159, 3, 30, 130, 45, 167, 158, 76, 128, 170, 136, 44, 64, 2, 13, 121, 111, 193, 101, 187, 66]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"e6vzuzLL1cP8"}},{"cell_type":"code","source":"class CNN(nn.Module):\n    # https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html#specify-how-data-will-pass-through-your-model\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 5x5 convolution layer with 32 channels\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding='same')\n        # 5x5 convolution layer with 64 channels\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding='same')\n        # fully connected layer with 512 units, in_features = channels * height * width from conv2\n        self.fc1 = nn.Linear(in_features=64*7*7, out_features=512)\n        self.fc2 = nn.Linear(in_features=512, out_features=10)\n\n    # x represents our data\n    def forward(self, x):\n        # Pass data through conv1\n        x = self.conv1(x)\n        # Use the rectified-linear activation function over x\n        x = F.relu(x)\n        # Run max pooling over x\n        x = F.max_pool2d(x, kernel_size=2)\n        \n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n\n        # Flatten x with start_dim=1\n        x = torch.flatten(x, start_dim=1)\n        # Pass data through fc1\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n\n        # Apply softmax to x\n        output = F.log_softmax(x, dim=1)\n        return output","metadata":{"id":"4KIxpXNR1dWg","execution":{"iopub.status.busy":"2023-05-24T01:57:22.891518Z","iopub.execute_input":"2023-05-24T01:57:22.891900Z","iopub.status.idle":"2023-05-24T01:57:22.901791Z","shell.execute_reply.started":"2023-05-24T01:57:22.891851Z","shell.execute_reply":"2023-05-24T01:57:22.900658Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_params = sum(p.numel() for p in CNN().parameters())\nprint(\"Total number of parameters:\", num_params)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLzdTLYt65fJ","outputId":"3f1223fb-5b0b-43c0-e35b-eab69d11a45c","execution":{"iopub.status.busy":"2023-05-24T01:57:22.903201Z","iopub.execute_input":"2023-05-24T01:57:22.903865Z","iopub.status.idle":"2023-05-24T01:57:22.950590Z","shell.execute_reply.started":"2023-05-24T01:57:22.903828Z","shell.execute_reply":"2023-05-24T01:57:22.949711Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total number of parameters: 1663370\n","output_type":"stream"}]},{"cell_type":"code","source":"for p in CNN().parameters():\n    print(p.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY3Pl12PP4rP","outputId":"5c6d2ae1-1831-4068-d3a8-3ed4ae5e1cd8","execution":{"iopub.status.busy":"2023-05-24T01:57:22.951919Z","iopub.execute_input":"2023-05-24T01:57:22.952445Z","iopub.status.idle":"2023-05-24T01:57:22.972541Z","shell.execute_reply.started":"2023-05-24T01:57:22.952413Z","shell.execute_reply":"2023-05-24T01:57:22.971597Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"torch.Size([32, 1, 5, 5])\ntorch.Size([32])\ntorch.Size([64, 32, 5, 5])\ntorch.Size([64])\ntorch.Size([512, 3136])\ntorch.Size([512])\ntorch.Size([10, 512])\ntorch.Size([10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Client\n","metadata":{"id":"RtdxFdsz1h0m"}},{"cell_type":"code","source":"class Client():\n    def __init__(self, k, model, args):\n        # inititalize client\n        self.id = k\n        self.model = model\n        self.args = args\n\n        # load dataset\n        self.dataset = []\n        self._load_dataset(k)\n        self.training_loader = torch.utils.data.DataLoader(self.dataset, batch_size=self.args['B'], shuffle=True)\n\n        # state_dict\n        self.state_dict = self.model.state_dict()\n\n    def _load_dataset(self, k):\n        # load dataset\n        for shard in training_datashards[k]:\n            self.dataset += shard\n        return\n\n    def labels(self):\n        return dict(Counter(data[1] for data in self.dataset))\n\n    def size(self):\n        return len(self.dataset)\n\n    async def update(self):\n        # load state_dict\n        self.model.load_state_dict(self.state_dict)\n\n        # Sets the module in training mode\n        self.model.train(True)\n\n        optimizer = optim.SGD(self.model.parameters(), lr=self.args['lr'])\n        loss_fn = nn.CrossEntropyLoss()\n\n        # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n        for epoch in range(self.args['E']):\n            for inputs, labels in self.training_loader:\n                # Every data instance is an input + label pair\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                # Zero your gradients for every batch!\n                optimizer.zero_grad()\n\n                # Make predictions for this batch\n                outputs = self.model(inputs)\n\n                # Compute the loss and its gradients\n                loss = loss_fn(outputs, labels)\n                loss.backward()\n\n                # Adjust learning weights\n                optimizer.step()\n        \n        # save state_dict\n        self.state_dict = self.model.state_dict()\n\n        return { self.id: self.state_dict }\n\n    def model_sync(self, state_dict):\n        self.state_dict = state_dict","metadata":{"id":"bzCVn4hfAOhX","execution":{"iopub.status.busy":"2023-05-24T01:57:22.974098Z","iopub.execute_input":"2023-05-24T01:57:22.974432Z","iopub.status.idle":"2023-05-24T01:57:22.985386Z","shell.execute_reply.started":"2023-05-24T01:57:22.974402Z","shell.execute_reply":"2023-05-24T01:57:22.984493Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Server","metadata":{"id":"unKQT-qEPnKL"}},{"cell_type":"code","source":"class Server():\n    def __init__(self, args):\n        self.model = CNN().to(device)\n        # number of rounds of communication\n        self.rounds = 0\n        # client fraction C\n        self.c = args['C']\n        # client list\n        self.clients = []\n        # inititalize clients according to num_clients\n        if PARALLEL_TRAINING:\n            for k in range(num_clients):\n                torch.manual_seed(seed)\n                client_model = CNN().to(device)\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n        else:\n            torch.manual_seed(seed)\n            client_model = CNN().to(device)\n            for k in range(num_clients):\n                client = Client(k, client_model, args)\n                self.clients.append(client)\n\n    def _fed_avg(self, state_dicts):\n        # total number of data\n        len_total = 0\n        for k in ChainMap(*state_dicts).keys():\n            len_total += self.clients[k].size()\n\n        dict = OrderedDict()\n        # for each client's state_dict\n        for k, state_dict in ChainMap(*state_dicts).items():\n            # for each tensor param\n            for param_tensor in self.model.state_dict().keys():\n                # param = w0 * wf0 + w1 * wf1 + ... wk * wfk\n                if param_tensor in dict:\n                    dict[param_tensor] += state_dict[param_tensor] * (self.clients[k].size() / len_total)\n                else:\n                    dict[param_tensor] = state_dict[param_tensor] * (self.clients[k].size() / len_total)\n\n        return dict\n\n    def clients_info(self):\n        for i, client in enumerate(self.clients):\n            print(\"Client {} - {}\".format(i, client.labels()))\n\n    async def model_sync(self):\n        selected_clients = self.clients\n\n        # clients random selection\n        if self.c < 1.0:\n            # clients per round\n            k = max(int(self.c * num_clients), 1)\n            # client selection\n            random.seed(self.rounds)\n            selected_clients = random.sample(self.clients, k=k)\n            client_ids = []\n            for client in selected_clients:\n                client_ids.append(client.id)\n            print(\"Selected clients - {}\".format(client_ids))\n\n        state_dicts = []\n        # for each selected client do client update\n        if PARALLEL_TRAINING:\n            state_dicts = await tqdm.gather(*[client.update() for client in selected_clients])\n        else:\n            for client in tqdm(selected_clients):\n                state_dict = await client.update()\n                state_dicts.append(state_dict)\n        \n        # update server weights\n        avg_state_dict = self._fed_avg(state_dicts)\n        self.model.load_state_dict(avg_state_dict)\n\n        # sync with all clients\n        for client in self.clients:\n            client.model_sync(avg_state_dict)\n\n        # increase rounds count\n        self.rounds += 1","metadata":{"id":"rjIkYahr1jVG","execution":{"iopub.status.busy":"2023-05-24T01:57:22.986744Z","iopub.execute_input":"2023-05-24T01:57:22.987383Z","iopub.status.idle":"2023-05-24T01:57:23.004339Z","shell.execute_reply.started":"2023-05-24T01:57:22.987328Z","shell.execute_reply":"2023-05-24T01:57:23.003365Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def test_model(model):\n    # https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-analysis-train-model#test-the-model-on-the-test-data\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Sets the module in evaluate mode\n    model.eval()\n    model.to(device)\n    \n    correct = 0\n    loss = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            # Every data instance is an input + label pair\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            # Make predictions for this batch\n            outputs = model(inputs)\n            _, pred = torch.max(outputs, dim=1)\n            total += labels.size(0)\n\n            # Compute the loss and accuracy\n            loss += loss_fn(outputs, labels).item()\n            correct += (pred == labels).sum().item()\n\n    loss /= total\n    accuracy = correct / total\n\n    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n        loss, correct, total, accuracy * 100))\n    return accuracy, loss","metadata":{"id":"v-JVTN0sCHlk","execution":{"iopub.status.busy":"2023-05-24T01:57:23.008039Z","iopub.execute_input":"2023-05-24T01:57:23.008348Z","iopub.status.idle":"2023-05-24T01:57:23.019014Z","shell.execute_reply.started":"2023-05-24T01:57:23.008309Z","shell.execute_reply":"2023-05-24T01:57:23.018171Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"async def execute(server, T, target_accuracy, es=None, min_delta=0.0, patience=0):\n    _patience = patience\n\n    # initial values\n    record_round = 0\n    best_round = 0\n    best_accuracy = 0.0\n    last_loss = None\n    state_dict, accuracies, losses = [], [], []\n\n    # loop until rounds\n    while server.rounds < T:\n        print(\"Round {}/{}\".format(server.rounds + 1, T))\n\n        # model sync\n        await server.model_sync()\n        \n        # test accuracy\n        accuracy, loss = test_model(server.model)\n\n        if accuracy >= best_accuracy:\n            # save best record\n            best_accuracy = accuracy\n            best_round = server.rounds\n\n            if best_accuracy >= target_accuracy or server.rounds > T - 10:\n                # save state_dict\n                state_dict = server.model.state_dict()\n\n        # statistics\n        accuracies.append(accuracy)\n        losses.append(loss)\n\n        # early stopping\n        if es == 'loss':\n            if last_loss is None:\n                last_loss = loss\n                continue\n\n            if last_loss - loss < min_delta:\n                # break if patience equal to 0\n                if patience == 0:\n                    break\n                else:\n                    patience -= 1\n            else:\n                # reset patience and update last loss\n                patience = _patience\n                last_loss = loss\n\n        # target accuracy reached\n        if accuracy >= target_accuracy and record_round == 0:\n            record_round = server.rounds\n\n    if record_round > 0:\n        print(\"Target accuracy reached at round: {}\".format(record_round))\n    print(\"Best round: {}, accuracy: {}\".format(best_round, best_accuracy))\n\n    return state_dict, accuracies, losses","metadata":{"id":"BQ7wc8Q_FAkU","execution":{"iopub.status.busy":"2023-05-24T01:57:23.020229Z","iopub.execute_input":"2023-05-24T01:57:23.020662Z","iopub.status.idle":"2023-05-24T01:57:23.032163Z","shell.execute_reply.started":"2023-05-24T01:57:23.020576Z","shell.execute_reply":"2023-05-24T01:57:23.031320Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Execute","metadata":{"id":"OE0VQHt_65fS"}},{"cell_type":"code","source":"# model params\nargs = { 'C': 1, 'E': 5, 'B': 10 , 'lr': 0.09 }\n\n# server\nserver = Server(args)\n\n# data distribution\nprint(\"Training dataset - {}\".format(dict(sorted(Counter(training_dataset.targets.tolist()).items()))))\nserver.clients_info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Gas3rs865fT","outputId":"f06e8ff8-8899-47c4-c709-f4aeb088613b","execution":{"iopub.status.busy":"2023-05-24T01:57:23.033341Z","iopub.execute_input":"2023-05-24T01:57:23.034324Z","iopub.status.idle":"2023-05-24T01:57:27.837103Z","shell.execute_reply.started":"2023-05-24T01:57:23.034292Z","shell.execute_reply":"2023-05-24T01:57:27.836155Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Training dataset - {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\nClient 0 - {8: 300, 1: 300}\nClient 1 - {0: 300, 9: 300}\nClient 2 - {3: 577, 2: 23}\nClient 3 - {2: 300, 1: 300}\nClient 4 - {9: 300, 1: 300}\nClient 5 - {8: 300, 6: 235, 7: 65}\nClient 6 - {1: 300, 7: 300}\nClient 7 - {5: 300, 0: 300}\nClient 8 - {0: 300, 1: 300}\nClient 9 - {2: 600}\nClient 10 - {6: 300, 7: 300}\nClient 11 - {9: 300, 7: 300}\nClient 12 - {2: 300, 8: 300}\nClient 13 - {9: 300, 5: 300}\nClient 14 - {2: 300, 5: 300}\nClient 15 - {7: 300, 3: 300}\nClient 16 - {0: 300, 1: 300}\nClient 17 - {9: 300, 4: 300}\nClient 18 - {8: 300, 1: 300}\nClient 19 - {9: 300, 4: 300}\nClient 20 - {9: 600}\nClient 21 - {4: 300, 1: 300}\nClient 22 - {4: 600}\nClient 23 - {3: 300, 0: 300}\nClient 24 - {5: 300, 6: 300}\nClient 25 - {1: 300, 4: 300}\nClient 26 - {1: 300, 7: 300}\nClient 27 - {3: 300, 4: 300}\nClient 28 - {2: 300, 0: 300}\nClient 29 - {7: 300, 2: 300}\nClient 30 - {3: 300, 7: 300}\nClient 31 - {8: 51, 9: 249, 1: 300}\nClient 32 - {7: 300, 9: 300}\nClient 33 - {5: 300, 4: 300}\nClient 34 - {1: 300, 4: 300}\nClient 35 - {4: 300, 2: 300}\nClient 36 - {3: 300, 4: 300}\nClient 37 - {5: 300, 8: 300}\nClient 38 - {3: 154, 4: 146, 0: 300}\nClient 39 - {3: 600}\nClient 40 - {1: 300, 6: 300}\nClient 41 - {6: 300, 7: 300}\nClient 42 - {6: 300, 8: 300}\nClient 43 - {2: 300, 1: 300}\nClient 44 - {5: 17, 6: 283, 8: 300}\nClient 45 - {6: 300, 9: 300}\nClient 46 - {6: 600}\nClient 47 - {4: 600}\nClient 48 - {9: 300, 1: 300}\nClient 49 - {0: 300, 8: 300}\nClient 50 - {2: 300, 5: 300}\nClient 51 - {9: 300, 1: 300}\nClient 52 - {3: 300, 7: 300}\nClient 53 - {4: 300, 7: 300}\nClient 54 - {4: 300, 3: 300}\nClient 55 - {8: 300, 6: 300}\nClient 56 - {7: 300, 0: 300}\nClient 57 - {1: 300, 7: 300}\nClient 58 - {6: 300, 5: 300}\nClient 59 - {5: 300, 4: 300}\nClient 60 - {9: 300, 2: 300}\nClient 61 - {3: 300, 5: 300}\nClient 62 - {2: 300, 8: 300}\nClient 63 - {4: 300, 3: 300}\nClient 64 - {8: 300, 7: 300}\nClient 65 - {8: 300, 0: 300}\nClient 66 - {0: 223, 1: 77, 5: 300}\nClient 67 - {3: 300, 6: 300}\nClient 68 - {8: 300, 7: 300}\nClient 69 - {1: 300, 5: 300}\nClient 70 - {3: 300, 0: 300}\nClient 71 - {9: 300, 8: 300}\nClient 72 - {0: 300, 2: 300}\nClient 73 - {7: 300, 5: 300}\nClient 74 - {4: 300, 5: 300}\nClient 75 - {5: 300, 3: 300}\nClient 76 - {5: 300, 6: 300}\nClient 77 - {2: 300, 7: 200, 8: 100}\nClient 78 - {7: 300, 0: 300}\nClient 79 - {2: 300, 8: 300}\nClient 80 - {8: 300, 1: 300}\nClient 81 - {9: 300, 2: 300}\nClient 82 - {3: 300, 7: 300}\nClient 83 - {1: 300, 0: 300}\nClient 84 - {6: 300, 1: 300}\nClient 85 - {9: 300, 0: 300}\nClient 86 - {5: 300, 2: 300}\nClient 87 - {8: 300, 9: 300}\nClient 88 - {6: 300, 1: 65, 2: 235}\nClient 89 - {0: 300, 7: 300}\nClient 90 - {0: 300, 1: 300}\nClient 91 - {6: 300, 2: 300}\nClient 92 - {8: 300, 7: 300}\nClient 93 - {3: 300, 6: 300}\nClient 94 - {8: 300, 6: 300}\nClient 95 - {2: 300, 3: 300}\nClient 96 - {0: 600}\nClient 97 - {6: 300, 5: 300}\nClient 98 - {9: 300, 4: 296, 5: 4}\nClient 99 - {9: 300, 3: 300}\n","output_type":"stream"}]},{"cell_type":"code","source":"# rounds and target accuracy\nT = 200\ntarget_accuracy = 0.99\n\nstate_dict, accuracies, losses = await execute(server, T, target_accuracy)\n\n# save model to file\ntorch.save(state_dict, \"cnn_state_dict.pth\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjbFmiTb65fT","outputId":"1467fbfb-3b0e-4bb3-bd3d-df056b1cbfaa","execution":{"iopub.status.busy":"2023-05-24T01:57:27.838512Z","iopub.execute_input":"2023-05-24T01:57:27.839121Z","iopub.status.idle":"2023-05-24T04:37:45.499074Z","shell.execute_reply.started":"2023-05-24T01:57:27.839085Z","shell.execute_reply":"2023-05-24T04:37:45.497336Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Round 1/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:49<00:00,  2.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.2293, Accuracy: 2255/10000 (22.55%)\nRound 2/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:46<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.2024, Accuracy: 6481/10000 (64.81%)\nRound 3/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.1350, Accuracy: 8293/10000 (82.93%)\nRound 4/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0759, Accuracy: 8989/10000 (89.89%)\nRound 5/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0701, Accuracy: 9115/10000 (91.15%)\nRound 6/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0352, Accuracy: 9360/10000 (93.60%)\nRound 7/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0344, Accuracy: 9435/10000 (94.35%)\nRound 8/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:46<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0230, Accuracy: 9505/10000 (95.05%)\nRound 9/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0197, Accuracy: 9569/10000 (95.69%)\nRound 10/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0165, Accuracy: 9626/10000 (96.26%)\nRound 11/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0153, Accuracy: 9636/10000 (96.36%)\nRound 12/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0136, Accuracy: 9665/10000 (96.65%)\nRound 13/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0130, Accuracy: 9681/10000 (96.81%)\nRound 14/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0117, Accuracy: 9686/10000 (96.86%)\nRound 15/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0103, Accuracy: 9703/10000 (97.03%)\nRound 16/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0113, Accuracy: 9688/10000 (96.88%)\nRound 17/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0094, Accuracy: 9721/10000 (97.21%)\nRound 18/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0096, Accuracy: 9731/10000 (97.31%)\nRound 19/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0089, Accuracy: 9736/10000 (97.36%)\nRound 20/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0087, Accuracy: 9733/10000 (97.33%)\nRound 21/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0079, Accuracy: 9755/10000 (97.55%)\nRound 22/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0075, Accuracy: 9767/10000 (97.67%)\nRound 23/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0071, Accuracy: 9777/10000 (97.77%)\nRound 24/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0070, Accuracy: 9781/10000 (97.81%)\nRound 25/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0068, Accuracy: 9785/10000 (97.85%)\nRound 26/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0068, Accuracy: 9793/10000 (97.93%)\nRound 27/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:46<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0065, Accuracy: 9797/10000 (97.97%)\nRound 28/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0062, Accuracy: 9797/10000 (97.97%)\nRound 29/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0059, Accuracy: 9803/10000 (98.03%)\nRound 30/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0057, Accuracy: 9808/10000 (98.08%)\nRound 31/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9815/10000 (98.15%)\nRound 32/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0055, Accuracy: 9812/10000 (98.12%)\nRound 33/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0054, Accuracy: 9819/10000 (98.19%)\nRound 34/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0051, Accuracy: 9828/10000 (98.28%)\nRound 35/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0052, Accuracy: 9823/10000 (98.23%)\nRound 36/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0051, Accuracy: 9826/10000 (98.26%)\nRound 37/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0049, Accuracy: 9825/10000 (98.25%)\nRound 38/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9833/10000 (98.33%)\nRound 39/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9829/10000 (98.29%)\nRound 40/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0047, Accuracy: 9831/10000 (98.31%)\nRound 41/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9839/10000 (98.39%)\nRound 42/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0045, Accuracy: 9847/10000 (98.47%)\nRound 43/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0046, Accuracy: 9844/10000 (98.44%)\nRound 44/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0044, Accuracy: 9850/10000 (98.50%)\nRound 45/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9851/10000 (98.51%)\nRound 46/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9849/10000 (98.49%)\nRound 47/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9847/10000 (98.47%)\nRound 48/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0042, Accuracy: 9855/10000 (98.55%)\nRound 49/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0043, Accuracy: 9851/10000 (98.51%)\nRound 50/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0041, Accuracy: 9858/10000 (98.58%)\nRound 51/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9855/10000 (98.55%)\nRound 52/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9858/10000 (98.58%)\nRound 53/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9857/10000 (98.57%)\nRound 54/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9855/10000 (98.55%)\nRound 55/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0040, Accuracy: 9858/10000 (98.58%)\nRound 56/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0039, Accuracy: 9858/10000 (98.58%)\nRound 57/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9860/10000 (98.60%)\nRound 58/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9860/10000 (98.60%)\nRound 59/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9868/10000 (98.68%)\nRound 60/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9866/10000 (98.66%)\nRound 61/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0038, Accuracy: 9866/10000 (98.66%)\nRound 62/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9861/10000 (98.61%)\nRound 63/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9868/10000 (98.68%)\nRound 64/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9867/10000 (98.67%)\nRound 65/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9868/10000 (98.68%)\nRound 66/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0036, Accuracy: 9870/10000 (98.70%)\nRound 67/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0037, Accuracy: 9868/10000 (98.68%)\nRound 68/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9868/10000 (98.68%)\nRound 69/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9866/10000 (98.66%)\nRound 70/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9876/10000 (98.76%)\nRound 71/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9872/10000 (98.72%)\nRound 72/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0035, Accuracy: 9866/10000 (98.66%)\nRound 73/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9872/10000 (98.72%)\nRound 74/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9869/10000 (98.69%)\nRound 75/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9868/10000 (98.68%)\nRound 76/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9870/10000 (98.70%)\nRound 77/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9873/10000 (98.73%)\nRound 78/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9872/10000 (98.72%)\nRound 79/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9876/10000 (98.76%)\nRound 80/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9873/10000 (98.73%)\nRound 81/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9874/10000 (98.74%)\nRound 82/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9877/10000 (98.77%)\nRound 83/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9875/10000 (98.75%)\nRound 84/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0034, Accuracy: 9870/10000 (98.70%)\nRound 85/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9871/10000 (98.71%)\nRound 86/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9871/10000 (98.71%)\nRound 87/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9874/10000 (98.74%)\nRound 88/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9881/10000 (98.81%)\nRound 89/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9875/10000 (98.75%)\nRound 90/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0033, Accuracy: 9869/10000 (98.69%)\nRound 91/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9871/10000 (98.71%)\nRound 92/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9880/10000 (98.80%)\nRound 93/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9874/10000 (98.74%)\nRound 94/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9879/10000 (98.79%)\nRound 95/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9883/10000 (98.83%)\nRound 96/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9875/10000 (98.75%)\nRound 97/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9876/10000 (98.76%)\nRound 98/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9884/10000 (98.84%)\nRound 99/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9873/10000 (98.73%)\nRound 100/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0032, Accuracy: 9872/10000 (98.72%)\nRound 101/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9875/10000 (98.75%)\nRound 102/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9881/10000 (98.81%)\nRound 103/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9878/10000 (98.78%)\nRound 104/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9875/10000 (98.75%)\nRound 105/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9878/10000 (98.78%)\nRound 106/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9879/10000 (98.79%)\nRound 107/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9880/10000 (98.80%)\nRound 108/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9882/10000 (98.82%)\nRound 109/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0031, Accuracy: 9886/10000 (98.86%)\nRound 110/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9885/10000 (98.85%)\nRound 111/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9880/10000 (98.80%)\nRound 112/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9882/10000 (98.82%)\nRound 113/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9885/10000 (98.85%)\nRound 114/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9884/10000 (98.84%)\nRound 115/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9885/10000 (98.85%)\nRound 116/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9883/10000 (98.83%)\nRound 117/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9887/10000 (98.87%)\nRound 118/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9883/10000 (98.83%)\nRound 119/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9881/10000 (98.81%)\nRound 120/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9884/10000 (98.84%)\nRound 121/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9886/10000 (98.86%)\nRound 122/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9889/10000 (98.89%)\nRound 123/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9886/10000 (98.86%)\nRound 124/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9889/10000 (98.89%)\nRound 125/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9887/10000 (98.87%)\nRound 126/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9888/10000 (98.88%)\nRound 127/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9881/10000 (98.81%)\nRound 128/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9890/10000 (98.90%)\nRound 129/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 130/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9891/10000 (98.91%)\nRound 131/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9883/10000 (98.83%)\nRound 132/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9887/10000 (98.87%)\nRound 133/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 134/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9896/10000 (98.96%)\nRound 135/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 136/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 137/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9890/10000 (98.90%)\nRound 138/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9889/10000 (98.89%)\nRound 139/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 140/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9896/10000 (98.96%)\nRound 141/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 142/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 143/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9893/10000 (98.93%)\nRound 144/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9889/10000 (98.89%)\nRound 145/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 146/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 147/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9890/10000 (98.90%)\nRound 148/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9890/10000 (98.90%)\nRound 149/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 150/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9898/10000 (98.98%)\nRound 151/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 152/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 153/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 154/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9892/10000 (98.92%)\nRound 155/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 156/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 157/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9890/10000 (98.90%)\nRound 158/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 159/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9895/10000 (98.95%)\nRound 160/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9893/10000 (98.93%)\nRound 161/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9894/10000 (98.94%)\nRound 162/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9896/10000 (98.96%)\nRound 163/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9896/10000 (98.96%)\nRound 164/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9890/10000 (98.90%)\nRound 165/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9897/10000 (98.97%)\nRound 166/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9897/10000 (98.97%)\nRound 167/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9897/10000 (98.97%)\nRound 168/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9897/10000 (98.97%)\nRound 169/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 170/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 171/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 172/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9899/10000 (98.99%)\nRound 173/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9901/10000 (99.01%)\nRound 174/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 175/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 176/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 177/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 178/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9902/10000 (99.02%)\nRound 179/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9902/10000 (99.02%)\nRound 180/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9902/10000 (99.02%)\nRound 181/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9906/10000 (99.06%)\nRound 182/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9901/10000 (99.01%)\nRound 183/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9899/10000 (98.99%)\nRound 184/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9901/10000 (99.01%)\nRound 185/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9900/10000 (99.00%)\nRound 186/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:44<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 187/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 188/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9904/10000 (99.04%)\nRound 189/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9905/10000 (99.05%)\nRound 190/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9904/10000 (99.04%)\nRound 191/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9905/10000 (99.05%)\nRound 192/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9904/10000 (99.04%)\nRound 193/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 194/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nRound 195/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0030, Accuracy: 9902/10000 (99.02%)\nRound 196/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9909/10000 (99.09%)\nRound 197/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9905/10000 (99.05%)\nRound 198/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9906/10000 (99.06%)\nRound 199/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0028, Accuracy: 9906/10000 (99.06%)\nRound 200/200\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:45<00:00,  2.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test set: Average loss: 0.0029, Accuracy: 9903/10000 (99.03%)\nTarget accuracy reached at round: 173\nBest round: 196, accuracy: 0.9909\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Statistics","metadata":{"id":"VIENpKmy65fT"}},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(accuracies)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Um5mHx2E65fT","outputId":"3be8cfe8-3876-4205-bdbd-aebf5b2bed9f","execution":{"iopub.status.busy":"2023-05-24T04:37:45.500367Z","iopub.execute_input":"2023-05-24T04:37:45.501156Z","iopub.status.idle":"2023-05-24T04:37:45.506778Z","shell.execute_reply.started":"2023-05-24T04:37:45.501120Z","shell.execute_reply":"2023-05-24T04:37:45.505547Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[0.2255, 0.6481, 0.8293, 0.8989, 0.9115, 0.936, 0.9435, 0.9505, 0.9569, 0.9626, 0.9636, 0.9665, 0.9681, 0.9686, 0.9703, 0.9688, 0.9721, 0.9731, 0.9736, 0.9733, 0.9755, 0.9767, 0.9777, 0.9781, 0.9785, 0.9793, 0.9797, 0.9797, 0.9803, 0.9808, 0.9815, 0.9812, 0.9819, 0.9828, 0.9823, 0.9826, 0.9825, 0.9833, 0.9829, 0.9831, 0.9839, 0.9847, 0.9844, 0.985, 0.9851, 0.9849, 0.9847, 0.9855, 0.9851, 0.9858, 0.9855, 0.9858, 0.9857, 0.9855, 0.9858, 0.9858, 0.986, 0.986, 0.9868, 0.9866, 0.9866, 0.9861, 0.9868, 0.9867, 0.9868, 0.987, 0.9868, 0.9868, 0.9866, 0.9876, 0.9872, 0.9866, 0.9872, 0.9869, 0.9868, 0.987, 0.9873, 0.9872, 0.9876, 0.9873, 0.9874, 0.9877, 0.9875, 0.987, 0.9871, 0.9871, 0.9874, 0.9881, 0.9875, 0.9869, 0.9871, 0.988, 0.9874, 0.9879, 0.9883, 0.9875, 0.9876, 0.9884, 0.9873, 0.9872, 0.9875, 0.9881, 0.9878, 0.9875, 0.9878, 0.9879, 0.988, 0.9882, 0.9886, 0.9885, 0.988, 0.9882, 0.9885, 0.9884, 0.9885, 0.9883, 0.9887, 0.9883, 0.9881, 0.9884, 0.9886, 0.9889, 0.9886, 0.9889, 0.9887, 0.9888, 0.9881, 0.989, 0.9892, 0.9891, 0.9883, 0.9887, 0.9892, 0.9896, 0.9895, 0.9894, 0.989, 0.9889, 0.9894, 0.9896, 0.9895, 0.9892, 0.9893, 0.9889, 0.9892, 0.9892, 0.989, 0.989, 0.9897, 0.9898, 0.9895, 0.9895, 0.9895, 0.9892, 0.9894, 0.9895, 0.989, 0.9895, 0.9895, 0.9893, 0.9894, 0.9896, 0.9896, 0.989, 0.9897, 0.9897, 0.9897, 0.9897, 0.9899, 0.9899, 0.9899, 0.9899, 0.9901, 0.9902, 0.9902, 0.9902, 0.9903, 0.9902, 0.9902, 0.9902, 0.9906, 0.9901, 0.9899, 0.9901, 0.99, 0.9904, 0.9904, 0.9904, 0.9905, 0.9904, 0.9905, 0.9904, 0.9903, 0.9903, 0.9902, 0.9909, 0.9905, 0.9906, 0.9906, 0.9903]\n","output_type":"stream"}]},{"cell_type":"code","source":"# manual save to shared drive for reproducible graph\nprint(losses)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfI_uBW-65fU","outputId":"938c6c2f-03c1-4a42-9ee7-e32cd9ad093b","execution":{"iopub.status.busy":"2023-05-24T04:37:45.508073Z","iopub.execute_input":"2023-05-24T04:37:45.508734Z","iopub.status.idle":"2023-05-24T04:37:45.516568Z","shell.execute_reply.started":"2023-05-24T04:37:45.508701Z","shell.execute_reply":"2023-05-24T04:37:45.515649Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[0.22925759294033052, 0.20237414591312408, 0.1349982677936554, 0.07591481669545173, 0.07014340841770172, 0.03524129109345377, 0.03441125398427248, 0.0230167167596519, 0.01969043506840244, 0.016494119084766133, 0.01534218602590263, 0.013595086565660313, 0.012988433095626533, 0.011718473165435717, 0.010309550979326013, 0.011321648910432122, 0.009354037974838867, 0.009567957609851145, 0.008857247790513794, 0.008736551835818682, 0.007894078736347728, 0.007454510912799742, 0.007111240522644949, 0.006953933207907539, 0.006758121373900213, 0.006779027570952894, 0.006460035693657119, 0.0062203381931365586, 0.005882048920711531, 0.005725926096420153, 0.005428905720261173, 0.005528648974913813, 0.005365806303991121, 0.005095648306176372, 0.005176543221683459, 0.005123346985504031, 0.004892963064029027, 0.004731652057292377, 0.004742153611876529, 0.004675154225378356, 0.004546844894267088, 0.004457123335985761, 0.004642414563165221, 0.004409183339318315, 0.004300598156088381, 0.0042671578164026865, 0.004324608456849637, 0.004160836416966594, 0.004324250127677078, 0.004067627956155502, 0.004013807201259169, 0.00395407142836757, 0.003933163364732172, 0.004029060522620057, 0.004019108503337702, 0.0038626717876813475, 0.0037933884502530644, 0.0037530428306973137, 0.003749461546440557, 0.0037317485684622625, 0.003767250335731205, 0.0036960901821039443, 0.0036644866281404574, 0.003647281903426119, 0.0036936503602356422, 0.003596560536099423, 0.0036772349632648, 0.0035169809566831874, 0.0035410360558795675, 0.003440701013690318, 0.003418185347754445, 0.0034616566865249866, 0.0034429809208883057, 0.003449077659038426, 0.003411310325538966, 0.003341274924898221, 0.003320319633869849, 0.0033210338623733834, 0.0033562144009817757, 0.0033182421669482893, 0.003317750941413442, 0.0032887459907691096, 0.00331586787447784, 0.0033717552244723493, 0.0033179759808946527, 0.0033342869579314083, 0.0032856462537437666, 0.0032333840855033485, 0.0032016472721469085, 0.0032562377860106836, 0.0032372525239611036, 0.003212709361631755, 0.0031941660704974083, 0.003128447758688901, 0.003100913416460173, 0.003119057529174705, 0.0031178806736145473, 0.003101744131603482, 0.00314108449203286, 0.00315545448935527, 0.0031459663372955904, 0.0031053771283811897, 0.0031168632312032285, 0.003084043812818197, 0.003050357842761014, 0.00305853947411469, 0.0030878806434731414, 0.0030824782765969927, 0.0030514810374483604, 0.00300344946650103, 0.003014243998230546, 0.0029834792513795806, 0.0030008431649497197, 0.0030010158091467645, 0.0029506471861004625, 0.002977596931131211, 0.002970900248807669, 0.0030322532499061365, 0.002996462703176758, 0.002968663155137571, 0.0029561434842800566, 0.0029900731064837656, 0.0029836432304986035, 0.0029593954877399965, 0.002965486497125076, 0.0029278270401229887, 0.0029813105311110805, 0.0029954949366861627, 0.0029343929444774516, 0.0029356428599895397, 0.0029801798210413637, 0.0029415239751440824, 0.0029286373857781854, 0.002931170500153996, 0.0029143081275021404, 0.0028862408957110418, 0.002894776793538796, 0.002921658473164974, 0.0029261299238738277, 0.002925679133168559, 0.0028634473718310524, 0.002856999038886204, 0.0029160288535235892, 0.002971668328672616, 0.002948079364503273, 0.0029248683010980863, 0.0029349213989437063, 0.002966847542970158, 0.0029227150257244753, 0.002923907231613855, 0.002917332239154242, 0.0029150147260831737, 0.0028747936737362595, 0.0029039982311479784, 0.0029484128921335845, 0.002917360210570547, 0.002992873478666137, 0.0028927725749342548, 0.0028797864466591173, 0.002863040585729239, 0.002886915672843771, 0.0028794044927998833, 0.0028731569824368515, 0.0029241303540074115, 0.002860445745520867, 0.002835859953567589, 0.002847322718841007, 0.0028227308800062895, 0.0028081733297887533, 0.0028522995689089065, 0.002874818795198232, 0.002860775230077439, 0.002856141287453257, 0.0028797096586801927, 0.00289810923831055, 0.002850797662934797, 0.0028681166830455524, 0.0028570938379540497, 0.0028472566450614225, 0.0028380482118856585, 0.002825897401668387, 0.0028089330755309873, 0.00283989456345379, 0.00286871360383096, 0.0029293964795983726, 0.0028313580049908354, 0.0028502504562175376, 0.0028398689982295456, 0.0028885596889452803, 0.002901963961487223, 0.0029209671949303657, 0.0029562829124190164, 0.0029312847167275455, 0.002910008471424564, 0.0029516733069394176, 0.0028854595809866715, 0.0029011286682365557, 0.00286198145425751, 0.0028460676275135635, 0.0029100089411936755]\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(accuracies)\nplt.title('Test Accuracy')\nplt.xlabel('Rounds')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nplt.grid(True)\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"mTQI9WGZ65fU","outputId":"7e81e0a0-ba97-460f-d980-bd2f5d4fb4d5","execution":{"iopub.status.busy":"2023-05-24T04:37:45.517697Z","iopub.execute_input":"2023-05-24T04:37:45.518383Z","iopub.status.idle":"2023-05-24T04:37:45.776866Z","shell.execute_reply.started":"2023-05-24T04:37:45.518350Z","shell.execute_reply":"2023-05-24T04:37:45.775857Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}